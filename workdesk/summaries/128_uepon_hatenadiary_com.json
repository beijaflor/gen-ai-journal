{
  "metadata": {
    "version": "1.0",
    "generatedAt": "2026-02-13T17:25:33.884572+00:00",
    "generatedBy": "gemini-3-flash-preview"
  },
  "content": {
    "title": "8GBメモリでOK！Raspberry Pi 5で使える日本語対応ローカルLLM一覧",
    "url": "https://uepon.hatenablog.com/entry/2026/02/03/234400",
    "language": "ja",
    "contentType": "💡 Tutorial & How-to (チュートリアル)",
    "oneSentenceSummary": "Raspberry Pi 5の8GBモデルにおいて、快適に動作する1B〜3Bクラスの日本語対応ローカルLLMの選び方と具体的な導入手順を解説。",
    "summaryBody": "Raspberry Pi 5（8GB RAM）環境において、外部ハードウェアを使わずリアルタイムに対話可能な日本語LLMの構築方法を紹介しています。1Bから3Bパラメータの軽量モデル（TinySwallow-1.5B、Gemma-2-2B-JPN-IT、LFM2.5-1.2B-JP等）が推奨されており、それぞれの推論速度やメモリ使用量の実測データが提示されています。導入ツールとしては、手軽なOllamaと、10〜20%高速なllama.cppの2つのアプローチを解説。さらに、ブラウザから対話するためのOpen WebUIのセットアップ方法も網羅しており、エッジデバイスでの実用的なAI活用を検討しているユーザー向けの包括的なガイドとなっています。",
    "topics": [
      "Raspberry Pi 5",
      "ローカルLLM",
      "エッジAI",
      "Ollama",
      "日本語LLM"
    ],
    "scores": {
      "signal": 5,
      "depth": 4,
      "uniqueness": 4,
      "practical": 5,
      "antiHype": 4,
      "mainJournal": 85,
      "annexPotential": 95,
      "overall": 90
    },
    "originalTitle": null
  }
}