## AI False Information Rate Nearly Doubles in One Year

https://www.newsguardtech.com/ai-monitor/august-2025-ai-false-claim-monitor/

NewsGuardの監査は、主要な生成AIツールがニュース関連の質問に対し誤情報を拡散する確率が過去1年でほぼ倍増し、35%に達したことを示しています。

**Content Type**: Research & Analysis

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 81/100 | **Annex Potential**: 82/100 | **Overall**: 84/100

**Topics**: [[AIの信頼性, 誤情報拡散, LLMの幻覚, リアルタイム検索の課題, 情報源の汚染]]

NewsGuardの最新監査によると、主要な生成AIツールがニュース関連の質問に対して誤情報を拡散する割合が、わずか1年でほぼ倍増し、2024年8月の18%から2025年8月には35%に達しました。これは、AI業界が「より安全で信頼性の高いシステム」を謳う一方で、現実世界での進歩が見られないことを浮き彫りにしています。

この増加の背景には、チャットボットが応答拒否を減らし、リアルタイムでのウェブ検索を積極的に取り入れた「構造的なトレードオフ」があります。2024年には31%あった応答拒否率が、2025年には0%に減少したものの、その代償として誤情報を提供する可能性が飛躍的に高まりました。AIは現在、「汚染されたオンライン情報エコシステム」から情報を引き出し、信頼性の低い情報源をあたかも信頼できるものとして扱っています。悪意のあるアクターは、AIがニュースクエリに応答しようとするこの新たな傾向を悪用し、信頼性の低いウェブサイトやAI生成のコンテンツファームを通じて誤情報を拡散させています。

ウェブアプリケーションエンジニアにとって、これはAIを活用したシステム開発において極めて重要な示唆を与えます。リアルタイム検索機能の統合は、利便性向上と引き換えに、意図せずプロパガンダを拡散してしまうリスクを伴う可能性があります。AIが生成するコンテンツのファクトチェック機構や、情報の信頼性を評価するレイヤーの必要性がこれまで以上に高まっており、AIの応答性と信頼性のバランスを慎重に考慮した設計が不可欠です。