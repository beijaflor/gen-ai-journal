## Claude、9月28日からデータをモデル学習に活用　オフの場合は設定変更

https://www.watch.impress.co.jp/docs/news/2043215.html

Anthropicは、9月28日以降、Claudeの一般ユーザーデータをモデルトレーニングに利用する方針変更を発表し、ユーザーにプライバシー設定でのオプトアウト選択肢を提供します。

**Content Type**: News & Announcements

**Scores**: Signal:5/5 | Depth:2/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 80/100 | **Annex Potential**: 74/100 | **Overall**: 72/100

**Topics**: [[Claude, データプライバシー, LLMトレーニング, 利用規約変更, AI倫理]]

Anthropicは、2025年9月28日より、一般ユーザー向けのClaude（Free、Pro、Maxプラン）がチャット等で利用したデータを、モデルのトレーニングに活用する方針へと利用規約とプライバシーポリシーを変更することを発表しました。この変更は、主に有害コンテンツ検出システムの精度向上と誤検知の削減、さらにはコーディング、分析、推論といったClaudeモデルの中核スキルを向上させることを目的としています。

この方針変更は、日々の開発業務でClaudeを利用するウェブアプリケーションエンジニアにとって、見過ごせない影響を及ぼします。これまで意識していなかったユーザーデータが、明示的に拒否しない限りモデル学習に利用される可能性があるためです。特に、コード生成、デバッグ補助、技術的な議論のパートナーとしてClaudeを活用している場合、入力した自社の知的財産や機密性の高いコードスニペットが、将来のモデルの「知識」の一部となるリスクを孕んでいます。

Anthropicはプライバシー設定画面からデータ利用を「オフ」にできる選択肢を提供しており、オフにした場合は現行の30日間データ保持期間が適用されます。しかし、データ利用を許可した場合は、その保持期間が5年間に延長されるという点も重要です。この設定変更は、単なるプライバシーポリシーの更新に留まらず、開発チーム内でのLLM利用ガイドラインやデータガバナンスのあり方を根本から見直す契機となります。

Claude for WorkやAPI利用、Amazon BedrockやGoogle Cloud Vertex AI経由の利用は対象外ですが、個人アカウントや小規模チームで利用しているエンジニアは、意図せず企業情報を共有してしまわないよう、注意が必要です。AIアシスタントの利便性を享受しつつ、データプライバシーとセキュリティを確保するためには、各開発者が自身の設定を確認し、組織としてClaudeを含むAIツールの利用方針を明確に定めることが、喫緊の課題となるでしょう。モデルの進化と引き換えに、データ共有のリスクをどう管理するかが問われています。