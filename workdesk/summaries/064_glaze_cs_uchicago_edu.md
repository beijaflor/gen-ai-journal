## Glaze：AIによる画風の模倣からアーティストを保護する防御システム

https://glaze.cs.uchicago.edu/what-is-glaze.html

**Original Title**: What is Glaze

機械学習による「アドバーサリアル（敵対的）な摂動」を画像に加えることで、人間の視覚を損なわずにAIモデルによる画風の抽出と模倣を技術的に妨害する。

**Content Type**: ⚙️ Tools
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 93/100 | **Overall**: 92/100

**Topics**: [[Adversarial Machine Learning, Style Mimicry, AI Ethics, Image Protection, Fine-tuning Defense]]

シカゴ大学のSAND Labが公開した「Glaze」は、アーティストの著作権やアイデンティティを保護するために設計された、アドバーサリアル（敵対的）機械学習に基づく防御ツールである。生成AI、特にStable DiffusionやMidJourneyといった拡散モデルの普及により、特定のアーティストの作風をLoRAなどの手法で低コストに模倣する「スタイル・ミミクリー（画風模倣）」が一般化している。著者は、これが単なるコピーの問題ではなく、アーティストが長年培ってきた「アイデンティティの盗用」であり、経済的な損失に加えて創作意欲を著しく削ぐものであると主張している。

技術的な仕組みとして、GlazeはAIモデルが画像を解釈する際の計算プロセスを逆手に取る。画像に微細な「摂動（微調整）」を加えることで、人間の目には元の絵（例：鉛筆画の肖像）と変わらずに見えるが、AIモデルには全く異なるスタイル（例：ジャクソン・ポロック風の抽象画）として認識させる。これにより、保護された画像を元にAIをファインチューニングしても、モデルは誤ったスタイルを学習するため、意図した通りの画風模倣が成立しなくなる。これはステガノグラフィー（隠しメッセージ）や単純なノイズ付与とは異なり、AIが画像を処理する際の「高次元の次元」に作用するため、スクリーンショットやリサイズ、圧縮、ノイズ除去フィルタといった一般的な画像処理に対しても一定の堅牢性を備えているのが特徴である。

最新のバージョン2.1では、2024年6月に報告された「noisy upscaler」攻撃など、Glazeの効果を無効化しようとする最新の試みに対する耐性が強化された。また、強力なGPUを持たないユーザー向けに、クラウド上で処理を行う「WebGlaze」も提供されている。

ウェブアプリケーションエンジニアの視点からこの技術が重要な理由は、AIモデルの脆弱性を防御に転用した「アドバーサリアル・ディフェンス」の実装例である点にある。著者は、法整備や規制には時間がかかるため、技術的な防壁がコミュニティの崩壊を防ぐために不可欠であると説く。一方で、これが「永続的な解決策」ではないことも認めており、AIの進化と保護技術のいたちごっこの中での「必要な第一歩」と位置づけている。生成AIを利用したプラットフォームを開発・運営するエンジニアにとって、学習データの倫理性や、モデルに対する敵対的攻撃への耐性、そしてクリエイターとの共生を考える上で、非常に示唆に富むプロジェクトである。