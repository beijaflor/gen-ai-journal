{
  "metadata": {
    "version": "1.0",
    "generatedAt": "2026-03-01T04:54:04.497299+00:00",
    "generatedBy": "gemini-3-flash-preview"
  },
  "content": {
    "title": "Anthropicが「責任あるスケーリング・ポリシー（RSP）」バージョン3.0を公開：実効性と透明性の向上へ",
    "url": "https://www.anthropic.com/news/responsible-scaling-policy-v3",
    "language": "ja",
    "contentType": "🚀 Product Launch (製品発表)",
    "oneSentenceSummary": "Anthropicは、AIの壊滅的リスクを抑制するための指針「RSP」を刷新し、自社目標と業界提言の分離、外部監査の導入、進捗公開の義務化を含む新枠組みを導入した。",
    "summaryBody": "Anthropicは、高度なAIモデルの開発に伴うリスクを管理するための「責任あるスケーリング・ポリシー（RSP）」の第3版を公開しました。2年間の運用経験を経て、従来の「AI安全レベル（ASL）」に基づく画一的な制限から、より透明性と柔軟性の高いアプローチへと移行しています。\n\n主な変更点は以下の3点です：\n1. **自社計画と業界提言の分離**: 一企業で実現可能な「自社の安全目標」と、業界全体や政府との協力が必要な「理想的な対策マップ」を明確に区別しました。\n2. **フロンティア安全ロードマップ**: セキュリティ、アライメント、政策などの領域で野心的な目標を設定し、その進捗を公表して自己評価を行う「非拘束だが公開される」目標管理を導入します。\n3. **リスクレポートと外部レビュー**: 3〜6ヶ月ごとにモデルの安全性を詳述したレポートを公開し、特定の状況下では第三者専門家による厳格な外部監査を実施します。\n\n本改訂は、AI能力評価の科学的な不確実性（Zone of Ambiguity）や、高度な安全対策を単独企業で完結させることの限界を認めた上で、実証的なデータに基づいた透明性の高いガバナンスを目指すものです。",
    "topics": [
      "AI安全 (AI Safety)",
      "Anthropic",
      "責任あるスケーリング・ポリシー (RSP)",
      "AIガバナンス",
      "リスク管理"
    ],
    "scores": {
      "signal": 5,
      "depth": 5,
      "uniqueness": 4,
      "practical": 3,
      "antiHype": 5,
      "mainJournal": 95,
      "annexPotential": 80,
      "overall": 92
    },
    "originalTitle": "Anthropic’s Responsible Scaling Policy: Version 3.0"
  }
}