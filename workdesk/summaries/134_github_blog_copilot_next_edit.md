## GitHub Copilotの次編集提案機能をカスタムモデルトレーニングで進化させる

https://github.blog/ai-and-ml/github-copilot/evolving-github-copilots-next-edit-suggestions-through-custom-model-training/

**Original Title**: Evolving GitHub Copilot’s next edit suggestions through custom model training

GitHub Copilotは、カスタムデータセット、強化学習、エディタ内ワークフローに合わせた継続的なモデル更新により、次世代の編集提案機能をより高速、スマート、かつ正確に進化させた。

**Content Type**: ⚙️ Tools
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 84/100 | **Annex Potential**: 83/100 | **Overall**: 84/100

**Topics**: [[GitHub Copilot, AI Code Generation, Machine Learning, Reinforcement Learning, IDE Enhancements]]

GitHub Copilotの「次編集提案（Next Edit Suggestions; NES）」機能が、カスタムモデルトレーニングを通じていかに進化しているかを詳細に解説しています。本記事は、NESの導入以降、GitHubがどのようにモデルを改善し、より高速かつ正確なコード補完を実現してきたかを紹介しています。

まず、トークン予測よりも困難な「次編集予測」の課題を提示します。これは、開発者の意図をローカルコンテキストから推測し、高速に反応しつつ、かつ邪魔にならないタイミングで提案する必要があるためです。既存の汎用モデルでは、この品質とレイテンシーの要件を満たせず、専用のカスタムモデル開発が不可欠でした。

モデルトレーニングの初期段階では、プルリクエストデータを用いたアプローチが試みられましたが、これは実際のリアルタイム編集の挙動（中間編集、破棄された編集、ネガティブサンプルなど）を捉えきれず、期待通りの性能を発揮できませんでした。この失敗から、GitHubは内部ボランティアの編集セッションから得られた高品位なカスタムデータセットを構築。このデータに対する教師ありファインチューニング（SFT）により、汎用LLMを上回る最初のNESモデルが誕生しました。

さらなるモデルの洗練には、強化学習（RL）が導入されました。SFTが「良い」提案を学習するのに対し、RLは「悪い」提案を避け、また大量のラベルなしコードサンプルを活用するために役立ちます。具体的には、大規模な推論モデルを「グレーダー」として使用し、提案の品質を評価し、UIでのコード差分の読みやすさも考慮に入れた基準で学習を強化しました。これにより、モデルは汎化能力を高め、定義された「悪い提案」を生成するのを効果的に回避できるようになりました。

最近のNESリリースでは、プロンプトの最適化（コンテキスト削減、トークンキャッシュの再利用）、LLMベースの品質フィルタリング、大規模モデルからの合成データ利用、ハイパーパラメータチューニングが改善され、速度と品質が向上しています。これらの改善は、オフラインテスト、社内ドッグフーディング、A/Bテストという厳格な評価プロセスを経て実装されました。

コミュニティからのフィードバックは、モデルの進化に不可欠であり、「積極的すぎる」という意見から「もっと積極的に介入してほしい」という多様な要望に応えるため、提案の表示頻度を調整し、レイテンシーを低減。今後は、個々の開発者の編集スタイルに適応するアダプティブな挙動も探求していく予定です。

Webアプリケーションエンジニアにとって、これが重要である理由は、GitHub Copilotが単なるコード補完ツールを超え、開発者の思考とシームレスに連携するインテリジェントなアシスタントへと深化しているためです。カスタムデータと強化学習による継続的な進化は、より複雑なリファクタリングやマルチファイル編集（「Edits at a distance」として今後の機能）においても、より的確で生産性の高い支援を提供することを示唆しています。これは、日々の開発ワークフローがAIによってさらに効率化され、より本質的な問題解決に集中できる未来を予感させます。