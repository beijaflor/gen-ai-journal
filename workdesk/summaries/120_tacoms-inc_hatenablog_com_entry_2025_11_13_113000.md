## 会話型AIエージェントでFunction Callingを使いこなす！

https://tacoms-inc.hatenablog.com/entry/2025/11/13/113000

tacomsのエンジニアMorix氏が、開発中の飲食店向け電話注文受付AIエージェント「Camel AI Call」におけるFunction Callingの活用経験から得られた課題とその解決策を具体的なプロンプト戦略と共に解説します。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 77/100 | **Overall**: 80/100

**Topics**: [[Function Calling, AIエージェント, プロンプトエンジニアリング, LLM, パフォーマンス最適化]]

tacomsのMorix氏は、飲食店向け電話注文受付AIエージェント「Camel AI Call」の開発において、LLMのFunction Calling機能を多用する中で直面した課題と、その実践的な解決策を共有しています。Function CallingはLLMが外部システムと連携し、API実行やDBアクセスを可能にする機能であり、LLMに明確なタスクを実行させる場合に速度と正確性で優位性があると筆者は指摘します。

記事では主に3つの課題と解決策が紹介されています。

1.  **期待するツールを呼んでくれない**:
    *   **課題**: LLMに提示したツールリストの中から、ユーザーの発話内容に応じて適切なツールを選んで実行させるのが難しい。システムプロンプトが複雑・長大になると、LLMがコンテキストを忘れることがある。
    *   **解決策**: システムプロンプトでツールの呼び出しタイミングを具体的に指示するだけでなく、ユーザーの発話内容をLLMに送る際に「動的プロンプト」として会話の状態に応じた追加情報や呼び出しルールを付与する。これにより、LLMのツール実行精度と情報理解度が向上します。

2.  **ツール実行後のLLMの動作を制御できない**:
    *   **課題**: ツールが実行された結果に基づいて、LLMに特定の返答生成や後続アクション（例：失敗時の謝罪と電話終了）を確実に実行させることが難しい。
    *   **解決策**: ツールの返却値に`ai_instruction`というフィールドを追加し、LLMがツールの結果をどのように扱うべきかを明示的に指示します。この指示はシステムプロンプトや動的プロンプトにも含めることで、LLMが指示を忘れずに意図した挙動をすると筆者は指摘します。

3.  **実行が遅い**:
    *   **課題**: Function Callingは、LLMの判断、ツール実行、ネットワークレイテンシー、結果解釈という追加ステップを伴うため、通常の会話よりも処理が遅延する。
    *   **解決策**: 遅延の原因（LLM判断、ネットワーク遅延、ツール実行速度、結果からの回答生成）を特定し、それぞれに応じた改善策を講じます。最も効果的なのはツールの呼び出し回数を減らすことであり、シンプルなバリデーションなどはLLM単独に任せることで速度と品質のトレードオフを検討することを推奨しています。

筆者は、LLMを思い通りに動かすためには「一番新しいコンテキストに指示を込める」ことが重要であると結論付け、これらの知見がFunction Callingを使いこなす上での鍵となると強調しています。これは、AIエージェントを開発するウェブアプリケーションエンジニアにとって、実装上の具体的なヒントとなるでしょう。