## 卓上サイズでVRAM 128GB搭載ミニPC、ASUS「ASCENT GX10」を遊び尽くしてみた

https://pc.watch.impress.co.jp/docs/column/nishikawa/2072125.html

Blackwell世代のGPUと128GBの広大なVRAMを備えたミニPC「ASCENT GX10」の検証を通じ、ローカル環境における超巨大モデルの実行とマルチモーダルなワークフローの優位性を実証する。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 83/100 | **Overall**: 84/100

**Topics**: [[ASCENT GX10, Blackwell, VRAM 128GB, ローカルLLM, マルチモーダル]]

ASUSの「ASCENT GX10」は、NVIDIA DGX Spark互換のアーキテクチャを採用した、卓上サイズのAI特化型ミニPCである。本記事では、著者がBlackwell世代のGPU（GB10）と128GBのユニファイドメモリという特異なスペックを活かし、最新の生成AIスタックをローカル環境でどこまで実用的に回せるかを詳細に検証している。

著者がまず注目したのは、Blackwellアーキテクチャの特権である新演算フォーマット「FP4」の活用だ。画像生成インターフェース「ComfyUI」において、カスタムノード「Nunchaku」を導入することで、Qwen-Imageの生成時間を17.08秒から7.89秒へと大幅に短縮させている。推論速度そのものはGeForce RTX 5090と比較して約3分の1程度（RTX 5060 Ti相当）に留まるものの、著者はこれを「十分実用レベル」と評価している。

このデバイスの真価は、計算速度よりもその圧倒的なVRAM容量（128GB）にある。一般的なハイエンドGPU（RTX 5090の32GBなど）では不可能な、1,000億パラメータを超える超巨大LLM（gpt-oss-120bなど）を全てVRAM上にロードして実行できる点が最大のメリットだ。筆者はさらに、この広大なメモリ空間を活かした「マルチモーダルな同時実行ワークフロー」を提案している。LLM（Prompt拡張用）とVLLM（画像解析用）、さらに画像生成モデル（Z-Image-Turbo等）を同時にメモリへ保持し、プロンプトの自動拡張から画像生成までを一気通貫で行うデモを披露した。この際、使用VRAMは60GBを超えており、コンシューマー向けGPUでは到達不可能な領域での「ローカル完結型AIエージェント環境」の可能性を示唆している。

また、最新の音声合成モデル「T5Gemma-TTS」を用いた声のクローニング検証も行っており、LLM、画像、動画、音声の全てを一台でこなす「オールマイティなAIワークステーション」としての実力が高く評価されている。約60万円という価格設定について、著者は「何に使いたいか」が重要であるとしつつも、巨大なLLMをローカルで動かしながら他の生成AIタスクを並行して回せる唯一無二の価値に、強い購買意欲を抱くに至っている。Webアプリケーションエンジニアにとっても、AIエージェントのローカル開発や重いモデルの検証環境として、従来のGPUサーバーやMacBook Proに代わる有力な選択肢となるだろう。