## ChatGPT Atlasにおけるプロンプトインジェクション対策の継続的強化

https://openai.com/index/hardening-atlas-against-prompt-injection/

**Original Title**: Continuously hardening ChatGPT Atlas against prompt injection attacks

強化学習を用いた高度な自動レッドチーミングにより、ブラウザ操作を行うAIエージェント「ChatGPT Atlas」をプロンプトインジェクション攻撃から保護する継続的な取り組みを公開した。

**Content Type**: 📰 News & Announcements
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 82/100 | **Annex Potential**: 80/100 | **Overall**: 80/100

**Topics**: [[Prompt Injection, AI Agents, Red Teaming, Reinforcement Learning, Cybersecurity]]

OpenAIは、ブラウザ上でクリックやキー入力などのアクションを代行する「ChatGPT Atlas」のセキュリティを強化するため、強化学習（RL）を導入した自動レッドチーミング体制を構築した。AIエージェントがWebページやメールの内容を直接処理する「ブラウザ内エージェント」というパラダイムにおいて、外部の悪意ある指示が正規のユーザー指示を上書きするプロンプトインジェクションは、従来のフィッシングや脆弱性攻撃を超える重大な脅威となっている。

著者は、この脅威に対処するために「自動攻撃LLM」を開発。この攻撃者は、シミュレーター上で自らの攻撃が成功したかどうかを試行錯誤し、推論ステップを繰り返すことで、人間によるレッドチーミングでは発見できなかった長期的で複雑な攻撃手法（例：メールの要約中に、偽の指示に従って退職届を送信させる等）を自律的に発見する。OpenAIは、この攻撃者に対してモデルを敵対的学習させる「プロアクティブ・ラピッド・レスポンス・ループ」を構築しており、発見された脆弱性に基づいた新しい防御モデルを既に全Atlasユーザーに展開している。

ウェブアプリケーションエンジニアにとって、この報告はAIエージェントの実装における「信頼境界」の定義に重要な示唆を与える。著者は、プロンプトインジェクションは完全に「解決」される課題ではなく、詐欺やソーシャルエンジニアリングのように永続的に続く「いたちごっこ」であると主張している。そのため、システム側での防御に加え、(1) 必要時以外のログイン状態の制限、(2) 重要なアクション（送金、送信等）における人間による承認の必須化、(3) 抽象的すぎる指示（「メールを見てよしなにやって」等）を避けるといった、設計レベルでの多層防御を推奨している。エージェントがブラウザという強力な権限を持つ環境において、攻撃コストを継続的に高めていくことが実世界でのリスク低減に不可欠であると結論付けている。