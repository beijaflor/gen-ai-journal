## Anthropicがデータ利用方針をオプトアウト方式へ変更するよ

https://zenn.dev/shirochan/articles/476419f488669b

AnthropicはClaudeの会話データ利用方針をオプトインからオプトアウトへ変更し、ユーザーが明示的に拒否しない限りモデル学習に利用する体制へ移行した。

**Content Type**: News & Announcements

**Scores**: Signal:5/5 | Depth:2/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 85/100 | **Annex Potential**: 78/100 | **Overall**: 76/100

**Topics**: [[AIプライバシー, データガバナンス, 利用規約変更, Claude, AIモデル学習]]

Anthropicが提供するAIアシスタントClaudeのデータ利用方針が、2025年8月29日の規約更新により「オプトイン方式」から「オプトアウト方式」へと大きく変更されました。これまではユーザーが明示的に同意しない限り会話データはモデル学習に利用されませんでしたが、今後は明示的に拒否設定を行わない限り、自動的に会話データがAIモデルの改善に使用されることになります。

この変更は、特に業務でClaudeを利用するウェブアプリケーションエンジニアにとって重要な意味を持ちます。データガバナンスやプライバシー保護の観点から、企業情報や機密性の高いコードスニペットなどが意図せずモデル学習に利用されるリスクが高まるためです。明示的なオプトアウトを行わない場合、同意した会話データは最長5年間保持される可能性があり、厳格なデータ管理が求められる開発現場では見過ごせない影響があります。

この新たなデフォルト設定により、ユーザーは自らのデータプライバシーを維持するために、Claudeのデータプライバシー設定ページ（claude.ai/settings/data-privacy-controls）を能動的に確認し、「Claudeの改善にご協力ください」の項目を適切に設定する喫緊の必要性があります。開発者は、自身のワークフローと企業ポリシーに合致するよう、直ちに設定を見直すべきです。この変更はClaude Free/Pro/Maxプランが対象であり、ビジネス向けサービスは対象外ですが、個人利用でも注意が必要です。