## プロンプトは「お願い」ではなく「コード」。論理式を応用した「公理系」プロンプトエンジニアリング

https://qiita.com/makotosaekit/items/031bf2a5b62050e3ca99

プロンプトを論理式に基づいた「公理系」として設計し、大規模言語モデル（LLM）をシステムとして扱うことで出力の精度と安定性を劇的に向上させます。

**Content Type**: Tutorial & Guide

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 88/100 | **Annex Potential**: 85/100 | **Overall**: 84/100

**Topics**: [[プロンプトエンジニアリング, 論理的思考, 公理系プロンプト, LLMの制御, 開発ワークフロー]]

AIへの指示を単なる「お願い」ではなく「コード」として捉え、論理式に基づいた「公理系プロンプトエンジニアリング」を適用することで、大規模言語モデル（LLM）の出力精度と安定性を飛躍的に向上させる手法が解説されています。ウェブアプリケーションエンジニアにとって、LLMを曖昧な対話相手ではなく、仕様通りに動作すべきシステムとして扱うこの視点は極めて重要です。

このアプローチは、プロンプトを「前提」「定義」「公理」というモジュールに構造化します。これにより、変更があってもプロンプト全体を読み解く必要なく特定部分の修正で済むため、システムの保守性と再利用性が格段に向上します。例えば、記事要約プロンプトの具体例では、記事のテーマに応じて専門家向けか初心者向けかを明確な公理で定義し、AIにルールブックとして従わせることで、意図通りの要約スタイルを安定して引き出せることを示します。

また、指示のロジックと出力スタイルを分離することで、LLMがプロンプト全体の文体に影響され、意図しないトーンで出力してしまう問題を効果的に回避できます。厳密な指示によって「一発OK」の確率が高まり、冗長な説明を避けることで、結果的にトークン消費量の節約にもつながります。

重要な注意点として、ゲームの「必勝法」にあたる「定理」をプロンプトに含めるべきではないと警鐘を鳴らします。定理を記述すると、AIは柔軟性を失い、特定の思考経路に固執する「馬鹿」な挙動を示すようになるためです。

複数の学術論文も、構造化されたプロンプトや記号的推論がLLMの論理的推論プロセスや精度、文脈認識能力を向上させるという研究結果を提示しており、この公理系プロンプトエンジニアリングの有効性を強力に裏付けています。

この手法を採用することで、エンジニアはAIをより信頼性の高い「動く仕様書」として活用し、開発ワークフローにおけるLLMとの連携を劇的に改善できるでしょう。