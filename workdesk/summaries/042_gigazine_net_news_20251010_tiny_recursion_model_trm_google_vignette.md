## わずか700万パラメーターでGemini 2.5 Proを打ち負かす脅威の小型AIモデル「Tiny Recursion Model(TRM)」をSamsungの研究者が開発

https://gigazine.net/news/20251010-tiny-recursion-model-trm/#google_vignette

Samsungの研究者が開発した「Tiny Recursion Model (TRM)」は、わずか700万パラメーターでGemini 2.5 Proを超える性能を示し、大規模モデルに依存しない新たなAI開発の方向性を提示します。

**Content Type**: Research & Analysis

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 93/100 | **Overall**: 92/100

**Topics**: [[小型AIモデル, 再帰的推論, LLMベンチマーク, 効率的なAI学習, AI開発パラダイム]]

Samsungの研究者Alexia Jolicoeur-Martineau氏が、わずか700万パラメーターの小型AIモデル「Tiny Recursion Model (TRM)」を開発し、その研究成果が注目されています。TRMは、人間の脳の階層的推論から着想を得ながらも、生物学的構造への過度な依存を取り除いた「再帰的推論」という革新的な手法を採用しています。この小型モデルは、AIの知能を測るベンチマークであるARC-AGI-1およびARC-AGI-2において、GoogleのGemini 2.5 Pro 32Kを含む複数の大規模言語モデルを凌駕する性能を発揮しました。

Webアプリケーションエンジニアにとって、この開発は極めて重要な意味を持ちます。TRMは、4台のH100 GPUを用いて2日間で500ドル未満という非常に低いコストでトレーニング可能であり、大規模AIモデルの運用にかかる高額なインフラ費用やAPI利用料に一石を投じます。これは、限られたリソース下でも高性能なAI機能をWebサービスに統合できる可能性を広げ、開発者がよりコスト効率よく、AIを活用したアプリケーションを構築するための新たな道筋を示します。

さらに、小型モデルであるTRMの成功は、「難しいタスクには大規模モデルが必須」という従来のパラダイムを打ち破ります。これにより、Webアプリケーションのバックエンドだけでなく、ブラウザやエッジデバイス上で動作するクライアントサイドAIの実装も現実味を帯びてきます。リアルタイム処理やデータプライバシー保護が求められるWebサービスにおいて、TRMのような効率的なモデルは、新たなUXや機能提供の可能性を拓くでしょう。この研究は、LLMへの過度な集中から脱却し、AI開発の多様な方向性を再考するきっかけを与えます。