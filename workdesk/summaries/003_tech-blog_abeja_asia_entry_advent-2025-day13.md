## LLMに「謎解き」はできるのか？

https://tech-blog.abeja.asia/entry/advent-2025-day13

大規模言語モデルは「ひらめき」が必要な謎解きタスクで苦戦するものの、思考過程を明示的に出力させることでその正答率が飛躍的に向上することを示唆した。

**Content Type**: Research & Analysis
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 84/100 | **Annex Potential**: 85/100 | **Overall**: 84/100

**Topics**: [[LLM能力評価, 推論能力, マルチモーダルAI, プロンプト戦略, AIベンチマーク]]

株式会社ABEJAの中西氏が、LLMが「ひらめき」を要する謎解きクイズにどこまで対応できるかについて検証結果を報告しています。一般的な推論能力が進化した最新LLMでも、著者が趣味とする脱出ゲームのような非連続な思考転換を必要とするタスクは苦手とするのではないか、という疑問から、自作の画像形式謎解きベンチマーク（10問の基本問題と2問の応用問題）を主要なマルチモーダルLLMに解かせています。

謎解きには、単なるテキスト解析を超えた高度なマルチモーダル理解、常識を打破する非連続な推論、そして論理を深く掘り下げすぎずに思考をリセットする柔軟性が求められます。検証では、GPT-4o、GPT-5シリーズ、Geminiシリーズ、Claudeシリーズが対象となり、画像と共通のプロンプトに加え、解答に至る「思考過程（reason）」を出力させるか否か、および推論の「努力度（reasoning_effort: high/low/none）」をパラメータとして設定し、その影響を分析しました。

検証結果のハイライトとして、Gemini 3 Pro Previewが最も安定して高い性能を示しました。特に注目すべきは、最新モデルであるGemini 3 Pro PreviewやGPT-5.1において、ベースライン（reasoning: none）では正答率が10〜20%と低迷していたのが、「reasoning_effortをHighに設定する」、または「理由も同時に出力させる」ことで、正答率が80〜90%に劇的に向上した点です。これは、謎解きのようなタスクが、LLMの潜在能力だけでは解けず、計算リソースを与えて「深く考える時間」を与えることで初めて解けるようになることを示唆しています。一方で、GPT-4oはreasoning設定が存在しないため、正答率は低迷しました。

しかし、この効果は基本問題に限られ、複雑な応用問題（11問目、12問目）については、思考過程で正解にかなり近いところまで迫るモデルはあったものの、どのLLMも最終的な解答には至りませんでした。特に、人間にとっての「ひっかけ」要素や、抽象的なメタファーの理解が鍵となる問題では、最新モデルでも苦戦する傾向が見られました。Geminiの思考過程は文字数が多く、日本語の謎解きでも英語で思考しているケースが4割ほど見られ、その多言語能力の特性が伺えます。

結論として、著者は「LLMに謎解きはできるのか？」という問いに対し、「基本的な問題なら思考過程の明示によって一定解けるようになってきた」と回答しています。LLMの推論能力は向上しているものの、「ひらめき」を要するタスクにおいては、その思考プロセスの制御が鍵であり、真の汎用的な知能にはまだ距離があることを示唆する興味深いベンチマークとなっています。