## Where AI is failing design systems, and where we are failing AI

https://bencallahan.com/where-ai-is-failing-design-systems

記事は、AIの確率的な性質がデザインシステムの決定論的な要求と衝突し、生産品質のコードやピクセルパーフェクトなデザインにおいて信頼性を損なっていると指摘します。

**Content Type**: Research & Analysis

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 89/100 | **Overall**: 92/100

**Topics**: [[デザインシステム, LLMの限界, コンテキストエンジニアリング, AIによるコード生成, 開発ワークフロー]]

「Where AI is failing design systems, and where we are failing AI」は、95名のデザインシステム実践者を対象とした調査データに基づき、AIとデザインシステムの統合における課題を深く掘り下げています。記事は、AIの確率的な性質が、安定性、高品質、耐久性といった決定論的な約束を要求するデザインシステムの本質と衝突している点を指摘します。これは、特に「生産品質のコード生成」や「ピクセルパーフェクトなデザインシステムへの準拠」といった収束的タスクにおいて、AIが信頼を損ねる原因となっています。

著者は、デザインシステムが「契約」であり、そのコンシューマーへの約束であると強調します。しかし、現在のLLMは「非常に速く、優れた推測屋」であるものの、その確率的な出力は、常に同じ結果を保証する決定論的なシステムが提供する「信頼性」や「セキュリティ保証」とは相容れません。この問題を解決するためには、モデルが出力する情報をより厳密に制御する「コンテキストエンジニアリング」が不可欠であり、これにはデータ、境界、指示、出力フォーマットなどを構築する複雑なシステムが必要となると述べられています。

調査結果によると、AIは「ブレインストーミング」「リサーチ支援」「使い捨てプロトタイプ作成」のような発散的タスクでは有効な支援を提供します。これらは、不正確さが許容され、むしろ創造性を刺激する領域です。しかし、「出荷可能なコードの生成」「デザインシステムの厳密な忠実性」「再現性」といった収束的タスクにおいては、AIの精度不足が顕著であり、組織の信頼を損なう結果に繋がっています。例えば、Figma Makeがデザインシステムを遵守しない、生成されたコンポーネントが疑わしいTypeScriptのプラクティスを含む、といった具体的な課題が挙げられています。

記事は、エンジニアに対し、AIがうまく機能する「探索・発見」や「要約・初稿作成」のタスクに注力しつつ、うまくいかない「デザインシステム遵守」や「本番コード生成」の領域では慎重に実験することを推奨します。具体的な対策として、「契約の明確化とテストの実施」「収束的タスクにおける厳格なチェック」「AI出力の信頼度測定」「より意図的なコンテキストの付与（例：スタイルガイドの適用）」を提案。最終的に、AIは「足場を作り、加速させ、提案する共同作業者」として扱うべきであり、「出荷する工場」ではないと結論付けています。これは、AIを活用する上で、人間のレビューとテスト、そして人間の課題解決能力が依然として重要であるという示唆を与えています。