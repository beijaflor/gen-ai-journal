## さくらインターネット、生成AI向け推論API基盤「さくらのAI Engine」を一般提供開始

https://www.sakura.ad.jp/corporate/information/newsreleases/2025/09/24/1968221046/

さくらインターネットが、生成AIの推論を容易にするAPI基盤「さくらのAI Engine」の一般提供を開始し、国内データセンターでの多様な基盤モデルとRAG機能の利用を可能にします。

**Content Type**: News & Announcements

**Scores**: Signal:5/5 | Depth:3/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 86/100 | **Annex Potential**: 80/100 | **Overall**: 80/100

**Topics**: [[生成AI推論API, RAG (検索拡張生成), 国内データセンター, 基盤モデル, アプリケーション開発]]

さくらインターネットは、生成AIの推論をアプリケーションに統合するためのAPI基盤「さくらのAI Engine」を2025年9月24日より一般提供開始しました。このサービスは、ウェブアプリケーションエンジニアが大規模言語モデル（LLM）や多様な基盤モデルを、インフラ構築の煩わしさなくAPI経由で迅速に組み込めるように設計されています。

「さくらのAI Engine」は、「さくらのクラウド」のコントロールパネルから利用可能で、チャット生成、音声認識、そして自社データを活用するための検索拡張生成（RAG）機能に必要なベクトルデータベース連携までをAPIで提供します。これにより、開発者は煩雑な環境構築やGPUリソース管理から解放され、アプリケーションのコア機能開発に集中できます。特にRAG機能は、企業が蓄積する膨大なドキュメントを活用した高精度なチャットボットやFAQシステムを、最小限の開発工数で実現できるため、ビジネス要件の迅速な実現に貢献します。

本サービスのもう一つの大きな利点は、さくらインターネットが運営する国内データセンターでサービスが完結することです。これにより、機密情報や個人情報の取り扱いにおいて国内法規遵守が求められる公共分野や金融機関など、高いセキュリティ要件を持つ企業でも安心して生成AIを導入できます。推論処理にはNVIDIA製高性能GPUが採用されており、複雑な生成AIタスクでも安定したパフォーマンスを保証します。

提供される基盤モデルには、gpt-oss-120bやQwen3-Coderシリーズ、日本語に特化したllm-jp-3.1-8x13b-instruct4などが含まれ、用途や性能要件に応じて最適なモデルを選択できる柔軟性も持ち合わせています。料金体系も無償プランと従量課金プランが用意されており、小規模な検証から大規模な本番運用まで、幅広いニーズに対応します。「さくらの生成AIプラットフォーム」が「さくらのAI」へと名称変更され、その中核を担う「さくらのAI Engine」は、今後の生成AI活用ビジネス拡大に向けた重要なステップとなるでしょう。この発表は、国内のウェブアプリケーション開発者が生成AIをより手軽に、かつ安全に自社サービスへ統合するための強力な推進力となります。