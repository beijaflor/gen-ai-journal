## LLMに「謎解き」はできるのか？

https://tech-blog.abeja.asia/entry/advent-2025-day13

最新のマルチモーダルLLMが「ひらめき」を要する謎解きクイズをどこまで解けるか、自作ベンチマークを用いて詳細に検証し、その推論能力の限界と特性を明らかにした。

**Content Type**: Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 77/100 | **Annex Potential**: 78/100 | **Overall**: 76/100

**Topics**: [[LLM推論能力, マルチモーダルLLM, プロンプトエンジニアリング, ベンチマーク, 思考過程分析]]

本記事は、進化が著しいLLM・生成AIの推論能力（リーズニング）に焦点を当て、特に「ひらめき」や「発想の転換」が求められる謎解きクイズをどこまで解けるかを検証した。著者は、論理的パスが明確な数学やプログラミング問題と異なり、謎解きは高度なマルチモーダル理解、常識の打破、非連続な推論を要求すると指摘する。

検証にあたり、著者は全12問の画像形式の自作謎解きベンチマーク「riddle-benchmark」を公開。GPT-4o、GPT-5シリーズ、Geminiシリーズ、Claudeシリーズといった主要なマルチモーダルLLMを対象に、API経由で画像をアップロードし、同一プロンプトで複数回解答させる方式を取った。特に、「reason有無」（思考過程の出力）と「reasoning_effort」（推論にかける努力レベル）のパラメータがLLMの性能にどう影響するかを分析している。

検証結果のハイライトとして、Gemini 3 Pro-previewやGPT-5.1-2025-11-13といった最新モデルは、reasoning_effortを`High`に設定することで、正答率がベースラインの10-20%から80-90%へと劇的に向上したことが挙げられる。この結果は、謎解きのようなタスクにおいて、モデルに「深く考える時間（計算リソース）」を与えることが、その潜在能力を引き出す上で極めて重要であることを示唆している。また、Gemini 3 Proでは、reasoning_effortが低めでも、reasonを同時出力させることで精度が大きく向上することも確認された。一方で、reasoning設定を持たないGPT-4oは低い正答率に留まり、難易度の高い11問目と12問目はどのモデルもほとんど解けなかった。

詳細な分析では、LLMが単純な連想に囚われやすい問題（例：005の「いちご」）や、抽象的なメタファー認識（例：009の「硬貨」）に苦戦する様子が示された。特にGeminiは思考過程を英語で記述する傾向があり、その文字数の多さや安定した性能から、日本語の謎解きでも英語での内部処理が効果的である可能性が示唆された。難解な問題では最終的な解答には至らなくとも、Gemini 3 Proの思考過程が正解にかなり迫っていたことから、高度な視覚理解と段階的な論理は持ち合わせているものの、最後の「ひらめき」や非線形な飛躍に課題があることが窺える。

著者は、「LLMに謎解きはできるのか？」という問いに対し、「基本的な問題なら一定解けるようになってきた」と結論付けている。しかし、複雑な「ひらめき」を要する謎解きは依然としてLLMにとって大きな挑戦であり、今後AIの推論能力の進化を測るための新たなベンチマークとなり得ると展望している。ウェブアプリケーションエンジニアにとって、これはLLMをシステムに組み込む際に、単純な論理的推論を超えたタスクではプロンプト設計やモデル選択に戦略的なアプローチが必要であることを示唆し、特に計算リソースと推論精度のトレードオフを考慮する重要性を強調する。