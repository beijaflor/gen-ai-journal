## AIキャスターによるyoutubeの政治デタラメ動画による情報が拡散してた

https://nou-yunyun.hatenablog.com/entry/2026/01/22/170000

AIを用いた政治的デマ動画の拡散事例を分析し、自動生成技術が世論操作に悪用される実態を報告する。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 74/100 | **Annex Potential**: 76/100 | **Overall**: 76/100

**Topics**: [[生成AI悪用, デマ拡散, コンテンツモデレーション, AIキャスター, 音声合成]]

本記事は、YouTubeチャンネル「**Mix Facts**」を事例に、**AIキャスター**を悪用した政治的デマ動画の拡散メカニズムを詳細に分析しています。当該チャンネルは、アカウント売買を経て1日に20本以上という人間には不可能なペースで動画を投稿しており、**生成AI**による動画量産体制がデマの拡散に直結している実態を浮き彫りにしています。

技術的な着眼点として、複数のチャンネル間で**VOICEVOX**による読み上げ原稿が使い回されている点や、アクセントの違和感、日付の誤認といった自動生成特有の欠陥が具体的に指摘されています。また、かつて人気だったチャンネルを再利用することで、既存の信頼（登録者数や実績）をデマのブースターとして利用する狡猾な運用手法についても言及されています。筆者は、これらの動向を金銭目的または政治的扇動を目的とした「仕組まれたデマ」であると断定しています。

生成AIが情報の真偽判定を困難にする中、開発者は**コンテンツの整合性チェック**や**不正検出アルゴリズム**の重要性を再認識させられます。**AI Safety**や**コンテンツモデレーション**、またはSNSプラットフォームの信頼性向上に取り組むエンジニアにとって、技術が悪用される現場の具体的パターンを知るための重要な事例報告です。