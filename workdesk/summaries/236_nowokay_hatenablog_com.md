## Qwen3-TTSに自分の声でしゃべらせる

https://nowokay.hatenablog.com/entry/2026/01/23/145128

オープンソースの音声合成モデル**Qwen3-TTS**を用いて、日本語の読み上げ精度や音声クローン、音声デザイン機能をローカル環境で検証する。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:3/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 72/100 | **Annex Potential**: 70/100 | **Overall**: 72/100

**Topics**: [[Qwen3-TTS, 音声合成 (TTS), 音声クローン, ローカルLLM, オープンソースモデル]]

オープンソース化されたテキスト読み上げ（TTS）モデル**Qwen3-TTS**をWindowsのローカル環境で動作させ、日本語の対応状況や音声クローンの実用性を検証したレポートです。**qwen-tts**ライブラリの導入手順から、**GPU（PyTorch）**対応における注意点、**mps**デバイス指定によるMacでの動作など、セットアップに関する実践的な情報がまとめられています。

検証では、特定のプリセット話者を選べる**CustomVoice**、音声クローンが可能な**Base**、声質を指示できる**VoiceDesign**の3つのモデルを使い分けています。特筆すべき点として、**Base**モデルによる音声クローンは、リファレンス音声に多くの音素（無声子音、長音、促音など）を含めることで再現度が劇的に向上し、話者特有の癖まで自然に再現できることが示されています。また、**VoiceDesign**では「female voice」といったプロンプト指定でアニメ声のような声質変化が可能です。Windows環境における**flash-attn**や**SoX**の依存関係に関するトラブルシューティングなど、実際に手を動かす際に直面する課題についても触れられています。

ローカル環境で高品質な音声合成やクローン機能をアプリケーションに統合したい開発者や、**Qwen**エコシステムのマルチモーダル展開に関心のあるエンジニアに最適な内容です。