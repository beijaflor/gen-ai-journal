## LLMはバンディット問題を解けるか

https://developers.cyberagent.co.jp/blog/archives/61239/

LLMによる多腕バンディット問題の解決能力を検証し、現状のモデルでは探索と活用のトレードオフを戦略的に扱うことが困難であることを明らかにする。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 84/100 | **Annex Potential**: 85/100 | **Overall**: 84/100

**Topics**: [[バンディット問題, 強化学習, Gemini 2.5, 意思決定エージェント, アルゴリズム比較]]

サイバーエージェントのAI Labによる、LLM（Gemini 2.5 Flash Lite）が多腕バンディット問題（MAB）を解けるかを検証した実験レポートである。MABは「探索と活用のトレードオフ」を最適化する逐次的意思決定タスクであり、推薦システムや広告配信などエンジニアにとって馴染み深い課題だ。本記事では、理論的ベースラインであるThompson Sampling（TS）と比較し、LLMが履歴データをテキスト形式で受け取って次に選ぶべき「腕」を判断する際の結果を分析している。

結論として、LLM単体での意思決定は従来のバンディットアルゴリズムの性能に及ばないことが示された。TSが累積後悔（Regret）を理想的な対数オーダー（log T）に抑えたのに対し、LLMは線形に増加し続け、最適な選択に収束しない挙動を見せた。著者はこの原因として、LLMが「不確実性（Uncertainty）」を確率分布として内部的に管理し、それを戦略的な「探索」に変換する仕組みを内在していないことを指摘している。LLMにとってランダム性は戦略的なツールではなく単なるノイズとして処理されがちであり、その結果、初期に得られた限定的な成功に固執して十分な探索を行わない、あるいは根拠なく腕を切り替えるといった不安定な挙動を招いている。

エンジニア視点での重要性は、LLMをエージェントの意思決定器として採用する際の「限界」がデータで示された点にある。最新のLLMであっても、統計学的な最適化が求められる逐次判断においては、伝統的なアルゴリズムを代替するのではなく、むしろそれらと組み合わせる、あるいはLLMに統計情報を解釈させるための追加レイヤーが必要であることを示唆している。推論コストやレイテンシといった実務上の制約も考慮すると、LLMを直接バンディットエンジンとして運用するのは現時点では時期尚早であり、LLMの推論能力をどのように統計的最適化フレームワークに組み込むかというハイブリッドなアプローチこそが現実的であるというのが筆者の提示する takeaway である。