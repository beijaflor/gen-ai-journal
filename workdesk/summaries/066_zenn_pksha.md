## なぜAIは会話を重ねると間違えるのか：マルチターン対話の落とし穴と実用化への示唆

https://zenn.dev/pksha/articles/6f38eac49db885

研究は、LLMがマルチターン対話において文脈を見失い、初期の間違いに固執することで、シングルターンに比べ性能が大幅に低下する傾向を定量的に明らかにしました。

**Content Type**: Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 83/100 | **Annex Potential**: 84/100 | **Overall**: 84/100

**Topics**: [[マルチターン対話, LLM評価, AIエージェントアーキテクチャ, コンテキスト管理, 生成AIの限界]]

PKSHA Technologyの原田氏が、論文「LLMS GET LOST IN MULTI-TURN CONVERSATION」を紹介し、LLMがマルチターン対話で性能を著しく低下させる現象とその原因、実用化への示唆を深く掘り下げています。LLMの性能評価はシングルターンベンチマークが主流ですが、実際のユースケースではマルチターン対話が不可欠であり、その評価手法は未確立でした。

本研究は、既存ベンチマークから引用した「完全に明確な指示」を複数の「シャード」に分割し、LLMがユーザーの指示を段階的に明確化していく対話をシミュレートする独自の手法を提案しました。ユーザーシミュレーターが各ターンでシャードを一つずつ小出しに提示し、アシスタントLLMの応答を評価します。これにより、従来のシングルターン評価（FULL）、全シャードを一度に与える評価（CONCAT）、シャードを段階的に与える評価（SHARDED）、さらに介入策として最終ターンで全シャードを再提示する（RECAP）、毎ターン全シャードを繰り返す（SNOWBALL）の5種類のシミュレーションを比較しています。

実験結果は、テストした全てのLLMにおいて、マルチターン対話（SHARDED）の性能がシングルターン（FULL）と比較して平均39%も大幅に低下することを示しました。この性能低下は、シャード化による指示の言い換えではなく、「マルチターン」という対話形式そのものに起因し、モデルの能力や規模に依存しない普遍的な現象であることが明らかになりました。特に注目すべきは、LLMが対話の初期段階で間違った仮説を立てると、それに固執して軌道修正が困難になる「迷子現象」です。この現象は、モデルの「適性（Aptitude）」の低下よりも「非信頼性（Unreliability）」の急増に起因することが示されました。

著者は、この「迷子現象」が起こりやすいタスクの条件として、「生成的タスクであること」「複数のシャードに分割できる程度に複雑であること」「新しい情報によってそれまでの回答全体を根本から見直す必要がある、分解不可能なタスクであること」の3点を挙げています。一方で、翻訳のような「エピソード的」で分解可能なタスクでは、性能低下は見られませんでした。

本論文は、LLM本体の能力向上だけでなく、アプリケーション側での高度な制御方法の探求が、マルチターン対話システムの実用化には不可欠であると結論付けています。開発者はLLMのデフォルトの振る舞いに頼るのではなく、その弱点を補うアーキテクチャを設計することの重要性を改めて示唆しています。