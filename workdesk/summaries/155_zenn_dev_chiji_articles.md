## Claude Code vs Codex vs Cursor ― 同じプロンプトでSlackクローンを生成したらちぢ🥇Claude Code vs Codex vs Cursor ― 同じプロンプトでSlackクローンを生成したら

https://zenn.dev/chiji/articles/9412e21dfce923

主要なAIコーディングエージェントにSlackクローン開発を指示し、コード品質、バグの有無、UI/UX、創造性に基づいて性能を詳細に比較評価した結果、Codex (GPT-5-Codex)が最も優れた成果を上げたことを特定する。

**Content Type**: ⚙️ Tools

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 86/100 | **Annex Potential**: 84/100 | **Overall**: 84/100

**Topics**: [[AIコーディングツール比較, エージェントベース開発, Next.js, Convex, コード生成品質]]

ウェブアプリケーション開発者が直面するAIコーディングツールの選択課題に対し、この記事では主要なAIコーディングエージェントの性能を実践的に比較評価しています。Next.js、Convex、Ultraciteを用いたSlackクローンアプリの開発を共通プロンプトで指示し、「エラーやバグの数」「UI/UX」「アバウトな指示への創造性」を評価軸としました。

比較の結果、**Codex (GPT-5-Codex)**が最も優れた結果を示しました。Codexは、エラーやバグが一切なく、ワンショットで完成度の高いコードを生成。既存の認証画面やメタデータまで適切に修正し、ユーザー表示名変更バナーの提示などUXへの配慮も見られました。機能はミニマルながら、未実装の機能について具体的なNext-Stepを提案する点も高評価です。

一方、**Claude Code (Sonnet 4)**もエラーなしのワンショットで生成しましたが、ユーザー名表示のバグやメッセージ反映のラグといった軽微な問題が残りました。**Cursor Agents (Auto)**は、多機能な実装を試みるあまり、多くの型エラーやConvexスキーマエラーが発生し、記載された機能一覧と実際の機能に乖離が見られました。

この比較は、AIエージェントが「曖昧で大きな指示に対しては、タスクの細分化が不十分になり、バグの多いコードを生成しやすい」という重要な示唆を与えます。また、SWE-benchのようなベンチマークで高成績を収めるAIが、必ずしも実践的なワンショットコーディングで優れているわけではないことも示されました。ウェブエンジニアにとって、利用するAIエージェントの性能は常に変化するため、特定のツールに固執せず、流行や要件に応じて最適なツールを選択することの重要性を強調しています。コミュニティの活発さもツール選択の重要な要素です。