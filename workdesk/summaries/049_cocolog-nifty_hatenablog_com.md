## AI で日本語の長文を校正する

https://cocolog-nifty.hatenablog.com/entry/2025/12/22/124436

50万文字に及ぶ長大な日本語原稿の校正を、Gemini CLIとAI生成スクリプトを活用して一括自動化する効率的なワークフローを提案する。

**Content Type**: 📖 Tutorial & Guide
**Language**: ja

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 86/100 | **Annex Potential**: 84/100 | **Overall**: 84/100

**Topics**: [[校正, Gemini CLI, Python, ワークフロー自動化, LLMプロンプト]]

著者の山下泰平氏は、50万文字という膨大な原稿を執筆する際、執筆中の脳のリソースを「内容の構築」に最大限割り振るため、あえて誤字脱字を一切気にせず書き進めるという戦略を採った。この手法は、誤字脱字の修正をAIに全面的に委ねることで、人間の創造性を阻害する低次のノイズを排除することを目的としている。

具体的な技術的アプローチとして、著者はAIを単なる対話相手としてではなく、構造化データを生成し処理する自動化パイプラインの一部として活用している。まず、AIに対して「校正結果を原文、修正案、修正理由の3要素を含むJSON形式で出力する」ためのプロンプトを設計。さらに、そのJSONデータを読み取って原稿ファイルを一括置換するPythonスクリプト自体もAIに生成させている。スクリプトの実装においては、実務的な安全性を確保するためにDry-run（試行）機能やバックアップ作成、エラー検知機能を組み込む重要性を説いている。

実際のワークフローでは、ClaudeやChatGPTでプロンプトを洗練させた後、最終的な大量処理にはGemini CLIを採用している。これはWeb UIでの手動操作を避けて効率化を図ると同時に、コストを抑えるための現実的な選択である。現在のLLMの制約として、数万文字を超える入力を一度に処理しようとすると精度が低下したり暴走したりするリスクがあるため、章単位や2000文字程度のチャンクに分割して処理し、複数回のパスを回すことで「もう誤字はない」という状態まで追い込む手法を提示している。

筆者が強調しているのは、AIによる校正が「完璧」であることではなく、電力と計算資源を力技で投入することで、人間の脳を消耗させずに「そこそこの精度」を雑に得る価値である。執筆時に「後でAIが直してくれる」という確信を持つことは、大規模なコンテンツ制作における認知負荷のマネジメントとして極めて有効である。この知見は、ドキュメンテーションや技術記事の執筆に携わるエンジニアにとっても、AIを自動化スクリプトと組み合わせた「データのパイプライン」として再定義する実用的なガイドとなっている。