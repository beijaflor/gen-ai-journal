## Google、「Gemma 3」ベースの翻訳特化モデル「TranslateGemma」公開　日本語含む55言語に対応

https://www.itmedia.co.jp/aiplus/articles/2601/16/news073.html

Googleが、最新のオープンモデル「Gemma 3」を基盤に翻訳タスクへ最適化を施した「TranslateGemma」を公開し、軽量モデルながら大規模モデルを凌駕する翻訳精度とマルチモーダル対応を実現した。

**Content Type**: 📰 News & Announcements
**Language**: ja

**Scores**: Signal:5/5 | Depth:3/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 76/100 | **Overall**: 76/100

**Topics**: [[Gemma 3, TranslateGemma, 翻訳モデル, エッジAI, Google Cloud]]

米Googleは1月15日、最新のオープンモデル「Gemma 3」をベースとした翻訳特化型のモデルファミリー「TranslateGemma」を発表しました。このモデルは日本語を含む55言語に対応しており、4B（40億）、12B（120億）、27B（270億）の3つのパラメータサイズで提供されます。最大の特徴は、翻訳タスクに特化したファインチューニングにより、モデルサイズを抑えつつ極めて高いパフォーマンスを実現した点にあります。Googleの測定によれば、12BサイズのTranslateGemmaは、ベースモデルである27BサイズのGemma 3よりも高い翻訳精度（MetricXスコア）を記録しており、同一サイズのベースモデルと比較してエラー率を約26%低減させています。

Webアプリケーションエンジニアにとっての重要なポイントは、用途に応じたデプロイ戦略の柔軟性です。4Bモデルはモバイルやエッジデバイス、12Bモデルは一般的なノートPCでのローカル実行をターゲットとしており、27Bモデルはクラウド環境での「最大忠実度」モデルとして位置づけられています。また、本モデルはGemma 3のマルチモーダル能力を継承しているため、画像内のテキスト翻訳精度も向上しており、マルチモーダル翻訳ベンチマーク「Vistra」において既存のオープンモデルを上回る性能を示しています。

著者は、本モデルの狙いを「高品質な翻訳を、より小さなモデルサイズで実現すること」にあると述べています。これは開発者が、商用APIによるコストやレイテンシ、プライバシーの制約を回避しつつ、高精度な多言語機能をアプリケーションに組み込めることを意味します。特に、12Bモデルが倍以上のサイズを持つ汎用モデルの精度を上回ったという事実は、特定ドメインにおける「小型特化型モデル」の有用性を強く裏付けるものです。現在、Hugging FaceやKaggle、Google CloudのVertex AIを通じて、開発者が自前の環境やクラウドに即座にデプロイ可能な状態で提供されています。