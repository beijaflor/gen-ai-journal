## Sakana AI 秋葉氏が解き明かす、「本番で戦えるAIエージェントの作り方」W&B Fully Connected公演

https://zenn.dev/olemi/articles/2ae97d8ce4fe2a

Sakana AIの秋葉氏が、実用的なAIエージェントを構築するための「推論時スケーリング」と「ドメイン知識の活用」という二つの鍵を解説します。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 86/100 | **Annex Potential**: 84/100 | **Overall**: 84/100

**Topics**: [[AIエージェント開発, LLM推論最適化, ドメイン知識活用, 自動コード生成, 評価基準設計]]

本記事は、Sakana AIのリサーチャー秋葉氏が「W&B Fully Connected」で講演した「本番で戦えるAIエージェントの作り方」の要点をまとめたものです。講演では、AIエージェントが簡単な自動化を超え、専門家レベルの高度な業務を遂行するための具体的な開発手法が紹介されました。

まず、Sakana AIが開発した専門家レベルのAIエージェント事例として、「The AI Scientist」（全自動科学研究・論文執筆）、「AE-Agent」（複雑な組合せ最適化問題のアルゴリズム設計）、そして「ShinkaEvolve」（自己進化による強力なエージェント自動生成）の3つが挙げられ、これらが国際的な評価を得ていることが示されました。

これらの成功の裏にある「決め手」として、秋葉氏は以下の2つの鍵を解説しています。

1.  **推論時スケーリング**
    LLMの性能を最大限に引き出すためのアプローチです。
    *   **Repeated Sampling**: 同じプロンプトでLLMを複数回実行し、生成された多数の解答から最も優れたものを選択するシンプルな手法。これにより正解率が劇的に向上する「量質転化」が実現します。
    *   **AB-MCTS (Adaptive Branching Monte Carlo Tree Search)**: 多様な解を広く探索する「go wide」と、有望な解を深く掘り下げて改良する「go deep」という二つの戦略を状況に応じて適応的に切り替えるアルゴリズムです。複数の異なるLLMを組み合わせることで、単体LLMを超える性能達成も可能になります。

2.  **ドメイン知識の活用**
    対象分野の専門的な知識をAIエージェントに組み込むことで、かつての機械学習における特徴量エンジニアリングに相当する重要性を持つと筆者は指摘します。
    *   **プロンプト**: ドメイン知識をプロンプトに含め、タスク解決に必要な知識や方法論を具体的に指示することで、特に専門性の高いタスクで性能が向上します。
    *   **ワークフロー**: 専門家の問題解決プロセス（例: 科学研究のアイデア創出→実験→論文執筆）自体をエージェントのコードに組み込むことで、体系的かつ効率的なタスク遂行を可能にします。
    *   **ルーブリック**: 結果の良し悪しを評価する専門家の暗黙的な基準を「ルーブリック」として明文化しLLMに与えることで、「LLM-as-a-Judge」の評価精度が専門家レベルに近づきます。これにより、推論時スケーリングで生成された大量の候補から高品質なものを自動で選別できるようになります。OpenAIの「PaperBench」はその好例であり、今後は専門家がコードではなくルーブリックを書く時代が来る可能性を筆者は示唆しています。

これらの「推論時スケーリング」と「ドメイン知識の活用」を両輪とすることで、AIエージェントは単なる自動化ツールではなく、専門家に匹敵する実用的なパートナーへと進化することが可能になると秋葉氏は結論付けています。Sakana AIの取り組みは、AIエージェントの未来が明るいものであることを予感させます。