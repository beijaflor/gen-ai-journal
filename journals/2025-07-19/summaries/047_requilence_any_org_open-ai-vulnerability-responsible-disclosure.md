## OpenAI – vulnerability responsible disclosure

https://requilence.any.org/open-ai-vulnerability-responsible-disclosure

OpenAIのシステムで発見された脆弱性は、トークン化のバグにより他のユーザー向けのチャット応答が意図せず露出する可能性があったことを明らかにし、修正された。

[[AIセキュリティ, データプライバシー, トークン化の脆弱性, 責任ある開示, AIシステム開発]]

OpenAIのシステムで発見された脆弱性は、特定の条件下で他のユーザー向けのチャット応答が意図せず露出する可能性があったことを示している。当初データ漏洩と疑われたこの問題は、OpenAIの調査により、音声入力が特定の制限を超えた際にトークン化が不適切に行われ、空のクエリとして処理されるバグが原因であることが判明した。これにより、モデルがランダムな開始トークンから応答を生成し、結果的に無関係な情報が表示される事態が発生した。この問題は2025年7月16日までに修正された。この事例は、AIシステムにおける入力処理の厳密な検証と、予期せぬ動作がプライバシーに与える影響を深く理解することの重要性を強調している。

**編集者ノート**: この脆弱性は、AIモデルを組み込むウェブアプリケーション開発者にとって、入力データの取り扱いがいかに重要であるかを再認識させるものです。特に音声入力のような複雑なデータ形式では、トークン化の段階で予期せぬ挙動が発生し、それが情報漏洩につながるリスクがあることを示唆しています。AIサービスを利用する際は、単にAPIを呼び出すだけでなく、その内部処理、特にデータの前処理と後処理のメカニズムを深く理解し、異常な入力に対する堅牢なエラーハンドリングと検証ロジックを実装することが不可欠です。今後、AIの利用が拡大するにつれて、このような「見えない」部分での脆弱性が顕在化するケースが増えるでしょう。開発者は、AIモデルの「ブラックボックス」を意識し、常にセキュリティとプライバシーを最優先した設計を心がけるべきです。