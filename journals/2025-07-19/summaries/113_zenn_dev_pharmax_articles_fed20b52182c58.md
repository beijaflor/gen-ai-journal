## LLMのAPIを活用したバックエンドアーキテクチャの事例を紹介します

https://zenn.dev/pharmax/articles/fed20b52182c58

PharmaXは、LLM APIをRuby on Railsバックエンドに統合する際の課題と、非同期処理やトランザクション管理による解決策を詳述する。

[[LLMバックエンド統合, 非同期処理, トランザクション管理, Ruby on Rails, API応答速度]]

PharmaXのYOJOサービスは、薬剤師と患者間のオンライン相談にLLMを活用しており、チャット提案だけでなく、システムメッセージ送信条件の決定や会話分類といったバックエンド処理にも利用しています。主な課題は、LLM APIの応答速度が数秒から10秒以上と遅い点です。この遅延に対処するため、彼らはRuby on RailsベースのバックエンドでSidekiqを用いた非同期処理を導入し、LLM関連のプロセスをバックグラウンドで実行しています。さらに、データの一貫性を保つためにLLM処理をトランザクション管理下に置き、前処理で実行条件を判断し、LLM処理でAPIコールを実行、後処理で最終的なアクションを決定するワークフローを構築しています。これにより、LLMの遅延がユーザー体験に与える影響を最小限に抑えつつ、複雑なAI機能をサービスに組み込むことに成功しています。記事は、LLM処理をバッチ処理のように扱うべきであり、慎重な状態管理が不可欠であると強調しています。

**編集者ノート**: Webアプリケーションエンジニアにとって、LLMのバックエンド統合は避けて通れないテーマです。特に、LLMの応答速度の遅さは、リアルタイム性が求められるWebサービスにおいて大きな障壁となります。PharmaXの事例は、非同期処理とトランザクション管理を組み合わせることで、この課題を現実的に解決する具体的なアプローチを示しています。これは、単にLLMを呼び出すだけでなく、その特性を理解し、システム全体としてどのように堅牢かつスケーラブルに組み込むかを考える上で非常に参考になります。今後、より多くのWebサービスがLLMをコア機能として取り入れる中で、このような非同期・トランザクション設計の重要性は増す一方でしょう。将来的には、LLMの推論速度が向上したとしても、複雑な処理や複数のLLM連携においては、同様の設計思想が引き続き求められると予測します。