## Anthropic、Claudeの会話データ利用方針をオプトアウト方式へ変更

https://zenn.dev/shirochan/articles/476419f488669b

AnthropicはClaudeの会話データ利用方針をオプトインからオプトアウトへ変更し、ユーザーに明示的な設定確認を促している。

**Content Type**: News & Announcements

**Scores**: Signal:4/5 | Depth:2/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 83/100 | **Annex Potential**: 79/100 | **Overall**: 76/100

**Topics**: [[AIプライバシー, データガバナンス, Anthropic Claude, 利用規約変更, AIモデルトレーニング]]

アンソロピックは、AIモデル「Claude」の利用規約を改訂し、特に会話データ利用方針を従来の「オプトイン方式」から「オプトアウト方式」へと根本的に変更しました。この重要な変更により、ユーザーが明示的に拒否しない限り、Claude Free、Pro、Maxプランにおける会話データが自動的にAnthropicのAIモデル改善のために利用されることになります。既存ユーザーは2025年9月28日までに設定を見直す必要があり、同意した場合はデータが最大5年間保持される一方、オプトアウトした場合は原則30日間の保持となります（ただし、安全性のレビューやフィードバック目的の場合は利用される可能性あり）。

この変更は、Webアプリケーションエンジニアにとってデータガバナンスとプライバシー保護の観点から極めて大きな意味を持ちます。開発プロセスにおいてClaudeをコード生成、デバッグ、アーキテクチャ設計の相談などに活用している場合、プロプライエタリなコードスニペット、未公開のプロジェクト詳細、顧客データの一部などが意図せずAIの学習データとして収集・利用されるリスクが高まります。これは情報漏洩のリスクだけでなく、企業のセキュリティポリシーや業界規制（GDPR、CCPAなど）への違反にも繋がりかねません。

したがって、エンジニアは自身のプロダクティビティツールとしてのClaude利用が、組織のデータセキュリティ基準に適合しているか緊急に確認する必要があります。具体的には、Claudeのデータプライバシー設定ページ（`claude.ai/settings/data-privacy-controls`）にアクセスし、「Claudeの改善にご協力ください」の項目を速やかに確認し、必要に応じてオプトアウト設定を行うべきです。AIアシスタントの利便性を享受しつつも、その背後にあるデータ利用のメカニズムを理解し、能動的に管理する責任が、現代のWebアプリケーションエンジニアには強く求められています。この変更は、AIツールの導入におけるデータ利用方針の透明性とユーザーによるコントロールの重要性を改めて浮き彫りにしています。