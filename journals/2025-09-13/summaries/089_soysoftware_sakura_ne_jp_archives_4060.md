## AI目当てでMacやRyzenAIMax+395を買うな

https://soysoftware.sakura.ne.jp/archives/4060

MacやRyzen AIMax+395をAI目当てで購入する行為に対し、NVIDIA GPUやクラウドAIサービスと比較してその実用性と限界を詳細に解説し、注意を促す。

**Content Type**: AI Hype
**Scores**: Signal:4/5 | Depth:4/5 | Unique:5/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 94/100 | **Annex Potential**: 95/100 | **Overall**: 92/100

**Topics**: [[AIハードウェア, LLM推論, GPU性能, 統合メモリ, クラウドAIサービス]]

この記事は、AI利用を目的としたMacやRyzen AIMax+395といった特定のハードウェア購入に対する一般的な誤解を正し、警鐘を鳴らすものです。筆者は、これらのデバイスがAI用途、特にLLMの学習、画像生成、動画生成といった主要タスクにおいて過大評価されており、多くのケースでNVIDIA製GPUやクラウドAIサービスの方がはるかに優れていると主張します。

MacやRyzen AIMax+395の長所は、CPUとメモリが直結されたユニファイドメモリによる「高速な帯域幅」と「大容量のメモリ」にあります。これは、消費者向けNVIDIA GPUのVRAM容量では不足する大規模なLLMモデルをメモリに載せて推論する際に、一定のメリットを提供します。しかし、この利点も限定的であり、LLMのプロンプト処理速度や、さらに大規模なモデルにおける推論速度はNVIDIA GPUに大きく劣ります。例えば、RTX4090がプロンプト処理で8534tpsを出すのに対し、M3 Ultraはわずか1116tps、DeepSeek-V3のような巨大モデルではM3 Ultra 512GBでもプロンプト処理60tps、生成6tpsと、実用には程遠い低速になる具体的な数値を示しています。

一方で、LLMの学習や画像・動画生成といったGPU性能が決定的に重要なタスクにおいては、M3 Ultra（RTX4070TiSUPER相当）やRyzen AIMax+395（RTX3060相当）のGPU性能では全く力不足であると指摘。個人がAIを効果的に利用するなら、高性能で手軽なChatGPTなどのクラウドAIサービスが最も費用対効果が高く、150万円のMac Studioを購入する代わりにChatGPTプロプランを4年以上契約できる方が合理的であると強調しています。本格的なローカルAI利用には、やはりNVIDIA製GPUを搭載したPCが必須であると結論付けています。

ただし、セキュリティ要件やインターネット接続の制約がある特殊なビジネス環境において、ローカルLLMを動かすミニPCとしてRyzen AIMax+395が限定的な役割を果たす可能性も示唆。しかし、一般的なAI利用目的でこれらのハードウェアを購入する必要性はなく、Copilot+PCのマーケティングにも批判的な姿勢で、AIハードウェア選択における「ハイプ」に対する冷静な現実チェックを促す、示唆に富む内容です。