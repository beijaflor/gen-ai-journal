## The destination for AI interfaces is Do What I Mean

https://interconnected.org/home/2025/08/29/dwim

AIはユーザーインターフェースを、段階的なコマンド入力からユーザーの意図を解釈する「Do What I Mean (DWIM)」型へと変革し、表現力と機能を大幅に向上させると提唱する。

**Content Type**: 💭 Opinion & Commentary

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 89/100 | **Annex Potential**: 89/100 | **Overall**: 88/100

**Topics**: [[AI UI/UXデザイン, 意図ベースインタラクション, DWIM, マルチモーダルインターフェース, AIエージェント]]

マット・ウェブの記事は、AIがユーザーインターフェースを根本的に変革し、コマンド駆動型からより意図駆動型のモデルへと移行する可能性を探っています。David Galbraithの提唱から始まり、複雑なプロンプトを「ボタン」としてカプセル化し、「Photoshopで雲を削除」のようなシンプルな記述的アクションで結果を得る、というアイデアが紹介されます。これは、*一連のステップ*を定義するのではなく、*望ましい結果*を表現することへのパラダイムシフトを示唆しています。

ウェブは、この考えを1966年にWarren Teitelmanが提唱した「Do What I Mean (DWIM)」という計算機科学の歴史的哲学に結びつけます。DWIMは、システムがユーザーの要求を文脈から解釈し、ニーズを予測して「シンタックスエラー」や不必要な確認を避けるべきだと提言します。ChatGPTは、DWIM UIの初期の不完全な例として挙げられています。この核となる洞察は、インターフェースの煩雑さを取り除くことが、単なる簡素化ではなく、ソフトウェアの*表現力と機能*を大幅に向上させることにあるという点です。

ウェブアプリケーションエンジニアにとって、これはユーザーエクスペリエンスの設計と構築方法に大きな変化をもたらすことを意味します。将来のAIインターフェースは、ボタンやメニューのような低帯域幅の入力方法に依存するのではなく、「容易さ、表現力、解像度」をもってユーザーの意図を捉えることを優先するでしょう。これは、意図の捕捉を最適化し、その後「私が意図することを実行する」という設計哲学を求めています。記事は、「サードデバイス」や、MITの1982年の「Put-That-There」プロジェクトのようなマルチモーダル入力（音声、ジェスチャー、視線）にも触れ、ユーザーの文脈に深く統合され、スクリーンに限定されないインターフェースの可能性を示唆しています。

重要なポイントは、エンジニアが明示的な段階的指示を減らし、文脈に基づいてユーザーの意図を積極的に解釈し、実行するシステムを設計するべきだということです。このアプローチはエージェントの複雑さを簡素化し、新たなレベルのユーザーインタラクションを解き放ち、アプリケーションを飛躍的に強力で直感的なものにすることができます。