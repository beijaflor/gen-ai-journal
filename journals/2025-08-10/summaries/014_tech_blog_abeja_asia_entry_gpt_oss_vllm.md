## gpt-oss-120bをpythonとvLLMで触りながら理解する

https://tech-blog.abeja.asia/entry/gpt-oss-vllm

本記事は、OpenAIが公開したオープンモデル「gpt-oss-120b」をvLLM上で実際に動かし、そのMoEアーキテクチャ、思考過程と最終出力を分けるOpenAI Harmonyの活用法、そして関数呼び出し機能の具体的な動作を詳細に検証します。

**Content Type**: ⚙️ Tools

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 77/100 | **Overall**: 80/100

**Topics**: [[GPT-OSS, vLLM, Mixture of Experts (MoE), Tool Use, OpenAI Harmony]]

OpenAIが新たに公開したオープンモデル「gpt-oss-120b」は、MoE（Mixture of Experts）アーキテクチャを採用しており、総パラメータ数は大きいものの推論時のアクティブパラメータが少ないため、特にvLLMのような高速推論フレームワークと組み合わせることで、高性能ながらも効率的な運用が期待されます。本記事は、この注目すべきモデルをPythonとvLLM環境で動かすための具体的な手順を解説しており、ウェブアプリケーションエンジニアが最新のオープンモデルを迅速に導入し、その性能を最大限に引き出すための実践的な知見を提供します。

特筆すべきは、gpt-ossがOpenAI Harmonyという独自のチャット/応答フォーマットに準拠している点です。これにより、モデルの出力は「analysis」（思考過程）と「final」（最終出力）という異なるチャンネルに構造化されます。この機能は、単に結果を得るだけでなく、モデルがどのようにその結論に至ったか、あるいはどのような思考ステップを踏んだかを可視化するため、アプリケーション開発者がモデルの振る舞いを深く理解し、より複雑なプロンプトやエージェントのロジックを設計・デバッグする上で極めて重要です。例えば、誤った出力があった際に、どの思考フェーズで問題が生じたのかを特定する手助けとなります。

さらに、記事ではモデルの関数呼び出し機能（Tool Use）を詳細に掘り下げています。カスタム関数の呼び出し方だけでなく、「python」や「browser」といった学習済みの組み込みツールとの連携方法がコード例と共に示されており、エンジニアはこれらを活用して、外部情報検索や計算処理を伴う高度なAIエージェント機能をアプリケーションに実装する具体的な道筋を得られます。ただし、複数のツールを同時に並列で実行する機能は、現状のgpt-ossではサポートされていないという実証結果は、今後のエージェント設計における重要な制約として認識すべき点です。

この実践的な検証は、新しいオープンモデルの技術的な詳細だけでなく、その運用上の特性や限界を明確にすることで、エンジニアが現実のシステムに組み込む際の設計判断に役立つ貴重な情報を提供します。MoEモデルの高速性とOpenAI Harmonyによる内部構造の可視化は、特にリアルタイム応答や複雑なタスク処理が求められるウェブアプリケーションにおいて、大きなメリットをもたらすでしょう。