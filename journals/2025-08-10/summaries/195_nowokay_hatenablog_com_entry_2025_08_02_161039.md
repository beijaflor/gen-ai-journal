## Qwen3-235BやQwen3-30B、Qwen3 Coder Flashは長コンテキストでの性能劣化が激しいのでは

https://nowokay.hatenablog.com/entry/2025/08/02/161039

著者は、Qwen3の最新モデルがベンチマークの高評価とは異なり、実際のコーディング作業において長文コンテキストでの性能劣化や不適切なコード生成といった課題を抱えていると指摘します。

**Content Type**: AI Hype

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 87/100 | **Annex Potential**: 88/100 | **Overall**: 84/100

**Topics**: [[LLM性能評価, コード生成AI, Qwen3, コンテキスト長, ベンチマークの限界]]

最新のQwen3モデル（235B、30B、Coder Flash）はベンチマークで高い評価を受けているものの、筆者は実際のコーディングタスクでの期待外れの性能を指摘します。特に長文コンテキストでの性能劣化が顕著であり、ベンチマーク結果が実利用時の性能を正確に反映していない可能性を示唆しています。

具体的な問題点として、モデルがプロンプト外の不要な情報を追加したり、指示通りの修正ができていないにも関わらず「変更しました」と報告したりする挙動が挙げられます。コーディングタスクでは、例えばJava Swingでのブロック崩し作成において、`KeyListener`のエラーに対して`@Override`を削除するという初歩的な誤った解決策を提示し、さらにその修正すら適用できない「ジュニアレベル以下」の推論能力を示したと述べています。これは、LLMが自信がないときに無駄な情報で埋めようとする傾向や、目の前のコンパイルエラーを短絡的に解決しようとする浅い思考に起因すると分析しています。

対照的に、Qwen3 14Bモデルは同様のエラーに対してもより適切な修正を試み、安定したコード生成能力を示したとのこと。筆者は、MoEモデルにおけるアクティブパラメータ数（Qwen3-30Bの3B）が思考の深さに影響し、コーディングには不十分ではないかとの仮説を提唱しています。長コンテキスト（30Bで6000トークン、235Bで15000トークン超）での性能不安定化は、AIを活用したエージェント開発においてシステムプロンプトが長くなりがちな実情に照らし合わせると、実用上の大きな課題です。

この分析は、ウェブアプリケーションエンジニアがAIコーディングツールを選定・利用する際に、ベンチマーク数値のみに惑わされず、実際の開発フローや長文のコンテキストでの挙動を検証することの重要性を示しています。表面的な高性能に騙されず、モデルの「思考の深さ」と実用性を深く見極める視点が求められます。