## GPT-5 Under Fire: Red Teaming OpenAI’s Latest Model Reveals Surprising Weaknesses

https://splx.ai/blog/gpt-5-red-teaming-results

SPLXAIは、GPT-5の安全性と堅牢性がデフォルトでは企業利用に不十分であることを、徹底的なレッドチーミング結果で明らかにした。

**Content Type**: Research & Analysis

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 81/100 | **Annex Potential**: 80/100 | **Overall**: 84/100

**Topics**: [[LLM安全性, レッドチーミング, プロンプトエンジニアリング, 企業向けLLM導入, LLMベンチマーク]]

SPLXAIは、OpenAIの最新モデルGPT-5の安全性とアライメント（整合性）を評価するため、包括的なレッドチーミングを実施しました。これは、企業がGPT-5を安全に導入するために何が必要かを示す重要な示唆を含んでいます。テストは、システムプロンプトなし、基本的なシステムプロンプトあり、そしてSPLXのプロンプト強化済みという3つの構成で、セキュリティ、安全性、ビジネスアライメント、信頼性の各カテゴリで1,000以上の攻撃シナリオを用いて行われました。

結果として、GPT-5の生モデル（システムプロンプトなし）は、企業利用にはほぼ使えないほど安全性が低いことが判明しました。OpenAIの提供する基本的なプロンプト層でも安全性は向上するものの、特にビジネスアライメントの面で大きなギャップが残ります。一方、SPLXのようなプロンプト強化を適用することで、GPT-5の安全性は大幅に向上しますが、微妙な失敗や敵対的な戦術を捕捉するためには、ランタイム保護層が不可欠であると結論付けられています。

興味深いことに、同じテストスイートを用いたGPT-4oとの比較では、特にプロンプト強化された状態において、GPT-4oの方が全体的な堅牢性でGPT-5を上回る結果となりました。さらに、GPT-5は基本的な難読化攻撃（例：StringJoin Obfuscation Attack）にも依然として脆弱であることが示されており、安全層を迂回して悪意のある指示を実行する可能性があります。これは、GLM-4.5やKimi K2など他の主要なLLMにも見られる共通の脆弱性を浮き彫りにしています。

ウェブアプリケーションエンジニアにとって重要なのは、「より高性能なモデルが必ずしもより安全であるとは限らない」という点です。LLMを企業環境に展開する際には、デフォルト設定を信頼せず、プロンプト強化や継続的なレッドチーミング、そしてランタイムでのガードレールによる保護を積極的に実施する必要があるという教訓です。AIのアライメントはモデルの能力だけでなく、それを支えるインフラストラクチャによって大きく左右されるため、開発者はそのセキュリティ対策に注力すべきです。