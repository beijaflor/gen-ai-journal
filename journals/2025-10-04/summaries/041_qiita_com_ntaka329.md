## 【2025年版】雑なpromptでも動く？AI Agent徹底比較！GPT-5 vs Claude Sonnet4.5 vs ローカルLLM #githubcopilot

https://qiita.com/ntaka329/items/a6f7cf94d0194852d45d

記事は、Golang Fiberの単体テスト作成タスクを通じて主要なAIエージェントの性能を徹底比較し、費用対効果に優れたモデルの選定基準を提示します。

**Content Type**: Tools

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 77/100 | **Overall**: 80/100

**Topics**: [[AI Agent, LLM比較, Go言語, ユニットテスト生成, 開発ワークフロー改善]]

「【2025年版】雑なpromptでも動く？AI Agent徹底比較！」は、Golang Fiberで記述された特定の関数（`fiber.Ctx`をパラメータに含む`addLogic`）の単体テストコード作成という、実際の開発現場で遭遇しうる複雑なタスクを設定し、複数のAIエージェントの性能を詳細に比較検証しています。

この記事がWebアプリケーションエンジニアにとって重要な理由は、具体的なモデル選定の指針を提供する点にあります。検証の結果、GPT-5 miniがコストと品質のバランスにおいて最も優れており、一度の指示で正確かつ必要最小限のテストコードを生成できることが示されました。これは、開発者がAIエージェントにテストコード作成を依頼し、他の作業に集中する「放置プレイ」のような効率的なワークフローを実現する上で、極めて実用的です。

一方、Claude Sonnet 4やそのプレビュー版であるClaude Sonnet 4.5、GPT-5-Codexも高品質なテストコードを生成しましたが、GPT-5 miniの出力と大きく変わらないことから、より複雑なタスクでその真価が問われると分析されています。特筆すべきは、MacBook Pro（M4 Max、メモリ36GB）で動作させたローカルLLM（ollama:qwen3-coder:30b）が、`Fiber Context`のモック化に大苦戦し、30分以上の試行錯誤の末にも正確なテストコードを生成できなかった点です。これは、ローカルLLMを実務で活用するには、メモリ容量を含めまだハードルが高いことを示唆しており、ハードウェア投資や技術選定における現実的な視点を提供します。

この比較は、AIエージェントが単にコードを生成するだけでなく、フレームワーク特有の複雑な要件（例: `Context`オブジェクトの扱い）に対してどれだけ堅牢であるかを示す貴重な情報です。エンジニアは、この記事の結果を参考にすることで、費用対効果が高く、かつ開発効率を最大化できるAIエージェントを自信を持って選択できるでしょう。