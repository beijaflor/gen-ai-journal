## テキスト埋め込みモデルの蒸留に関する調査

https://zenn.dev/retrieva_tech/articles/c0a7fc6fe35fb4

強力なテキスト埋め込みモデルを効率的に小型化するため、異なる知識蒸留手法や訓練の工夫の有効性を実験的に検証し、実用的な知見を提示します。

**Content Type**: Research & Analysis

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 81/100 | **Annex Potential**: 80/100 | **Overall**: 84/100

**Topics**: [[テキスト埋め込みモデル, 知識蒸留, RAG, 大規模言語モデル, モデル最適化]]

大規模化が進む言語モデルにおいて、推論コストの高さは実応用での大きな課題です。特にRAGシステムで検索器として利用されるテキスト埋め込みモデルでは、検索時間がユーザー体験に直結するため、小型化が不可欠です。本記事は、この課題に対し、大規模モデルの能力を維持しつつ小型化する「知識蒸留」に焦点を当て、その具体的な手法や訓練の工夫の有効性を体系的に調査したものです。

ウェブアプリケーション開発者がRAGシステムを構築する際に、既存の強力な埋め込みモデルをそのまま利用すると、コストやレイテンシがボトルネックになります。この研究は、どの蒸留損失関数（KLD、CKD、JS）や訓練テクニック（正例利用、prefix付与、TAID）が、どのようなデータセットの条件で最も効果的かという、エンジニアが直面する具体的な疑問に答えます。

主要な発見として、約200万件の多様なタスクデータを用いる場合、CKDがKLDやJSよりも優れた性能を示すものの、データ種類や量に非常に敏感であることが明らかになりました。一方、KLDはより少ないデータ量でも安定した性能を発揮します。また、LLM蒸留で用いられるTAID手法はテキスト埋め込みモデルの蒸留にはほとんど効果がなく、むしろ性能を劣化させるケースが見られました。正例の利用はKLDで効果的でしたが、CKDでは逆効果となる場合もあり、特に性質の異なる文ペアを正例とするタスクでは性能が大きく落ち込みました。Prefix付与も全体の性能を劣化させる結果となり、特にRetrievalタスクで顕著でした。これは、訓練データのバッチ構成とネガティブサンプリングの相互作用に起因する可能性が指摘されています。

これらの知見は、RAGの推論コスト削減を目指すエンジニアにとって非常に実用的です。採用する蒸留手法、データセットの選定、そして特定の訓練テクニックの適用可否を判断する上で、具体的な指針を提供します。闇雲に既存手法を適用するのではなく、データやタスクの特性に応じた最適なアプローチを選択することで、高性能かつ効率的な埋め込みモデルを構築できるようになります。特に、特定のデータセットで優れた性能を示すCKDと、より一般的なデータで安定するKLDの使い分けは、モデル最適化戦略の重要な鍵となるでしょう。