## そのAI生成コード、全部レビューしますか？全部信じますか？

https://zenn.dev/r_kaga/articles/66c190413d3ab9

AI生成コードのレビューにおける課題に対し、「確率・影響・検知性」の3軸でリスクを評価し、具体的な技術的対策を講じるフレームワークを提案する。

**Content Type**: 🛠️ Technical Reference

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 90/100 | **Overall**: 92/100

**Topics**: [[AIコードレビュー, AI生成コードのリスク管理, コンテキストエンジニアリング, テスト戦略, 開発者ワークフロー]]

AIコーディングエージェントによるコード生成が加速する現代において、開発者は「生成されたコードをどこまでレビューし、どこまで信頼すべきか」という新たなジレンマに直面している。本稿は、Thoughtworksの知見を基に、「確率（Probability）・影響（Impact）・検知性（Detectability）」の3軸でAI生成コードのリスクを評価するフレームワークを提唱し、その具体的な向き合い方を示す。

このフレームワークは、AIが開発ワークフローに深く統合される中で、人間がどのようにコードの品質と安全に責任を持つべきか、その指針となる点で極めて重要だ。
各軸に対する具体的なアプローチは以下の通りだ。
まず「確率（AIが間違う可能性）」を下げるには、コンテキスト分離・圧縮やタスクの細分化といったコンテキストエンジニアリングが有効である。LangChainの「Write」「Select」「Compress」「Isolate」といった基本要素は、AIの誤り確率を減らす上で参考になる。AIフレンドリーなコードベースや明確なタスク設定も、AIの精度を高める鍵となるだろう。
次に「影響（ミスがあった時の被害）」を見極める観点では、金融決済システムと社内ツールのプロトタイプで求められる品質が異なるように、プロジェクトの性質に応じた徹底したレビューが不可欠だ。特にセキュリティ脆弱性には厳重な注意が必要で、Veracode社の調査ではAI生成コードの45%にOWASP Top 10に含まれるような重大な脆弱性が含まれることが指摘されている。
そして最もコントロールしやすいのが「検知性（ミスに気づけるか）」の最大化だ。ユニットテスト、型システム、静的解析ツールは必須であり、コンパイラやテストはAIのhallucination（幻覚）に対する強力なファクトチェック機構として機能する。OpenAI社内でも生産性を10倍向上させたとして「10X」と呼ばれるAIコードレビューツールが活用されており、AIが生成したテストでAI生成コードを検証し、AIがコードレビューするという「AI同士の相互チェック」も現実的になっている。Meta社のTestGen-LLMによるテスト自動改善や「Testing Trophy」のような統合テスト重視のアプローチも、この検知性を高める新たな方向性を示唆する。

結論として、実装の詳細よりも「仕様と振る舞いの保証」に重点が移りつつある。現代の開発者には、この3軸を活用してAIを「いつ信じ、いつ疑うか」という、実践的な勘所と審美眼を養うことが求められている。