## 高性能な日本語マルチモーダル基盤モデル「clip-japanese-base-v2」の公開

https://techblog.lycorp.co.jp/ja/20251218a

LINEヤフーは、日本語に特化した高性能マルチモーダル基盤モデル「clip-japanese-base-v2」をApache-2.0ライセンスで商用利用可能として公開しました。

**Content Type**: Tools
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 81/100 | **Annex Potential**: 79/100 | **Overall**: 84/100

**Topics**: [[マルチモーダルAI, 日本語AIモデル, 知識蒸留, データフィルタリング, 基盤モデル]]

LINEヤフーのFoundation Models研究開発チームは、画像と言語のマルチモーダル基盤モデル「clip-japanese-base-v2」を開発し、商用利用可能なApache-2.0ライセンスで公開しました。この新モデルは、以前のバージョン「clip-japanese-base」と比較して、学習データと学習方法の両面で大幅な改善が図られています。

今回のアップデートでは、まず学習データにおいて、Common Crawlから収集した日本語の画像・テキストペアデータを大幅に増加させ、フィルタリング前のサンプル数を10億件から28億件に拡張しました。さらに、画像とテキストの関連度を測るためのフィルタリング手法を改善し、従来のCLIP-scoreのバイアスを排除する新しい指標「negCLIPLoss」を導入。加えて、小規模なクリーンデータで学習させた独自のフィルタリング用CLIPモデルを構築することで、ダウンストリームタスクの平均精度向上に大きく貢献しました。最終的に5.4億件の高品質な画像・テキストペアが学習データとして使用されています。

学習方法では、大規模で高精度なモデルの知識を軽量モデルに引き継ぐ「知識蒸留」が導入されました。特に、CLIP特有の構造を活かす「Interactive Contrastive Learning (ICL)」と「Contrastive Relational Distillation (CRD)」の組み合わせが最も有効とされ、チームはCRDに独自の改良を加えることで大幅な精度改善を実現しています。

性能評価の結果、clip-japanese-base-v2は、日本語ImageNet-1kやWAON-Benchといった日本語評価データセットにおいて、既存の日本語特化モデルやマルチリンガルモデルよりも少ないモデルパラメータで高い平均性能を示しました。この成果は、学習データの更新と知識蒸留の両方が精度向上に寄与していることを明確に裏付けています。LINEヤフーは、このモデルが広く利用され、今後の開発に貢献することを期待しており、今後も構築したモデルの一部を継続的に公開する予定です。