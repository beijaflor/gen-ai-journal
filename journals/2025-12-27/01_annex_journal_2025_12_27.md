# GenAI Weekly Journal - Annex - 2025-12-27

## Annexについて

「Annex」は、メインジャーナルとは異なる視点から生成AI×コーディングの世界を切り取る実験的なセクションです。ここでは、主流の技術トレンドからは少し外れた「B面」のような記事を扱います。クリエイティブな実験、批判的な視点、先進的すぎてまだ定着していない戦術、一見マニアックだが深い洞察を含む考察、そしてビジネスや社会への影響を考えさせられる話題――。これらは必ずしも「今すぐ役立つ」とは限りませんが、視野を広げ、思考を刺激し、未来のヒントを与えてくれる可能性を秘めています。

## クリエイティブな実験

### NotebookLM × ChatGPT × Fish Audio で「三行で終わる世界」を作った話

https://zenn.dev/acntechjp/articles/b2f8969bc97e94

本記事は、アクセンチュアの有志社員が、描画や脚本の専門スキルを持たずに、複数のAIツールを駆使してわずか2日間でアニメ漫画動画を制作した過程を詳述した実践記である。著者は、NotebookLMの「スライド生成機能」がアニメ調のイラストを高精度で生成できる点に着目し、これを制作の核に据えた革新的なワークフローを提示している。

制作フローの第一段階として、ChatGPT（GPT-5.2と記述）をストーリー設計の「壁打ち」相手に選び、物語の根幹となる世界観や20話分の構成案を数時間で構築した。特筆すべきは、AIに丸投げするのではなく、著者が納得いくまでプロットを練り直す「相棒」としての活用法である。次に、NotebookLMを用いた画像生成では、特定の参照画像をスタイルガイドとして読み込ませ、詳細な日本語指示（プロンプト）を与えることで、キャラクターの一貫性と正確な日本語描画を両立させている。これは、生成AIにおける「一貫性の欠如」という課題を、既存ツールの組み合わせで解決する具体的なアプローチである。

音声面では、当初検討したツールのエラーを受け、Fish Audioへ柔軟に切り替えることで、自然な日本語発音と迅速な生成スピードを確保した。著者は「ツールは一つに固執せず、目的に応じて切り替える」という、AI時代のエンジニアに求められる柔軟な創作スタイルを強調している。最終的に、これらの素材を動画編集ソフトで統合し、極めて短期間での作品完成に至った。

著者がこの試みを通じて伝えたい核心は、「作りたい」という意志さえあれば、技術的な障壁（絵が描けない、脚本が書けない等）をAIが補完し、個人の創造性を爆発させられるという点にある。AIはあくまで強力な「道具」であり、それを使いこなす人間の試行錯誤（リテイクや指示の工夫）こそが作品の質を左右するという、現実的かつ前向きなメッセージが込められている。これは、Webエンジニアにとっても、技術をどのようにクリエイティブな成果に結びつけるかを示唆する重要な事例となっている。

### Nano Banana Pro で ストーリー漫画の作成を試す

https://note.com/npaka/n/n5e7f167c9bf8

画像生成AIを用いたクリエイティブ活動において最大の難関の一つである「物語の一貫性（キャラクターや文脈の維持）」に対し、著者はGoogle DeepMindの技術をベースとしたNano Banana ProとChatGPTを組み合わせた具体的な解決策を提示している。

ワークフローは大きく3つのステップで構成されている。第一に、ChatGPTを用いてキャラクターの細かな設定（容姿、性格、持ち物、ギャップなど）を言語化し、それを基にNano Banana Proで「キャラクター設定画像」を生成する。ここでは「1K」の解像度で基本となるビジュアルを固定することが重要視されている。第二に、全10ページの構成案と具体的なセリフ、演出意図を盛り込んだ詳細なプロンプトをChatGPTで作成し、Nano Banana Proで2行5列のグリッド形式の「ストーリーボード画像（2K）」として一気に生成する。この段階で物語全体の流れとレイアウトの雛形が決定される。最後に、個別に分割したストーリーボードの各コマに対し、最初に作成したキャラクター設定画像と個別のシナリオを突き合わせ、1ページずつ高解像度（2K）でリファインしていく。

著者がこの手法を重要視している理由は、AIによる漫画制作が単発の画像生成の域を超え、構造的な物語表現へと昇華できることを証明するためである。特に、ストーリーボードを一度グリッドで生成してから個別ページをリファインするという「全体から細部へ」のアプローチは、AI特有の気まぐれな生成結果を制御し、演出意図を維持するための現実的かつ効率的な手法として示されている。また、日本語の漫画フォーマット（右から左へ読む形式）への対応や、セリフの埋め込み、効果線の演出など、実用的な漫画表現をAIでどこまで再現できるかという技術的な限界に挑んでいる点が興味深い。エンジニアの視点からは、複数のAIエージェント（企画・構成としてのChatGPTと、出力としての画像生成AI）を段階的に連携させ、各工程の出力を次工程のコンテキストとして利用する「パイプライン的な思考」が、クリエイティブな領域においても極めて有効であることを再認識させる内容となっている。最終的に生成された漫画は、コミュ障の主人公がゲームを通じて成長するという青春ドラマであり、AIが単なる道具ではなく「演出家の意図を具現化するパートナー」として機能することを示唆している。

### Generative Agents を動かして遊ぶ

https://qiita.com/othelloman/items/7ed46bf59b7e1c7adf6e

本記事は、スタンフォード大学とGoogle Researchが発表し大きな注目を集めた研究プロジェクト「Generative Agents（仮想の街で人間らしく生活するエージェント）」を、実際にローカル環境で構築・稼働させた技術検証レポートである。著者は、公式リポジトリのセットアップ手順から、モデルの廃止（text-davinci系）に伴う「TOKEN LIMIT EXCEEDED」エラーの回避策、さらには挙動を理解しやすくするための日本語化対応まで、エンジニアが直面する具体的な実装ハードルとその解決策を詳述している。

特筆すべきは、単なる導入ガイドに留まらず、ソースコードの解析を通じて「エージェントがどのように思考し、行動しているか」という内部ロジックを解き明かしている点だ。著者は、エージェントの自律性を支えるアーキテクチャとして「知覚（Perceive）」「計画（Plan）」「行動決定（Act）」「反応（React）」「省察（Reflect）」という一連のサイクルが、独立したLLM呼び出しと状態更新のループによって実現されていることを明らかにしている。

また、エージェントが持つ「記憶」の管理手法についても鋭い洞察を提供している。各エージェントは共通のデータベースを参照するのではなく、個別の「空間記憶（Spatial Memory）」や他者との「関係性の記憶」をJSON形式で保持しており、これがシミュレーションにおける行動の連続性と一貫性を生み出している。著者は、一度のプロンプトで全てを決定するのではなく、状態を細かく更新しながら何度もLLMを呼び出す多段構成の設計こそが、複雑なエージェント挙動を実現する鍵であると主張している。

ウェブアプリケーションエンジニアにとっての重要性は、この「多段的な思考プロセス」の実装パターンにある。現在のLLMアプリケーション開発において、単一の推論では限界がある複雑なワークフローに対し、どのような粒度でタスクを分解し、過去のコンテキスト（記憶）をどう再注入すべきかという問いに対する具体的な解を、このプロジェクトは提示している。著者の試行錯誤（日本語化に伴うパースエラーの修正など）は、LLMをシステムに組み込む際の堅牢なパース処理や構造化出力の重要性を再認識させる実戦的な内容となっている。

### AIエージェント × 人の褌でトレード戦略を爆誕させる

https://note.com/drillan/n/n7379c02632c9

本記事は、投資コミュニティ「マケデコ」の3年分・60本以上に及ぶアドベントカレンダー記事をソースとして、AIエージェントに高度なトレード戦略を立案させる試みを解説している。著者は、膨大な専門知識を人間がすべて咀嚼するには膨大な時間がかかるという課題に対し、マルチエージェント・フレームワーク「MixSeek」を用いた解決策を提示している。

MixSeekは、複数のエージェントチームが独立して戦略を生成し、評価エージェント（Evaluator）によるフィードバックを受けて改善を繰り返す「コンペ型」の構成を特徴とする。本プロジェクトではまず、Claude 4.5 Haikuを用いた「記事フェッチエージェント」が全記事から主要テーマと投資のキーポイントを抽出してCSV化。その後、「システマティック・トレーダー」「ファンダメンタル投資家」「リスクマネージャー」という異なる専門性を持つ3つのチームが、抽出された知見をもとに3ラウンドにわたる競争を行った。

各チームは、単なる情報の要約にとどまらず、マケデコの記事群から「Comomentum（混雑度）」や「Chatterjeeの順位相関」といった具体的な技術コンセプトを抽出し、独自の投資ロジックへと昇華させている。最終的に生成された「アンチ・クラウディング・ネットキャッシュ・スクイーズ戦略」などの3案は、実行可能性やリスク調整後リターンの観点から高い評価スコアを獲得した。

著者が本手法を重視する理由は、投資のように「正解がなく、多様なアプローチが共存する領域」では、単一のワークフロー型エージェントよりも、複数の視点が競い合うことで洞察が深まるからである。このアプローチは、記事の内容を起点としつつ、web_searchエージェントを介して学術論文等の外部知識と接続することで、さらに精緻な「ディープリサーチ」へと拡張できる可能性を秘めている。エンジニアにとって、大量のドキュメントから実用的なインサイトを抽出・合成する際の強力なデザインパターンとなり得る内容である。

### 「壁打ち」をして「壁」を作ろう

https://zenn.dev/dress_code/articles/b085b7826f1c56

著者は、プライベートでの子供部屋の間仕切り壁作りを例に、生成AIを「設計・計画・実地確認」のパートナーとして活用する方法を解説している。普段エンジニアとしてコーディングエージェントを利用している経験を、物理的なDIYという領域に応用した実例である。

具体的には、GoogleのAI「Gemini」と、その高度な画像生成機能「Nano Banana Pro」を組み合わせて使用している。まず、Geminiとの対話（壁打ち）を通じて、部屋の寸法や使用したいパーツ（ラブリコ等）に基づいた詳細な「DIY計画書」を作成した。ここでは、必要な木材の規格や本数、ビスの太さに至るまでの買い物リスト、さらにはホームセンターでのカット指示書までを具体化している。

次に、Nano Banana Proを用いて視覚的な設計図を生成した。著者は、このツールの特徴である「高度なテキストレンダリング」と「2K解像度」を高く評価しており、設計図内に寸法や材料名を正確に表示させることで、店頭スタッフへの意図伝達を劇的にスムーズにしたと述べている。

また、実地店舗での活用も特徴的である。ネジや金具の売り場で、候補となる商品の写真をGeminiに送信し、事前に作成した計画書と照らし合わせて「これで合っているか」をリアルタイムで確認している。著者は、DIY初心者が陥りやすい「ビスの種類や長さの選択ミス」という不安を、AIのマルチモーダル機能によって解消できることを示した。

筆者は、このプロセスがエンジニアリングにおけるエージェント活用と本質的に同じであると主張している。「作りたい」という抽象的なアイデアをAIとの対話で具体化し、実行可能な手順に落とし込む流れは、分野を問わず有効な手法であるという。最終的に、著者はAIを活用することで、設計の難しさを理由にDIYを躊躇している層のハードルを大きく下げられると結論づけている。

## 批判的視点

### 粗さは洗練に勝る：画像生成AIにおける「不完全さ」の価値

https://borretti.me/article/coarse-is-better

筆者のフェルナンド・ボレッティは、画像生成AIの進化が皮肉にもその「芸術性」を損なっていると主張している。初期のDALL-E 2やMidjourney v2がもたらした、言葉では言い表せない魔法のような感覚が、最新のモデル（作中ではNano Banana Proと呼称）では失われ、代わりに「具体的で退屈なスロップ（粗悪な模造品）」が生成されているという。

この変化の核心は、モデルが「高精細で正確」になりすぎたことにある。筆者は、古いモデルが持っていた不完全さ、曖昧さ、矛盾こそが、受け手の想像力が入り込むための「余白」を生んでいたと説く。対照的に最新モデルは、プロンプトをあまりにも文字通りに解釈してしまう。例えば「大英博物館にあるペルシャの細密画」というプロンプトに対し、古いモデルは博物館の空気感を纏った神秘的な絵画を生成したが、最新モデルは「博物館に展示されている絵画の不鮮明な写真」を出力する。これは意味論的な正確さの向上ではあるが、芸術的な表現としては「教養のない、無粋な（philistinism）」結果であると厳しく批判している。

エンジニアの視点で重要なのは、AI開発における最適化のジレンマだ。解像度を高め、プロンプトへの忠実度（Prompt Adherence）を向上させるという技術的な「進歩」が、ユーザーの創造性を刺激するというプロダクトの本質的な価値を必ずしも高めないことを示唆している。彩度が低く、特定の事象に固執する最新の出力は、多様な解釈を拒絶する。筆者は、AI生成を再び「奇妙で、捉えどころのないもの」に戻すべきだと提言している。

この考察は、生成AIを活用したアプリケーションを設計するエンジニアにとって、モデルの性能を単にベンチマークや「正確さ」だけで評価することの危うさを警告している。時には「粗さ（Coarse）」を残し、ユーザーの想像力を補完させる設計こそが、真に豊かなユーザー体験を生む可能性があるという逆説的な洞察は、ツール開発の方向性を再考させる強い力を持っている。

### AIはあなたを監視しているだけではない:AIが消費者を欺き、支出を増大させる仕組み

https://newrepublic.com/article/204525/artificial-intelligence-consumers-data-dynamic-pricing

著者は、ビッグテックや大手企業が「生活を便利にするツール」としてAIを推進する一方で、実際には消費者の購買習慣を監視し、より高い価格を提示するための手段として悪用している実態を複数の報告書を引用して詳述している。まず、Vanderbilt Policy Acceleratorの調査を挙げ、マクドナルドのような企業がロイヤリティプログラム（アプリ）を「監視の回避策」として利用していると指摘する。ユーザーが割引を求めてオプトインしたアプリを通じて、位置情報やブラウジング履歴、さらには性格的傾向や心理的特性までをAIモデルに学習させており、その規模は国家の情報機関に匹敵する心理プロファイルを構築しているという。

さらに深刻な事例として、食料品配送アプリInstacartの調査報告を紹介している。AIを活用したデータ収集により、同じ商品を同じ時間にカートに入れても、ユーザーの場所やIPデータによって価格が最大23%も変動する「ダイナミックプライシング」が密かに行われている。著者は、これが単なる需給調整ではなく、特定の顧客が支払える最大額をAIが予測してターゲットを絞る「ターボチャージされた価格操作」であると批判している。消費者にとっては何が適正価格か判断できず、家計の管理を困難にする「アフォーダビリティ（負担可能性）の問題」へと発展している。

著者がこの問題を重要視する理由は、これが個別の企業の不正にとどまらず、規制の空白地帯で成長し続ける「制御不能なAIバブル」の象徴だからである。共和党政権による規制緩和の動きが強まる中で、消費者の権利を守るための立法は停滞しており、AIを活用したアルゴリズムによって消費者が搾取される構造が固定化されつつある。著者は、AIに対する期待よりも懸念を抱く国民が多数派であることを強調し、将来的にAIバブルが崩壊した際、誰が「真の悪役」であったかを明確に定義し、適切な政策的規制を導入すべきだと主張している。エンジニアにとっても、自身が開発するアルゴリズムやデータ収集機能が、どのように倫理的一線を越え、社会的な信頼を損なう武器になり得るかを再考させる内容となっている。

### AIによる画風盗用を防ぐ保護ツール「Glaze」の仕組みと意義

https://glaze.cs.uchicago.edu/what-is-glaze.html

シカゴ大学のSAND Labが開発した「Glaze」は、生成AIによるアーティストの画風模倣（Style Mimicry）からクリエイターを保護するためのシステムである。Webアプリケーションエンジニアの視点からは、本作は「敵対的機械学習（Adversarial Machine Learning）」を知的財産保護の実践的なソリューションとして昇華させた、極めて示唆に富む事例と言える。

本ツールの核心は、AIモデルには認識されるが人間には感知できない「摂動（Perturbation）」を画像に加えることにある。具体的には、人間には写実的な肖像画に見える画像であっても、AIモデルが学習する際には「ジャクソン・ポロックのような抽象画」として誤認させるような微細な変更を加える。これにより、特定のアーティストの作品群をStable Diffusionなどのモデルで追加学習（ファインチューニングやLoRA）させても、意図した画風が再現されるのを防ぐ仕組みだ。

著者は、画風の盗用が単なる経済的損失に留まらず、アーティストのアイデンティティそのものを脅かし、創作意欲を減退させている現状を危惧している。技術的な優位点として、Glazeは従来の電子透かし（Watermark）のような脆い技術ではなく、AIの認識プロセスそのものをターゲットにしているため、スクリーンショットやリサイズ、ノイズ除去といった一般的な画像加工攻撃に対しても高い堅牢性を維持する。

エンジニアとして注目すべきは、AIの進化に伴う「防御側」の継続的なアップデートプロセスである。記事内では「IMPRESS」や「Noisy Upscaler」といったGlazeを無効化しようとする最新の攻撃手法（除去アルゴリズム）についても言及されており、それらに対抗するためにバージョン2.1へと進化を続けている。これは、モデルの脆弱性と防御技術の終わりなき軍拡競争の実態を物語っている。

また、本プロジェクトは非営利で運営されており、強力なGPU環境を持たないクリエイターのためにクラウドベースの「WebGlaze」をAWS上で提供するなど、アクセシビリティの確保にも注力している。AIエージェントや生成ツールが普及する中で、データの「提供側」が自己防衛を行うための技術スタックとして、Glazeは重要なマイルストーンとなるだろう。著者はこれが「完全な解決策ではない」と認めつつも、法的・規制的枠組みが整うまでの不可欠な「第一歩」であると主張している。

### 生成AIと処遇AIの混同について、まだ言いたいことがある──LLMは処遇AIを救うかもしれない

https://takagi-hiromitsu.jp/diary/20251221.html

著者は、現在のAI規制議論における最大の欠陥は、人を評価・選別する「処遇AI」と、コンテンツを生み出す「生成AI」の混同にあると強く主張している。かつて処遇AIのために用意された「説明可能性」や「透明性」といった語彙が、文脈を無視して生成AIに流用されたことで、不必要な文書化コストが発生し、本質的な議論が停滞しているという指摘である。

特筆すべきは、著者がLLM（大規模言語モデル）を「処遇AIの救世主」と捉えている点だ。従来の処遇AIは、人間が判断材料を数値やチェックボックスへと「形式化」する過程で、重要な文脈（定性情報）を削ぎ落としてしまう宿命にあった。実例として挙げられた「こども家庭庁の虐待リスクAI」の失敗は象徴的である。「母親に半殺しにされた」という児童の切実な訴えがあっても、痣（あざ）がないという形式的データに変換された途端、AIはリスクを極めて低く判定してしまう。しかし、LLMであれば自然文をそのまま読み込み、文脈に基づいた多面的なリスク抽出が可能になる。

また、著者はLLMが「関連性（Relevance）」の判断、つまり「見えていても判断に使ってはいけない情報」をプロンプト指示によって制御できる可能性に期待を寄せている。統計的推定に依存する従来型AIでは不可能だった「論理的な情報の切り分け」が、LLMの倫理理解によって実現されつつあるという分析だ。

ウェブアプリケーションエンジニアにとっての意義は、AIの実装において「何をデータ化するか」という設計思想の転換を迫られる点にある。単にデータを構造化して機械学習にかけるのではなく、LLMによって定性情報を保持したまま判断の根拠を提示させるアプローチが、より「人間的で妥当な」システム構築に繋がることを示唆している。ただし、技術的進歩が法的な規律を不要にするわけではない。入力データの統制や異議申し立ての保障といった「外側からの規律」を整備することこそが、LLMのポテンシャルを正しく社会に還元するための条件であると著者は締めくくっている。

### AI で日本語の長文を校正する - 山下泰平の趣味の方法

https://cocolog-nifty.hatenablog.com/entry/2025/12/22/124436

著者の山下泰平氏は、50万文字という膨大な分量の日本語原稿を執筆するにあたり、執筆中の認知リソースを「内容の検討」に集中させるため、誤字脱字を一切気にせず書き進め、後からAIで一括処理するという合理的かつ大胆なワークフローを実践した。このアプローチの根底には、執筆期間中にAIの性能が向上し、完成時には大規模な校正が可能になっているだろうという「技術進化への賭け」があり、著者はこれに成功したと述べている。

具体的な実装プロセスにおいて、著者はAIを単なる「相談相手」としてではなく、「自動化システムの構成要素」として活用している。まず、AIに対して「原文・修正案・修正理由をJSONデータとして出力する校正用プロンプト」を作成させた上で、そのJSONを読み込んで元ファイルを一括置換するPythonスクリプト自体もAIに書かせている。この際、実務的な安全性を確保するために、Dry-run（試運転）機能、バックアップ作成、原文不一致時のエラー検知機能を含めるよう指示する手法は、エンジニアリングにおける要件定義の勘所を押さえた実用的なアプローチである。

ツールの使い分けも戦略的だ。ClaudeやChatGPTを用いて対話的にプロンプトを洗練させた後、最終的な大量処理にはGemini CLIを採用している。これはWeb UIの操作を排除し、コマンドラインからの安価で高速なバッチ処理を可能にするためだ。著者は、Unixパイプを組み合わせたテキスト分割処理（2000文字単位など）についても言及しており、10万文字単位の章を数回繰り返して校正にかけることで、最終的に「誤字なし」の状態まで追い込めることを示している。

ウェブエンジニアにとっての本記事の意義は、LLMを既存の開発・執筆ワークフローに「システム」として組み込むための具体的なパターンを提示している点にある。最新のAIモデルの特性を理解した上で、スクリプトによる自動化と組み合わせることで、人間が本来集中すべき創造的な作業にリソースを全振りする。この「AIに仕事を押し付ける」ための具体的な実装能力こそが、これからのエンジニアに求められるスキルであることを、50万文字という圧倒的な物量をもって証明している。

## 先進的な戦術

### エージェントのツールを80%削減した理由：Vercelが辿り着いた「ファイルシステム・エージェント」の衝撃

https://vercel.com/blog/we-removed-80-percent-of-our-agents-tools

Vercelは、自然言語からSQLを生成する社内データ分析エージェント「d0」を大幅に刷新し、その劇的な成果を報告している。従来、同社はモデルのハルシネーションや複雑なスキーマへの対応を懸念し、スキーマ参照やクエリ検証、エラー復旧といった多数の専用ツールを開発し、緻密なプロンプトエンジニアリングと文脈管理を行っていた。しかし、このアプローチはモデルの推論を開発者が肩代わりしようとするものであり、結果としてシステムは脆弱で遅く、頻繁なメンテナンスを要する「重い」ものになっていた。

この課題を解決するため、Vercelは「モデルの推論を妨げない」という逆転の発想に立ち、ツールの8割を削除した。新しいアーキテクチャでは、エージェントに「任意のbashコマンドを実行する」という汎用的なツールを一つ与え、YAMLやMarkdownで記述された定義ファイル群（セマンティックレイヤー）が格納されたファイルシステムへの直接アクセスを許可した。これにより、エージェントはls、grep、cat、findといった50年以上前から存在する標準的なUnixツールを駆使し、人間のアナリストが調査を行うのと同じように定義ファイルを探索して自律的に推論を行うようになった。

この変更の結果、Claude 4.5を搭載した新しいエージェントは、従来の構成と比較して実行速度が3.5倍高速化し、トークン使用量を37%削減、さらにベンチマークでの成功率は以前の80%から100%へと向上した。著者が強調するのは「モデルの進化を信じ、重力に抗わない」ことの重要性だ。Claude 4.5のような高度なモデルは、開発者が用意した限定的な要約ツールよりも、生のドキュメントを直接読む方が正確に状況を把握できる。本記事は、エージェント構築において最も重要なのは「賢いツールを自作すること」ではなく、データやドキュメントを「モデルが解釈しやすい形で整理・構造化すること」であるという、今後のAIアプリケーション開発における本質的なパラダイムシフトを提示している。

### Claude Code中心のAIコーディング運用：実務で効いた5つの型

https://zenn.dev/mkj/articles/868e0723efa060

松尾研究所の中川氏が、Claude Codeを単なる補助ツールではなく、開発プロセスの中核（仕組み）として運用するための5つの実践的な「型」を公開している。AIコーディングにおける最大の課題である「品質のばらつき」と「コンテキストの混濁」を、エンジニアリング的なアプローチで解決しようとする極めて実用的な内容である。

筆者が提示する第一の型は、**git worktreeを用いた並列開発**だ。モジュールごとに作業ディレクトリを物理的に分離することで、AIとの会話コンテキストを強制的に分離し、コンフリクトを最小限に抑えながら複数機能の実装を同時並行で進める手法を推奨している。第二に、タスク管理をMarkdownファイルに集約し、そのままClaude Codeへの指示（プロンプト）として使い回すことで、オペレーションの定型化を図っている。

最も技術的に興味深いのは第三の型、**「Subagent ↔ レビューSubagent」の強制ループ**である。FastAPIやReactなど、技術スタックごとに定義した実装用Subagentと、品質管理に特化した「quality-check-expert」をカスタムスラッシュコマンドで交互に呼び出す仕組みを構築している。これにより、人間が介在せずに「実装→自動レビュー→修正」のサイクルを回し、Linterやテストが通るまでAIを自律的に働かせるプロセスを実現している。記事内では実際に使用されているSubagentの定義ファイルも公開されており、具体的なインストラクションの書き方は即座に実務へ転用可能だ。

第四、第五の型では、ナレッジの一元管理と「Claude Skills」の活用に触れている。AIが参照すべき仕様を`README.md`や`CLAUDE.md`に固定し、指示に従わなくなる「出力の癖」に対しては、Skills機能を使って挙動をフックすることで、長文プロンプトに埋もれない制約を課している。

著者は、AIコーディングの本質的な価値は単に「速く書く」ことではなく、**プロセスを固定化することで品質と再現性を安定させること**にあると主張している。ペアプロ的な張り付きは依然として必要であり、並列化による思考負荷の増大というトレードオフはあるものの、開発速度と品質を高い次元で両立させるための「仕組み化」の重要性を説く、先駆的な実践報告である。

### Claude Codeのフック機能を活用し、Mac通知から対象のtmuxペインへ即座に移動する

https://nealle-dev.hatenablog.com/entry/2025/12/25/122620

Claude CodeをCLI環境、特にtmuxと併用して高度に活用するエンジニアにとって、AIの処理完了や入力を待つ時間は「別の作業」への切り替えが発生しやすいタイミングである。しかし、複数のセッションやペインを使い分けていると、どの画面でAIが応答を待っているのかを見失い、結果として開発のテンポが損なわれるという課題が生じる。筆者はこの課題を解決するため、Claude Codeの`hooks`機能を駆使してmacOSのデスクトップ通知を表示し、さらにその通知をクリックすることで「AIが待機中のtmuxペイン」へ一瞬でフォーカスを移動させる自動化スクリプトを公開した。

技術的な実装の柱は、Claude Codeの設定ファイルにおける`hooks`セクションの活用である。`idle_prompt`（待機状態）、`permission_prompt`（権限確認）、`user_question_prompt`（ユーザーへの質問）といった主要なステータス変化をトリガーとして、通知用のシェルスクリプトを実行する。通知自体はmacOSで定番の`terminal-notifier`を使用しており、`-execute`オプションを介してクリック時のアクションを定義している。

筆者は、この仕組みを安定させるために克服した3つのハードルを詳解している。
1. **パスの問題**: `terminal-notifier`経由で実行されるスクリプトは通常のシェル環境とは異なるため、冒頭で明示的に`/opt/homebrew/bin`等のパスを通す必要がある。
2. **tmuxソケットの特定**: 複数のtmuxセッションが走る環境では、接続先のソケットを誤ると操作が効かない。そのため、フック発火時の`$TMUX`環境変数からソケットパスを動的に抽出し、`tmux -S`オプションで明示的に指定する工夫がなされている。
3. **複数クライアントへの対応**: 同一セッションに複数のクライアントが接続している場合、単一の`switch-client`では意図した画面が切り替わらないことがある。これに対し、`list-clients`で全クライアントのTTYを取得し、ループ処理で全てのクライアントを強制的に対象セッション・ペインへ誘導するという、実用性を重視した堅牢な解決策を採用している。

このハックは、AIコーディングツールを「単なるチャット」ではなく「開発ワークフローの一部」として深く組み込む際の好例である。特にtmuxヘビーユーザーにとっては、コンテキストスイッチの摩擦を最小限に抑え、開発に集中するための非常に具体的かつ即効性のあるテクニックと言えるだろう。

### 2025年、Claude Code と 1 人で 40 万行規模のフルスタック＋インフラを構築した話（あみださん）

https://zenn.dev/shusuke_o/articles/f63e1bf61363b8

著者は、1万人以上の利用者がいるオンラインあみだくじサービス「あみださん」の構築において、約40万行に及ぶコードとインフラを一人で完結させた。この成果を支えたのは、GitHub CopilotからClaude Codeへと至るAIツールの進化と、それに対応して進化させた「AIとの協働を前提とした設計手法」である。著者は、AIに丸投げするのではなく、AIが効率的にコンテキストを理解できる「土台」を人間が用意することの重要性を強調している。

具体的に提示されている手法は、AIの推論を制御するための「構造化」に集約される。アーキテクチャ面では、フロントエンドにレイヤードアーキテクチャ、バックエンドにクリーンアーキテクチャを採用し、AIが必要なコンテキストを最小限の探索で収集できるよう整理している。ドキュメント管理においては、`docs/todo`（計画）と`docs/done`（完了）ディレクトリを使い分けることで、セッションごとのコンテキスト肥大化を防ぎ、実装意図を明確に残す運用を提案している。

また、プロンプトエンジニアリングにおける独自の知見として、「重い言葉」の使用を挙げている。例えば「シンプルに」という抽象的な指示ではなく、「YAGNI」や「KISSの法則」といったソフトウェアエンジニアリング特有の専門用語（ドメイン知識を持った尖った単語）を用いることで、少ない語数で的確にLLMの推論を誘導できると主張する。加えて、`Claude.md`の設定やMCPの選定（Serena, Context7, Playwright）を最小限に絞ることで、コンテキストの汚染を防ぎ、ツールの精度を維持する工夫も凝らされている。

著者は、AI駆動開発のフェーズを「設計・実装・レビュー」に分け、特に設計フェーズでの対話が実装の質を左右すると説く。実装自体はAIに任せつつも、人間はエディタを監視し、意図と異なる挙動を即座に中断させる「監督者」としての役割を担う。2025年時点において、大規模プロジェクトを個人で完遂するためには、AIの進化に合わせつつ、人間側の設計力と判断力を「AIが理解しやすい形式」で出力し続けることが不可欠であるというのが著者の結論である。

## 深い考察

### 巨人の肩に乗る

https://zenn.dev/ymd/articles/084336a54fb6d5

本記事は、AIによる科学論文の自動実装能力と、それを用いた暗号資産（仮想通貨）トレード戦略の構築、そして2025年の「仮想通貨 Advent Calendar」から得られた市場インサイトを統合的に解説したものである。

著者が特に注目しているのは、科学論文の再現性を測定するベンチマーク「PaperBench」において、商用コードエージェント「DeepCode」が示した圧倒的なパフォーマンスだ。DeepCodeは、トップ大学の機械学習博士（ML PhD）やClaude Code、Cursorといった既存の主要ツールを大きく上回る正答率（84.8%）を叩き出しており、同一のLLMを用いながらも「ハーネス（制御機構）」の最適化によって実装精度が劇的に向上することを示唆している。これにより、エンジニアの役割は「論文を読み解きコードに落とし込む作業」から、AIが生成した実装プランの妥当性を検証し、どの論文の手法を適用すべきかという「戦略的判断」へと明確にシフトしていると筆者は述べている。

また、著者はこの「AIの肩」を借りるアプローチをトレード戦略に応用。Batch Normalizationの再現やペアトレーディング論文の自動実装プラン生成を通じ、AIがいかに詳細なディレクトリ構造や設定パラメータ、検証項目までを網羅できるかを実証している。一方で、技術的に高度な実装が可能になったからこそ、「戦う場所（戦場）の選択」が重要になると主張する。

NotebookLMを用いた「仮想通貨 Advent Calendar 2025」の分析によれば、技術力だけで勝負するレッドオーシャンを避け、新興・マイナープロトコルやAPI未提供の領域をブラウザ操作で力技攻略する「ブルーオーシャン戦略」こそが、現在のマーケットで生き残る鍵であるという。著者は「Botは不労所得ではなく、過労所得である」という先人の至言を引用し、AIによる自動化が進んでもなお、戦略の起点や継続的なメンテナンスには人間の泥臭い洞察と努力が不可欠であると結論付けている。実装能力が民主化されるAI時代において、真の差別化要因は「ドメイン知識に基づいた仮説立案」と「市場の構造的隙間を見出す嗅覚」にあることを強調している。

### AIによる長期タスク実行能力の測定：完了までの時間が7ヶ月ごとに倍増

https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/

AI評価機関のMETR（旧称:ARC Evals）は、AIエージェントの能力を測る新たな指標として「タスク完了までの時間軸（Time Horizon）」を提唱した。これは、人間が完了するのに要する時間に基づき、AIがどれほどの長さのタスクを自律的に完遂できるかを定量化するものだ。著者は、現在のフロントエンドモデル（Claude 3.7 Sonnet等）は、人間が数分で終わらせるタスクには100%近い成功率を示すが、4時間を超えるタスクでは成功率が10%未満に急落すると指摘する。しかし、この「完遂可能なタスクの長さ」は過去6年間、約7ヶ月ごとに2倍のペースで指数関数的に成長している。

ウェブアプリケーションエンジニアにとって、この報告はAIとの協働プロセスの転換点を示唆している。従来のベンチマークは知識や単発の推論（スプリント能力）を重視してきたが、実務レベルの「エージェント」には、数時間から数日間にわたる複数のステップやツール利用、エラー修正を自己完結させる「耐久力」が必要となる。著者の分析によれば、この成長トレンドが今後数年続けば、現在は人間の専門家が数日、あるいは数週間を費やすようなソフトウェア開発プロジェクトを、AIエージェントが自律的に完了できる時代が10年以内に到来するという。

著者がこのアプローチを重要視する理由は、AIの性能向上が実世界のインパクトにどう直結するかを予測しやすくするためだ。従来の「正答率」という尺度では、100%に近づくにつれて実用性の向上が見えにくくなる。一方で「時間軸」で測れば、数分の作業の自動化から数ヶ月のプロジェクトの自動化までを単一の対数スケールで捉えられる。筆者は、現在のAIが日常業務を代替しきれていないのはスキル不足ではなく、長いシーケンスを破綻なく繋ぎ合わせる能力の不足であると分析しており、この時間軸の延伸こそが「AIによる労働の代替」を測る真のシグナルになると主張している。開発現場における将来のワークフロー設計において、AIが担える「タスクの長さ」を前提にした戦略的判断が必要になる。

### 自律的な言語-画像生成ループは普遍的なビジュアルモチーフへ収束する

https://www.cell.com/patterns/fulltext/S2666-3899(25)00299-5

Arend Hintze、Frida Proschinger Aström、Jory Schossauらによる本研究は、AIシステムが自らの創造的アウトプットを生成し評価するようになった場合、創造性そのものがどのように進化するかという根源的な問いに取り組んでいる。Patterns誌（Cell Press）にて2025年12月19日にオープンアクセスで公開された本論文は、最先端の画像記述モデルと画像再生成モデルを組み合わせ、両者を人間の介入なしに相互作用させた際の挙動を分析している。

研究チームが発見したのは、こうした自律的なループが、灯台（lighthouse）、大聖堂（cathedral）、宮殿内装（palatial interior）といった、極めて慣習的で限定されたビジュアルモチーフの集合へと収束するという事実である。これは、AIが生成する画像が、多様性を失い、ステレオタイプ化されたイメージへと傾倒していくことを示唆している。言い換えれば、人間の判断や介入がない場合、AIは「創造性」を拡張するのではなく、むしろ最も一般的で予測可能なパターンへと退行する傾向があることが明らかになった。

この現象は、Webアプリケーションエンジニアやプロダクト開発者にとって、重要な警鐘である。生成AIを活用したサービス設計において、モデルの出力を自動的にフィードバックループに組み込む場合、意図せず「画一化」や「創造性の劣化」を引き起こすリスクがある。特に、ユーザー生成コンテンツの自動生成、推薦システムにおけるコンテンツ生成、あるいは自律的なクリエイティブエージェントの実装においては、人間による品質管理や多様性の担保が不可欠であることを、本研究は示している。

また、本研究の知見は、AIによる「創造性」が、人間のそれとは本質的に異なる構造を持つことを示唆している。AIは膨大なデータから学習した統計的パターンに基づいて生成を行うため、自律的に動作させた場合には、データセット内で最も頻出する「平均的なイメージ」へと収束する。この傾向は、AIが真に「新しいもの」を創造する能力に限界があることを意味する。

Webアプリケーションエンジニアとしての実践的な示唆としては、生成AIを使ったプロダクトにおいて、アウトプットの多様性をモニタリングし、定期的に人間が介入して新たなシードや制約を与える仕組みを設計することが推奨される。また、生成AIのフィードバックループを設計する際には、収束を防ぐためのランダム性の導入や、異なるモデルの併用、あるいは外部データソースからの定期的な刺激が重要となる。本研究は、AI主導の創造プロセスにおける「人間の役割」の再定義を迫る、極めて重要な知見を提供している。

### AIエージェントの最前線~シングルからマルチAIエージェントへの進化につながる技術とマルチAIエージェントの現在地~

https://zenn.dev/mkj/articles/10ee4ced3d7aaf

松尾研究所による本記事は、大規模言語モデル（LLM）を基盤としたAIエージェントの最新技術動向と、現在直面している課題を包括的に調査したものである。シングルエージェントの限界を突破する手段として期待されるマルチAIエージェント（MAA）について、オーケストレーション、通信、メモリ、最適化、セキュリティという5つの核心的要素から深掘りしている。

技術面では、エージェント間の連携を支える「オーケストレーション」のパターン（シーケンシャル、グループチャット、ハンドオフ等）や、エージェント間通信の標準化を目指すMCP（Model Context Protocol）やA2A（Agent-to-Agent Protocol）といったプロトコルの重要性を解説。また、単なる履歴保持を超えた「共有メモリ」による自己進化や、他者の意図を推論する「心の理論（Theory of Mind）」を導入した協調最適化、さらにはマルチエージェント強化学習（MARL）の最新手法（MAPoRLやMAGRPO）など、アカデミックかつ実践的な知見が提示されている。セキュリティ面では、エージェント間の信頼を悪用する「Confused Deputy（混同代理人）」問題や、間接プロンプトインジェクションといった分散システム特有の脅威についても警鐘を鳴らしている。

しかし、本記事の最も重要な指摘は、2025年に公開された最新の論文（Google/MITの"Towards a Science of Scaling Agent Systems"等）を引用した「マルチエージェント化の現在地」に関する冷静な分析にある。筆者によれば、o1のような高度な推論能力を持つモデルの登場により、多くのタスクではシングルエージェントの方が高精度かつ低コストである場合が増えている。特に逐次的な推論タスクにおいては、マルチ化が情報の断片化や通信ノイズ、コンテキスト汚染を招き、性能を39〜70%も低下させるリスクがあるという定量的な事実を紹介している。

筆者は、AIエージェントはもはや「モデル性能を補うための手段」ではなく、「タスク構造に適合したときにのみ意味を持つ設計選択」へと位置づけが変わりつつあると主張している。Webエンジニアにとっての重要課題は「マルチかシングルか」という二択ではなく、タスクの性質を見極めて適切にアーキテクチャを選択する「設計力」にある。並列化や専門分化が本質的に必要な長期プロセスや組織境界を跨ぐケースに限定してマルチ化を検討すべきであり、安易なマルチ化ブームに流されないための指針として、極めて価値の高い内容となっている。

### LLMは人格を持つか?ペルソナ推定に関して

https://techblog.insightedge.jp/entry/llm-persona-estimation

本記事は、LLMに特定の役割を演じさせる「ロールプレイング」と、ユーザーの入力からその属性や性格を推察して回答を最適化する「パーソナライゼーション」の2軸から、ペルソナ推定の有効性を技術的に検証している。著者は、一律的な回答を超えて状況に応じた柔軟な対応を実現することが、次世代のAIサービスにおけるCX（顧客体験）向上の鍵であると説く。

具体的な手法として、GPT-4o-miniを用いたプロンプトエンジニアリングの実例が紹介されている。第一の検証では、同一の問い合わせに対し「温かく活発な専門家」と「冷静で事務的な専門家」という相反するペルソナをシステムプロンプトで定義。結果、回答内容の本質的な情報は維持しつつも、出力される文体や「internal_thought（内部思考）」フィールドでの処理が劇的に変化することを実証した。これは、提供するサービスのブランドイメージに合わせてLLMの挙動を制御する上で極めて実用的なアプローチである。

第二の検証では、より高度な「ユーザー側のペルソナ推定」に焦点を当てている。システムプロンプト内で「Step 1: ペルソナ推定」「Step 2: 法的整理」「Step 3: 同調したトーンでの回答」という多段階の思考プロセスを定義。論理的な社員と不安を抱える社員という異なるタイプの相談に対し、LLMが属性・性格・ニーズをプロファイリングし、それに基づいた最適な法的アドバイスを生成する過程を具体的に示している。例えば、不安を感じているユーザーに対しては「心身の健康が最優先」といった共感的なフレーズを組み込むなど、推定されたペルソナに同調したトーンの切り替えが自動で行われる。

筆者は、ペルソナ推定を組み込むことで、単なる情報提供に留まらない「ユーザーの心理的コンテキストを汲み取った振る舞いの設計」が可能になると主張している。エンジニアにとって、APIのシステムプロンプトを工夫するだけで、特定のドメインやユーザー層に特化した高度なパーソナライゼーションを実装できる点は、アプリケーションの差別化において非常に大きな示唆を与えてくれる。今後、市場調査やカスタマーサポートの自動化において、このペルソナという側面を考慮することが新たな価値創造に繋がると結論付けている。

## ビジネス・社会的インパクト

### 高校の「数学」再編へ　AIの学び重視しA、B、Cの区分なくす方向

https://www.asahi.com/articles/ASTDN55SJTDNUTIL02ZM.html

文部科学省は、高校数学の教育課程を抜本的に再編し、AI（人工知能）やデータサイエンスの習得を教育の核に据える方針を固めた。最大の変更点は、長年続いてきた「数学A」「数学B」「数学C」という科目区分を廃止し、これらを一つの科目として統合することだ。これにより、生徒はベクトルや数列といった各項目を、自身の進路や関心に合わせて柔軟に組み合わせて学ぶことが可能になる。

この変革の背景には、現代社会において必須の教養となりつつあるAI技術の基礎を、全ての高校生に保障したいという国の強い危機感がある。著者が解説するように、AIやデータサイエンスの土台となる「行列」「確率」「統計」といった概念は、現行の指導要領では数学A・B・Cに分散して配置されている。しかし、数学Bの履修率が約45%、数学Cが約34%にとどまっている現状が示す通り、多くの生徒がこれらの重要項目を学ばずに卒業している。文系・理系の早期分断が、高度なデジタル社会に対応する人材育成の障壁となっているのが現状だ。

新たな指導要領では、必履修科目である「数学I」の内容を強化し、行列や確率の基礎を実生活の課題解決に関連付けて学ぶ「社会を読み解く数学（仮称）」を新設する。これにより、すべての高校生がAI時代の「共通言語」としての数学的素養を身に付けることが期待されている。さらに、数学の有用性を実感させ、学習の動機付けを強化するために、学問の全体像や社会での活用事例を紹介する「数学ガイダンス（仮称）」も導入される。

この再編は2032年度からの導入を目指しており、単なる科目の整理統合にとどまらず、日本の教育システム全体を「AIネイティブ」な社会実装に合わせて最適化しようとするものである。エンジニアにとっても、将来的にチームを組む非エンジニア層の数学的リテラシーが底上げされることは、データに基づいた意思決定やAIツールの活用が社会全体で一般的になることを意味しており、その社会的意義は極めて大きい。

### ディズニーとOpenAIの提携、キャラクター独占使用権は1年のみと判明

https://techcrunch.com/2025/12/15/disneys-openai-deal-is-exclusive-for-just-one-year-then-its-open-season/

ディズニーがOpenAIと締結した3年間のライセンス契約において、キャラクターの独占使用権は最初の1年間のみであることが、同社CEOボブ・アイガー氏の発言により明らかになった。この契約により、OpenAIの動画生成AI「Sora」は、マーベル、ピクサー、スター・ウォーズを含む200以上のディズニーキャラクターを合法的に利用できる唯一のプラットフォームとなるが、1年が経過した後は他社のAI企業とも同様の提携が可能になる「オープン・シーズン」を迎える。

筆者は、この短期間の独占設定を、ディズニーが自社の知的財産（IP）を生成AI分野でどのように活用・保護すべきかを評価するための「観測気球」であると分析している。アイガー氏は、技術の進歩を阻むのではなく、既存のビジネスモデルを破壊する可能性があっても積極的に関与すべきだという実利的な姿勢を示している。

また、本提携の発表と同時に、ディズニーがGoogleに対して著作権侵害の停止勧告を送ったことも報じられている。これは、正規のライセンス契約を結ぶ相手（OpenAI）と、無断で学習に利用する相手（Google）を明確に選別し、IPの価値をコントロールしようとするディズニーの「アメとムチ」の戦略を反映したものだ。開発者やプロダクトマネージャーにとって、高品質な商業資産がAIツールに統合される道筋が示された点は重要だが、独占が限定的であることは、将来的に複数の動画生成モデルでディズニーのアセットが利用可能になる競争環境を予唆している。

### OpenAI、ChatGPTでの広告導入を本格検討へ — 会話型UIに最適化した収益化モデルを模索

https://www.suzukikenichi.com/blog/openai-is-developing-an-advertising-strategy-for-chatgpt/

OpenAIがChatGPTにおいて広告ビジネスの展開を検討し始めたことが、複数の報道により明らかになった。週次アクティブユーザー数が9億人に達し、2030年までに26億人への拡大を目指す同社にとって、膨大な非課金ユーザーからの収益化は避けて通れない課題となっている。サム・アルトマンCEOはかつて広告に対して否定的なスタンスを示していたが、現在はデジタル広告分野の専門家を登用し、非課金ユーザー1人あたりの年間平均収益（ARPU）を現在の約2ドルから15ドルへと引き上げる計画を推進している。現在、ChatGPTの有料サブスクリプションを利用しているのはユーザー全体の約5%に過ぎず、広告はこの収益ギャップを埋めるための重要な戦略的柱として位置付けられている。

筆者によれば、OpenAIは単に既存のバナー広告を模倣するのではなく、会話型インターフェースに最適化した3つの広告コンセプトを実験している。一つ目は「スポンサード回答」で、製品比較などのクエリに対して特定のスポンサー情報を優先的に回答に含める手法だ。二つ目は「セカンダリー・ステップ広告」と呼ばれ、旅行プランの作成といった最初の回答では広告を表示せず、ユーザーが詳細リンクをクリックした段階で初めてツアー予約などのスポンサードポップアップを表示する。三つ目は、メインの回答ウィンドウとは別にサイドバーを設け、視覚的に分離した形で広告を表示する案だ。これらは、AIとの自然な対話というユーザー体験を損なわずに広告を統合する試みといえる。

ウェブアプリケーションエンジニアにとってこの動向が重要な理由は、生成AIが「純粋なユーティリティ」から、GoogleやMetaのような「広告プラットフォーム」へと変貌する転換点を示しているからだ。これは将来的に、APIを介したエコシステムやエージェントの挙動にも、スポンサーシップによるバイアスやインジェクションが組み込まれる可能性を示唆している。一方で、導入には高いハードルも存在する。社内ではAGI（汎用人工知能）開発という高潔な目標と広告ビジネスの哲学的な相反に対する反発があり、ユーザー側にもプライバシーへの懸念が根強い。また、現状のChatGPT利用において購入意図のある商用クエリはわずか2.1%に留まっており、広告モデルを成立させるためにはユーザーの利用習慣そのものを変容させる必要があると、著者はその難しさを指摘している。

### 評価プロセスを生成AIで （半）自動化する！人事評価 x AIの境界実験

https://techblog.insightedge.jp/entry/personnel-evaluation-by-ai

マネージャにとって最も精神的負荷の高い業務の一つである「人事評価」に対し、生成AIやAIエージェントをどこまで介入させるべきか、その「境界線」を技術的・組織的視点から考察した記事です。著者はInsight EdgeのCTOであり、評価業務を「情報の収集・整理」「評価軸への照合」「最終判断・対話」の3段階に分解した上で、AIが担うべきは前2者の「作業」に限定し、後者の「判断」は人間が負うべき聖域であると明確に定義しています。

記事では、評価の透明性と納得感を担保するための具体的なデータ収集・整理手法が解説されています。
1. **データソース別の収集戦略**: Slackからは意思決定ログや周囲への巻き込みを（Ubie社公開のSlack MCPサーバ活用）、Google Driveからは成果物の構造化力や論理性を（Gemini Enterprise活用）、GitHubからは単なるコード量ではなく「設計意図」や「トレードオフの判断」が見える代表的なPR（3〜5本）を、GitHub API経由で収集しRAGを構築する手法を提示しています。
2. **評価軸へのマッピングとバイアス検知**: AIには点数付けをさせるのではなく、収集したエビデンスが企業のバリューや評価基準のどの項目に該当するかを分類・説明させる役割を担わせます。さらに、直近の出来事に評価が引きずられていないか、発言量だけで過大評価していないかといった「バイアスの可能性」をAIに列挙させることで、人間の判断を補完する仕組みを提案しています。

著者が最も強調しているのは、「AIはマネージャを『楽』にするが、責任を『軽く』はしない」という点です。昇給や昇格といった個人の人生に直結する意思決定、および成長を促すための感情を伴う対話は人間にしかできない仕事であり、AIの役割はマネージャがその本質的な業務に集中できる環境を整えることにあると主張しています。技術的な実装案だけでなく、人事評価という極めてセンシティブな領域において、AIとの共存をどう設計すべきかという哲学的な指針が含まれており、エンジニア組織のリーダーにとって非常に実用性の高い内容となっています。

## 編集後記

今週のAnnexは、生成AIという現象を多様なレンズで捉え直す試みとなりました。

「クリエイティブな実験」では、技術を道具として使い倒すクリエイターたちのエネルギーを感じました。NotebookLMとChatGPTを組み合わせて2日でアニメ動画を作る、Nano Banana Proで10ページの漫画を描く、エージェントに投資戦略を立案させる――こうした実践は、AIが単なる業務効率化ツールではなく、「作りたい」という意志さえあれば誰もがクリエイターになれる時代を予感させます。

「批判的視点」では、技術への盲信を戒める声に耳を傾けました。画像生成AIの「不完全さ」の価値を説くボレッティの論考、AIによる価格操作や監視の実態を暴く報道、アーティストを保護するGlazeの取り組み――これらは、進歩の裏側にある倫理的問題や構造的歪みを浮き彫りにします。高木浩光氏による「処遇AI」と「生成AI」の混同への警告も、技術議論の粗雑さに一石を投じるものでした。

「先進的な戦術」では、エージェント開発の最前線が垣間見えました。Vercelがツールの8割を削除してファイルシステムに委ねる大胆な設計転換、松尾研が実践するgit worktreeとSubagentループによる並列開発、tmuxとフックを駆使した通知システム――いずれも「AIをシステムの一部として組み込む」発想の具体例です。40万行のプロジェクトを一人で完結させた事例は、AI時代の個人開発の可能性を示しています。

「深い考察」では、より本質的な問いに向き合いました。METRのタスク完了時間指標は、AIの能力を測る新たな視座を提供し、Patternsの論文は創造性の収束問題を突きつけます。松尾研によるマルチエージェントの現在地分析は、流行に流されず設計の本質を見極めることの重要性を説いています。

「ビジネス・社会的インパクト」では、技術が現実世界に与える影響を考えました。高校数学の再編、ディズニーとOpenAIの提携、ChatGPTへの広告導入検討、AIによる人事評価の境界――これらは、生成AIが教育、エンターテインメント、収益モデル、組織運営といった社会の基盤そのものを変容させつつあることを物語ります。

Annexで扱った記事群は、メインジャーナルの補完であると同時に、異なる角度から見た「もう一つの現実」です。技術の進歩を追いかけるだけでなく、立ち止まって問い直す。実験し、批判し、深く考える。そうした姿勢こそが、この急速に変化する時代において、私たちエンジニアに求められているのかもしれません。

次週も、メインとAnnex、両方の視点から生成AI×コーディングの世界を捉えていきます。
