## AIによる画風盗用を防ぐ保護ツール「Glaze」の仕組みと意義

https://glaze.cs.uchicago.edu/what-is-glaze.html

**Original Title**: What is Glaze

敵対的機械学習の原理を応用し、AIモデルによる画風の模倣を無効化する不可視の画像摂動を生成する。

**Content Type**: ⚙️ Tools
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 93/100 | **Overall**: 92/100

**Topics**: [[敵対的学習, 著作権保護, 生成AI, 機械学習セキュリティ, 画像処理]]

シカゴ大学のSAND Labが開発した「Glaze」は、生成AIによるアーティストの画風模倣（Style Mimicry）からクリエイターを保護するためのシステムである。Webアプリケーションエンジニアの視点からは、本作は「敵対的機械学習（Adversarial Machine Learning）」を知的財産保護の実践的なソリューションとして昇華させた、極めて示唆に富む事例と言える。

本ツールの核心は、AIモデルには認識されるが人間には感知できない「摂動（Perturbation）」を画像に加えることにある。具体的には、人間には写実的な肖像画に見える画像であっても、AIモデルが学習する際には「ジャクソン・ポロックのような抽象画」として誤認させるような微細な変更を加える。これにより、特定のアーティストの作品群をStable Diffusionなどのモデルで追加学習（ファインチューニングやLoRA）させても、意図した画風が再現されるのを防ぐ仕組みだ。

著者は、画風の盗用が単なる経済的損失に留まらず、アーティストのアイデンティティそのものを脅かし、創作意欲を減退させている現状を危惧している。技術的な優位点として、Glazeは従来の電子透かし（Watermark）のような脆い技術ではなく、AIの認識プロセスそのものをターゲットにしているため、スクリーンショットやリサイズ、ノイズ除去といった一般的な画像加工攻撃に対しても高い堅牢性を維持する。

エンジニアとして注目すべきは、AIの進化に伴う「防御側」の継続的なアップデートプロセスである。記事内では「IMPRESS」や「Noisy Upscaler」といったGlazeを無効化しようとする最新の攻撃手法（除去アルゴリズム）についても言及されており、それらに対抗するためにバージョン2.1へと進化を続けている。これは、モデルの脆弱性と防御技術の終わりなき軍拡競争の実態を物語っている。

また、本プロジェクトは非営利で運営されており、強力なGPU環境を持たないクリエイターのためにクラウドベースの「WebGlaze」をAWS上で提供するなど、アクセシビリティの確保にも注力している。AIエージェントや生成ツールが普及する中で、データの「提供側」が自己防衛を行うための技術スタックとして、Glazeは重要なマイルストーンとなるだろう。著者はこれが「完全な解決策ではない」と認めつつも、法的・規制的枠組みが整うまでの不可欠な「第一歩」であると主張している。