## 米国の学校で急拡大するAI監視システム：安全か監視社会か

https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/

### 概要

米国の学校で、顔認識、行動分析AI、トイレ音声監視、ドローン、ナンバープレート読取など、AI駆動の監視技術が急速に導入されている。ビバリーヒルズ高校は2024-2025年度に480万ドルをセキュリティに投資。銃乱射事件防止を目的とするが、有効性を示す独立した研究は乏しく、生徒のプライバシーと信頼関係への懸念が高まっている。

### 主なポイント

**導入されている監視技術**
- 顔認識システム（Vaidio）：15台のカメラで顔データベースと照合
- 行動分析AI（VoltAI）：暴力行為の兆候を検出、年間365ドル/ストリーム
- トイレ音声モニター（Motorola Halo）：「助けて」「緊急」などのキーワードを検出
- 銃検出AI（ZeroEyes）：50台のカメラで銃を検出、2023年以降1000件以上検出
- 金属探知機（Evolv）：800校以上で導入、1日85万人の来校者をスクリーニング
- ドローンとナンバープレート読取（Flock Safety）

**導入の背景**
- 2025年の学校敷地内での銃撃による死者：49人
- 2024年：59人、2023年：45人
- 2000-2022年：131人が死亡、197人が負傷（大半が子供）

**効果への疑問**
- ACLUレポート：コロンバイン事件以降の大規模銃撃事件10件中8件は、監視システムが導入されていたキャンパスで発生
- 独立した研究によるAI監視の有効性の検証が不足
- ランコーカスバレー高校：アクティブシューター訓練で銃撃者の逮捕時間が半減（学校側主張）

**誤検知の問題**
- Evolv：ノートPC、水筒を銃と誤認識。2022年に7インチのナイフを検出できず生徒が刺される事件
- Omnilert：ドリトスの袋を銃と誤認識し、16歳生徒が警察に銃を向けられる
- ZeroEyes：2023年のテキサス州の学校で誤警報によりロックダウン

**プライバシーへの懸念**
- 14-18歳の生徒の32%が「常に監視されている」と感じる
- 生徒が精神的健康問題や身体的虐待を教育者に報告しにくくなる
- カリフォルニア州では、公立学校は顔認識システムへの登録を保護者・生徒・教師に通知する法的義務なし
- ビバリーヒルズの教師組合：図書館やフィットネスセンターへのカメラ設置に対し苦情を申し立て

**セキュリティリスク**
- 2025年、ポートランドの10代がHaloデバイスをハッキングし、トイレでの会話を永続的に記録できるリスニングデバイスに変換
- 管理者パスワードの推測制限がなかったことが原因（現在は修正済み）

**コストと実用性**
- ビバリーヒルズ学区：「安全とセキュリティへの投資額に異論を唱える保護者やコミュニティはいない」
- ハイライン学区（ワシントン州）：ZeroEyesとの年間33,000ドルの契約を2年残して解約。代わりに除細動器とSUV車両を購入

**生徒・保護者の反応**
- 賛成派：脅威が増加する中、予防的措置として支持。「誰かが常に生徒を見守っているという感覚」
- 反対派：「監視されていると感じる人を信頼しない」ため信頼関係が崩れ、実際には安全性が低下

### なぜ注目すべきか

学校の安全対策としてのAI監視は、技術的解決策と倫理的懸念の間で揺れ動く現代の縮図である。銃乱射事件という深刻な脅威に対し、学校は最新技術に巨額を投資しているが、その有効性は未証明で誤検知も多い。一方で、常時監視は生徒のプライバシーを侵害し、教育現場の信頼関係を損なう可能性がある。カリフォルニア州のように法的規制が追いついていない地域では、生徒や保護者の知らないうちに顔データが収集される事態も起きている。セキュリティとプライバシーのバランス、AI技術の限界と責任、そして「安全のためなら何でも許される」という風潮への警鐘として、この問題は重要である。
