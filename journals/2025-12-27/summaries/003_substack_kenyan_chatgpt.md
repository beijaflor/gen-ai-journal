## 「私はケニア人だ。ChatGPTのように書いているのではない。ChatGPTが私のように書いているのだ」

https://marcusolang.substack.com/p/im-kenyan-i-dont-write-like-chatgpt

**Original Title**: I'm Kenyan. I Don't Write Like ChatGPT. ChatGPT Writes Like Me.

AI生成特有とされる「形式的で構造的な文章スタイル」が、実は植民地時代の教育に根ざした非ネイティブ圏の正統な英語表現であることを指摘し、AI検知アルゴリズムに潜む文化的なバイアスを告発する。

**Content Type**: 💭 Opinion & Commentary
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:5/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 78/100 | **Annex Potential**: 81/100 | **Overall**: 76/100

**Topics**: [[AIバイアス, AI検知ツール, 学習データ, 非ネイティブ英語, アルゴリズムの公平性]]

ケニア出身のライターである著者は、自身が心血を注いで執筆した企画書に対して「ChatGPTが書いたような文章だ。もっと人間味のある（Human touch）修正をしてほしい」というフィードバックを受けた経験から、現代のAI言説に潜む深刻な問題を提起している。著者の主張によれば、AI検知ツールや人々が「AIっぽい」と判定する根拠となる、構造化された論理構成や丁寧な接続詞の多用、バランスの取れた文末表現は、ケニアをはじめとする旧英国植民地諸国で徹底されてきた「正統な英語教育」の賜物であるという。

筆者は、自身が受けてきたケニアの教育システム（KCPEなど）が、曖昧さを排除し、豊かで洗練された語彙と厳格な構造を重視する「クイーンズ・イングリッシュ」の習得を、社会的成功の絶対条件として課してきた歴史を詳述している。皮肉なことに、ChatGPTなどの大規模言語モデル（LLM）もまた、過去数世紀の書籍、学術論文、法的文書といった、極めてフォーマルで構造化されたデータセットで学習されている。つまり、AIが人間のように書くのではなく、権威ある形式的な教育を受けた人間が書くスタイルをAIが模倣した結果、両者が酷似するに至ったのである。

この事実は、現在のAI検知ツールが採用している「Perplexity（当惑度：予測のしにくさ）」や「Burstiness（バースト性：文の長さや構造の多様性）」といった指標が、特定の文化的背景を持つ人々に対して差別的に機能していることを示唆している。非ネイティブスピーカーは、教育過程で「予測可能で論理的（＝低Perplexity）」かつ「整然とした（＝低Burstiness）」文章を書くよう訓練されている。その結果、AI検知ツールは非ネイティブによる完璧な英語を「非人間的」と誤判定する傾向が強いという研究結果も紹介されている。

ウェブアプリケーションエンジニアやAI開発者にとって、本記事は「人間らしさ」を定義するアルゴリズムがいかに狭量で欧米中心的な偏りに満ちているかを再認識させるものである。AIを用いたコンテンツ評価や、AIツール自体のUX設計において、「カジュアルで崩れた表現＝人間的」という短絡的な定義を採用することは、グローバルな文脈におけるプロフェッショナルなスキルを否定するリスクを孕んでいる。著者は、指をさして「AIだ！」と叫ぶ前に、それが異なる教育や歴史、基準の結果として生み出された「別の形の人間性」である可能性を考慮すべきだと強く訴えている。