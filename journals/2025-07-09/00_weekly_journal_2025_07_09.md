# 週刊Gen-AIジャーナル 2025年7月9日号

今週は、AIエージェントが単なる「ツール」から、開発ワークフロー全体を自律的に動かす「システム」へと進化する大きな転換点を示す週となりました。特に、エージェントを信頼性の高いソフトウェアとして構築するための設計原則「12-Factor Agents」の提唱や、LLMを推論エンジンではなく「コード生成器」として捉え直す議論は、今後の開発スタイルの核心に迫るものです。

また、AIエージェントの性能を最大限に引き出すための「コンテキストエンジニアリング」という概念が、単なるプロンプト作成技術を超えた、より体系的なアプローチとして注目されています。開発のボトルネックはコードを書くこと自体にはなく、むしろその周辺にあるという指摘も、AI時代のエンジニ���リングの本質を突いています。

今週の動向は、AIとの協業が新たなフェーズに入り、開発者がより高レベルな設計と思考に集中できる未来を示唆しています。

---

## 特集：AIエージェントの進化と開発思想の転換

### 1. AIエージェント開発の新標準「12-Factor Agents」
- **情報源**: [12-Factor Agents](https://github.com/humanlayer/12-factor-agents)
- **概要**: 信頼性の高いLLMエージェントを構築するための12の原則。従来の「12-Factor App」をAI時代に適用し、プロンプト管理、ツールの構造化、ステートレスな設計などを提唱。
- **編集者ノート**: LLMエージェント開発が、実験的な段階から本格的なソフトウェアエンジニアリングへと移行していることを示す重要な提言です。これにより、より堅牢で保守性の高いAIアプリケーションの開発が加速するでしょう。

### 2. LLMは推論より「コード生成」に使うべき
- **情報源**: [Tools: Code Is All You Need](https://lucumr.pocoo.org/2025/7/3/tools/)
- **概要**: LLMに���接推論させるのではなく、コードを生成させて実行する「LLM→コード→LLM」パイプラインを提唱。このアプローチは、結果の信頼性とスケーラビリティを高める。
- **編集者ノート**: AIによる自動化を「魔法」ではなく、開発者が管理・制御可能な「ツール」として捉え直す視点は、現実的な開発ワークフローへの統合を示唆しています。

### 3. 「エージェンティック・コーディング」時代の到来
- **情報源**: [Claude CodeではじめるAgentic Coding入門](https://buildersbox.corp-sansan.com/entry/2025/07/03/142500)
- **概要**: AIエージェントが自律的に計画・実行する新しいコーディングスタイル。開発者は目標を与えるだけで、その達成プロセスをAIに委ねる。
- **編集者ノート**: 定型的なタスクをAIに任せることで、開発者はより創造的で複雑な問題解決に集中できるようになります。これは開発の生産性を劇的に向上させる可能性を秘めています。

---

## MCPと開発エコシステム

### 4. MCP：AIアシスタントから「意図せぬ」普遍的プラグインシステムへ
- **情報源**: [MCP: An (Accidentally) Universal Plugin System](https://worksonmymachine.substack.com/p/mcp-an-accidentally-universal-plugin)
- **概要**: MCPがAIアシスタントの機能拡張を超え、様々なアプリケーションを接続する汎用的なプラグインシステムへと進化していることを論じる。
- **編集者ノート**: 特定のプラットフォームに依存しない、再利用可能なコンポーネントエコシステムへの移行を示唆しており、開発ワークフローのモジュール化を促進するでしょう。

### 5. MCPはAPIではない：LLMとの連携に特化したツール連携プロトコル
- **情報源**: [MCPはAPIではない - 単純変換してはいけない理由](https://memo.tyoshida.me/power-platform/copilot-studio/mcp-is-not-api/)
- **概要**: MCPは従来のAPIとは異なり、LLMが外部サービスと対話するための「ツール」を提供するプロトコルであると解説。
- **編集者ノート**: 開発者はAPIをAIが理解しやすい「ツール」とし���再定義するスキルが求められます。これにより、AIエージェントはより複雑なタスクを自律的に実行可能になります。

---

## AI開発ワークフローの革新

### 6. 「出力を修正せず、入力を修正する」パーソナルAIファクトリー
- **情報源**: [Building a Personal AI Factory](https://www.john-rush.com/posts/ai-20250701.html)
- **概要**: AIが生成したコードを直接修正するのではなく、計画やプロンプトといった「入力」を改善することで、自己改善するエージェントを構築するワークフロー。
- **編集者ノート**: AIとの協働におけるパラダイムシフトです。開発者はコード修正者から、AIエージェントを「設計・管理する」役割へとシフトしていくでしょう。

### 7. Claude Code Hooksによる開発ワークフローの自動化
- **情報源**: [Claude Code Hooks](https://docs.anthropic.com/en/docs/claude-code/hooks)
- **概要**: Claude Codeのライフサイクルの様々な段階でシェルコマンドを実行し、コードフォーマット、通知、カスタム権限などを自動化する。
- **編集者ノート**: 開発プロセスへの深い統合を可能にし、AIエージェントが単なるコード生成ツールから、開発パイプライン全体を管理・最適化するコアコンポーネントへと進化する流れを加速させます。

### 8. GitHub Copilotのエージェントワークフロー
- **情報源**: [From idea to PR: a guide to GitHub Copilot’s agentic workflows](https://github.blog/ai-and-ml/github-copilot/from-idea-to-pr-a-guide-to-github-copilots-agentic-workflows/)
- **概要**: Copilotのエージェント機能を活用し、アイデア出しからプルリクエスト作成まで、開発プロセス全体を効率化する。
- **編集者ノート**: ローカライズのような定型タスクをAIに任せることで、開発者はより本質的な問題解決に時間を割けるようになります。

---

## コンテキストエンジニアリングの重要性

### 9. コンテキストエンジニアリング：AI時代の新たなスキル
- **情報源**: [Context Engineering for Agents](https://rlancemartin.github.io/2025/06/23/context_engineering/), [Context Engineering: The New Skill in AI](https://www.philschmid.de/context-engineering)
- **概要**: LLMエージェントの性能は、プロンプトだけでなく、提供されるコンテキスト全体の質に依存する。「書き込み」「選択」「圧縮」「分離」といった戦略が不可欠。
- **編集者ノート**: LLMのコンテキスト管理は、現在の開発ワークフローにおけるボトルネックです。これらの戦略は、エージェントの能力を飛躍的に向上させるフレームワークとなるでしょう。

### 10. LLMのメモリ実装における考察
- **情報源**: [LLM Memory](https://grantslatton.com/llm-memory)
- **概要**: LLMの文脈ウィンドウの限界を克服するため、ナレッジグラフやベクトル埋め込みといった長期記憶を実装するアプローチを提示。
- **編集者ノート**: AIが過去のプロジェクト履歴やデバッグ経験を「記憶」し、より文脈に沿ったコード生成を行う未来を示唆しています。

---

## AI開発の現実と課題

### 11. ソフトウェア開発の真のボト��ネック
- **情報源**: [Writing Code Was Never The Bottleneck](https://ordep.dev/posts/writing-code-was-never-the-bottleneck)
- **概要**: 開発の真のボトルネックはコード記述ではなく、レビュー、知識共有、テスト、デバッグといった人間的で複雑なプロセスにあると指摘。
- **編集者ノート**: AIがコード生成を補助する一方で、これらの「非コード生成」プロセスへの負荷は増大する可能性があります。AIをこれらのプロセスにどう組み込むかが新たな挑戦です。

### 12. LLMの「ポチョムキン理解」という弱点
- **情報源**: [What is "Pochomkin Understanding"?](https://xenospectrum.com/what-is-pochomkin-understanding-the-decisive-weakness-of-llm-exposed-by-harvard-university-and-others/)
- **概要**: LLMが概念を説明できても、実践では一貫して適用できない「見せかけの理解」を持つ可能性を指摘。
- **編集者ノート**: LLMの出力を鵜呑みにせず、その「理解度」を測るためのより実践的な評価手法が求められます。

### 13. AI生成コードのセキ���リティリスク
- **情報源**: [Risks of AI-Generated Code (CSET Report Summary)](https://qiita.com/hokutoh/items/5119872f45845dee78bf)
- **概要**: AIモデルは脆弱性のあるコードを生成するリスクがあり、開発者は厳格なレビュープロセスを適用する必要がある。
- **編集者ノート**: AI生成コードの静的・動的解析をCI/CDパイプラインに組み込むことが標準化され、AIを「強力だが注意が必要なアシスタント」として捉える必要があります。
