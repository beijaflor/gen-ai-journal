## 【生成AI】プロンプトインジェクションを防ぐ方法【LLM】

https://qiita.com/keiichileograph/items/b6d76fcb5f90883ea9f7

LLMシステムにおけるプロンプトインジェクション攻撃を防止するため、リクエスト制限、機密情報分離、String Format活用、そして多段階LLM連携といった具体的な防御策を提示する。

**Content Type**: Tutorial & Guide

**Scores**: Signal:3/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 106/100 | **Annex Potential**: 100/100 | **Overall**: 76/100

**Topics**: [[Prompt Injection, LLM Security, Prompt Engineering, System Architecture, API Security]]

この記事は、LLMを活用したサービス開発において極めて重要な「プロンプトインジェクション」攻撃への具体的な対策を、ウェブアプリケーションエンジニア向けに解説しています。プロンプトインジェクションとは、ユーザーが生成AIに対してシステム側の意図しない動作を引き起こさせ、機密情報の流出、API使用料の高騰、サーバー負荷の増大といった被害をもたらす攻撃の総称です。

その防御策として、まずユーザーのリクエスト回数を制限する基本的なアプローチを提示。これにより、APIコストの暴騰やリソース枯渇を防ぎ、安定したシステム運用を確保します。次に、パスワードやシークレットキー、SQL文といった重要情報をLLMに直接渡さない設計の重要性を強調。多くの攻撃が機密情報の引き出しを狙うため、AIへの入力段階での徹底した分離が第一線の防御策となります。

さらに具体的なプロンプトエンジニアリングの観点からは、「String Format概念」の利用を推奨しています。ユーザーからのテキストを直接LLMに渡すのではなく、あらかじめ定義されたシステム側のテンプレートに文字列として埋め込むことで、ユーザー入力がAIの指示系統に干渉するのを防ぎます。PHPのコード例を挙げ、`{{code}}`のようなプレースホルダーを使って入力を安全に組み込む具体的な手法を示しています。

最終手段として、LLMを二段階に連ねるアーキテクチャも紹介。ユーザーからの入力が「システムが処理すべき内容か」を判断する専用のLLMを前段に配置することで、より強固なフィルターとして機能させます。これは処理速度とコストを犠牲にするものの、極めて安定したシステム運用には有効な選択肢となります。

これらの対策は、単なるプロンプト調整に留まらず、LLMサービスの堅牢な運用とセキュリティ確保のためにウェブアプリケーションエンジニアが実践すべき具体的なアーキテクチャ設計・実装指針を示しており、現代のAI活用サービス開発において不可欠なノウハウを提供します。