## AIプログラムの開発演習に使う低消費リソースローカルLLMはQwen3 1.7B Q4がベスト

https://nowokay.hatenablog.com/entry/2025/08/30/104903

著者は、AIプログラム開発演習向けローカルLLMとして、低リソース環境で安定した指示追随性とツール呼び出し性能を持つQwen3 1.7B Q4_K_Mを推奨する。

**Content Type**: Opinion & Commentary

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 87/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[Local LLM, AI Programming Exercises, Qwen3, Function Calling, Resource Optimization]]

「きしだのHatena」の著者は、AIを組み込むプログラミング、特にRAGやエージェント開発といった演習において、参加者のPCリソースが限られる状況を考慮し、最適なローカルLLMの選定基準と具体的な推奨モデルを共有しています。

重要なのは、知識量やハルシネーションの少なさよりも「指示追随性」と「ツール呼び出し（Function Calling/MCP）の安定性」です。これらの能力が不安定だと、プログラムのバグかLLMの出力の問題か判別が困難になります。著者の検証によれば、ファイルサイズ約1.2GBで1.5GB程度のメモリと4コアCPUがあれば動作する「Qwen3 1.7B Q4_K_M」が、この用途において最もバランスの取れた選択肢であると結論付けられました。これは、Qwen3 4B Q2Kの不安定さや、量子化による性能劣化（特にQ2_K）を避けるためです。ただし、1.7Bモデルはシステムプロンプトが長くなる際の動作が不安定で、長文プロンプトに対する思考抑制（/no_think）も機能しにくいという限界も指摘されています。

実際に開発を行う場合は、より強力なモデルとして「Qwen3 14B Q4_K_M」が推奨されます。これはファイルサイズとリソース消費を抑えつつ、推論力と動作の安定性を兼ね備えているためです。特にユニットテストのようにLLMを頻繁に呼び出す開発工程で、API課金を気にせずに安心して利用できる点がメリットです。他のモデル（Qwen3 32B, GPT-oss 20B, Gemma 3, Devstral Smallなど）も試されたものの、安定性やツール呼び出し能力に課題が見られました。

最終的な使用感の確認や本番環境への導入を検討する際は、14BのQ8モデルや、Qwen3 Coder、GPT-5、Claude 4といった商用ハイエンドモデルの利用が推奨されています。この選定ガイドは、限られた環境でAIプログラミング学習や初期開発を進めるウェブアプリケーションエンジニアにとって、具体的なモデル選定の指針となるでしょう。