## TypeScriptファーストなコーディングAIエージェントのベンチマーク「ts-bench」を公開しました

https://blog.lai.so/ts-bench/

laisoは、AIコーディングエージェントのTypeScriptコード編集能力を実用的に評価するため、手軽に再現可能なベンチマークツール「ts-bench」を公開しました。

**Content Type**: Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 89/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[AIコーディングエージェント, TypeScript, ベンチマークツール, LLM評価, 開発ワークフロー]]

「laiso」が公開した「ts-bench」は、Webアプリケーション開発に不可欠なTypeScriptに特化したAIコーディングエージェントのベンチマークツールです。既存のベンチマークがPythonのアルゴリズム問題に偏りがちな中で、本ツールは静的型付け言語であるTypeScriptの特有の課題、すなわち型チェッカーやビルドツール、テストランナーからの厳格なフィードバックループにAIエージェントがどう対応するかを評価します。これは、一度の生成で正解を出すpass@1のような単純な指標ではなく、コード編集とテスト実行を繰り返しながら問題を解決していく、より実用的な開発プロセスを再現している点が重要です。

ts-benchの仕組みは、プログラミング学習プラットフォームExercismのTypeScript問題セットを利用し、エージェントが指示書に基づいてコードを編集し、テストをパスできるかを自動で判定します。このアプローチにより、開発現場で実際に直面するビルドエラーやテスト失敗の修正能力といった実践的なスキルを測定できるため、AIエージェント導入の判断基準として極めて高い価値を持ちます。

開発の背景には、ベンダー発表の「SWE-bench Verified」スコアが実用的な参考にならないという課題があり、エージェントの効率的な評価と選別、多様なモデル・エージェント組み合わせの検証（例：opencodeと様々なモデル）、特定バージョンにおける性能変化の追跡（例：Claude Codeのバージョン間の性能差）、そして自作エージェントの評価基盤の提供が目的とされています。実際にClaude CodeとDeepSeek V3.1の組み合わせが低いスコアを記録するなど、具体的な性能差を明らかにしています。DockerとGitHub Actionsによる再現性の高さがコミュニティからの評価を得ており、ローカルLLMの評価にも活用され始めています。今後は、より難易度の高いタスクセットの追加や、ベンチマーク実行コストの課題解決が展望されています。本ツールは、WebアプリケーションエンジニアがAIコーディングエージェントを実務に導入・活用する上で、その真価を見極めるための強力な基盤となるでしょう。