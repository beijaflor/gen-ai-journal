## 「隠れAI利用」は解雇の可能性も、職場で使う者の4割が社内規定に違反

https://forbesjapan.com/articles/detail/81621

職場における隠れたAI利用が社内規定違反や機密データ漏洩のリスクを高め、解雇に繋がる可能性について警鐘を鳴らす。

**Content Type**: 🤝 AI Etiquette

**Scores**: Signal:4/5 | Depth:1/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 96/100 | **Annex Potential**: 91/100 | **Overall**: 68/100

**Topics**: [[AI利用規約, 情報セキュリティ, 従業員生産性, シャドーAI, 職場コンプライアンス]]

職場での生成AI利用が急速に普及する中、多くの従業員が「隠れAI利用」による予期せぬリスクに直面しているとForbes JAPANが報じています。OpenAIの調査によると、米国の就労者の28%が職場でChatGPTを利用しており、わずか1年で3倍以上に増加しました。しかし、KPMGとメルボルン大学の調査では、AI利用者の約半数が無意識のうちに社内規定に違反していることが判明しています。

ウェブアプリケーションエンジニアにとって、この状況は特に重要です。生産性向上（効率67%、情報アクセス61%、イノベーション59%）というAIの恩恵は大きい一方で、明確なルールや安全対策が追いつかない現状が深刻な問題を引き起こしています。エンジニアが業務でAIツールを使用する際、安易な機密データの入力や、AIが生成した成果物を自身の作品として提出する行為は、顧客や上司との信頼関係を損ねるだけでなく、解雇につながる可能性さえあります。

なぜこれが重要かというと、AIツールの導入スピードが企業内の研修やガバナンス体制の整備を上回っているため、従業員はリスクを十分に理解しないままAIを操作しているからです。エンジニアは機密性の高いコードや設計に携わることが多いため、AIにそれらの情報を入力する際のセキュリティリスクを常に意識し、企業のAIポリシーを積極的に確認・遵守する必要があります。AIを活用した開発効率化を進める際も、データの取り扱い、知的財産の帰属、そしてAI生成物の適切な開示といったエチケットを意識し、組織全体のコンプライアンスとセキュリティ文化を構築する一翼を担うことが求められます。この動向は、単なるツールの話ではなく、職場の倫理と信頼を左右する重要な課題として、開発者自身のキャリアにも直結する喫緊の課題です。