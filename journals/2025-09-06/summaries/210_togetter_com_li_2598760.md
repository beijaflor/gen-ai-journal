## Geminiの合成機能がすごすぎた結果、都市部にクマが出没するフェイク画像が作り放題になっている→加工に凝れば本当に見分けがつかない

https://togetter.com/li/2598760

Google Geminiの高度な画像合成機能が都市部のクマのフェイク画像を現実と見分けがつかないレベルで生成できることを示し、災害時のデマ拡散の危険性を警告しています。

**Content Type**: 🤝 AI Etiquette

**Scores**: Signal:3/5 | Depth:2/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 93/100 | **Annex Potential**: 94/100 | **Overall**: 64/100

**Topics**: [[Generative AI, 画像生成, 偽情報対策, 災害時対応, AI倫理]]

Google Geminiの画像合成機能が驚くべき精度で、都市部にクマが出没するような極めて現実的なフェイク画像を生成できることがTogetterで話題になっています。この技術は、ウォーターマークを消せば本物と見分けがつかないレベルに達しており、災害時などの緊急事態において、虚偽情報が容易に拡散される深刻なリスクを提起しています。

特に懸念されるのは、2016年の熊本地震時に発生した「ライオン脱走」のデマのように、人々の不安を煽り、混乱を招く偽情報が悪用される可能性です。当時のデマ画像はアフリカの風景だったため区別がつきやすかったものの、現在のAIは日本の都市風景に自然にクマを合成できるため、視覚的な判断が極めて困難になります。

現状では、AIが生成した画像に書き込まれた文字（例: 看板の文字）が不自然であったり、文字化けしている場合が多いという指摘があり、これが一時的な見分け方として挙げられています。しかし、AIの進化によりこの区別も早晩不可能になるでしょう。

ウェブアプリケーションエンジニアにとって、これは単なる技術的な進歩以上の意味を持ちます。プラットフォームはコンテンツの信憑性検証に新たな課題を突きつけられ、開発者はAI生成コンテンツの悪用を防ぐための倫理的かつ技術的な対策を喫緊に考える必要があります。もはや、視覚情報だけでは真偽を判断できない時代に入りつつあり、公式発表や信頼できる情報源への依存度が高まる一方です。真実のデジタル化における脆弱性を認識し、ディスインフォメーションに対抗する堅牢な戦略が求められます。