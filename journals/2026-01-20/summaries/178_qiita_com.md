## 【LLM文字起こし性能比較】低解像度のAI泣かせ表データを読ませてみた結果（GPT-5.2 / Gemini 3 / Claude 4.5 Opus）

https://qiita.com/k2a_Y4a/items/b46a545a96e9150c457f

2026年の未来という設定で、最新LLMによる高難度な表データ文字起こし性能の限界と特性を比較検証する。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:5/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 88/100 | **Annex Potential**: 88/100 | **Overall**: 88/100

**Topics**: [[OCR, マルチモーダルLLM, データ抽出, プロンプトエンジニアリング, ベンチマーク]]

2026年1月という近未来の設定に基づき、当時のフラッグシップモデルであるGPT-5.2、Gemini 3、Claude 4.5 Opusを用いた「画像からの文字起こし性能」を徹底比較した検証記事である。筆者は、人間でも判読が困難な低解像度、かつ特殊文字や記号が複雑に混在する「AI泣かせ」の表データを独自に用意し、実務におけるRAGシステム構築や大量データ抽出の精度をシビアに評価している。

検証の結果、最新鋭のマルチモーダルLLMであっても、厳密なデータ抽出には依然として大きな障壁があることが浮き彫りになった。GPT-5.2は「完璧主義型」の特性を持ち、詳細なプロンプトを介して初めて本領を発揮するが、ID列などの特殊文字やURLの細部において誤認識が目立つ。一方でGemini 3は、プロンプトの質に左右されず安定した構造維持能力（Markdown出力など）を見せる反面、特殊文字の認識はほぼ全滅しており、物理量の単位ミスや固有表現の改変といった「意味の変質」を招くリスクが指摘されている。また、Claude 4.5 Opusは厳密なOCRには不向きであり、むしろ検証用プロンプトの生成といったメタ的なタスクで強みを発揮するという、各モデルの役割分担が明確に示された。

エンジニアにとっての重要な教訓は、LLMが視覚情報を言語化する過程で「推論」が「捏造」にすり替わる境界線を理解することにある。著者は、業務上不可欠なIDやURLの完全一致を目指すならば、画像を分割して処理する、特定のフォーマットを明示する、あるいは人間による最終確認を工程に組み込むといった、泥臭い最適化が不可欠であると説く。特定の万能モデルに期待するのではなく、高精度な抽出にはGPT、構造維持にはGemini、設計支援にはClaudeといった「用途別の使い分け戦略」こそが、実務におけるAI実装の成否を分けるという知見は、マルチモーダル技術を扱う開発者にとって極めて実践的なガイドとなる。