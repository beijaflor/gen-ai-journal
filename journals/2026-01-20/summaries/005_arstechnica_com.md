## Google、AI検索による「危険な」医療情報の要約を一部削除――調査で重大な欠陥が判明

https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/

**Original Title**: Google removes some AI health summaries after investigation finds “dangerous” flaws

Googleが、検索結果をAIが要約する「AI Overviews」において、肝機能検査の誤解を招く数値や膵臓がん患者への不適切な食事アドバイスなどの「危険な欠陥」を指摘され、一部の要約を削除した。

**Content Type**: 📰 News & Announcements
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:3/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 92/100 | **Annex Potential**: 93/100 | **Overall**: 68/100

**Topics**: [[AI Overviews, Google Search, RAG, Hallucination, Medical AI]]

Googleが提供するAI検索要約機能「AI Overviews」において、人命に関わる可能性のある重大な誤情報が提示されていることが、英Guardian紙の調査で明らかになった。これを受け、Googleは特定のクエリに対する要約を削除・停止する措置を講じた。

調査では、AIが肝機能検査（LFT）の正常値として提示したデータに、年齢や性別、人種といった不可欠な文脈が欠落しており、深刻な肝疾患を持つ患者が「自分は健康である」と誤認して必要な受診を逃すリスクが指摘された。また、膵臓がん患者に対して、標準的な医学的ガイダンスとは正反対の「高脂肪食を避けるべき（実際には体重維持のために重要とされる）」といったアドバイスを生成したケースも確認されている。

著者は、これらのエラーが単なる一時的な不具合ではなく、システムの設計上の欠陥に起因していると指摘する。AI Overviewsは、Googleのページランクアルゴリズムで上位に表示されたコンテンツを「正確である」という前提で要約するように設計されている。しかし、現在の検索結果はSEO対策によって操作された信頼性の低い情報やスパムに溢れており、AIがそれらを「権威あるトーン」で要約してしまうことで、ユーザーを誤導する仕組みになっている。また、参照元のウェブサイトが正確であっても、言語モデルがデータから誤った結論を導き出す「論理的な飛躍」も発生している。

Google側は「大多数の要約は正確であり、内部の臨床チームによるレビューでは情報の多くに不正確さはなかった」と反論しているが、肝機能検査のクエリにわずかなバリエーション（例：「lft reference range」など）を加えるだけで、依然として同様の危険な要約が表示される実態も報告されている。

本記事の教訓は、Webエンジニアにとって極めて重要である。汎用的な検索エンジンやRAG（検索拡張生成）を用いたシステムにおいて、「ランキング上位＝正確」というロジックを無批判に要約に適用することの危険性が浮き彫りになった。特に医療や法務など、不正確さが致命的な結果を招くドメインでは、LLMの「もっともらしい語り口」が事実の検証を困難にするため、ドメイン固有の検証層やコンテキストの補完が不可欠であることを示唆している。