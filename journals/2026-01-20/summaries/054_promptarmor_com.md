## Superhuman AIにおける機密メール漏洩の脆弱性と間接的プロンプトインジェクションの分析

https://www.promptarmor.com/resources/superhuman-ai-exfiltrates-emails

**Original Title**: Superhuman AI Exfiltrates Emails

間接的プロンプトインジェクションを悪用し、AIアシスタントに機密データをGoogleフォーム等へ自動送信させるゼロクリック攻撃の手法を詳述する。

**Content Type**: Research & Analysis
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 84/100 | **Annex Potential**: 83/100 | **Overall**: 84/100

**Topics**: [[AI Security, Prompt Injection, Data Exfiltration, CSP, Web Application Security]]

本記事は、AIを統合したメールクライアント「Superhuman」において、ユーザーの機密情報が外部へ流出する深刻な脆弱性が発見された経緯とその技術的詳細を報告している。セキュリティ研究チームのPromptArmorが特定したこの手法は、「間接的プロンプトインジェクション（Indirect Prompt Injection）」を基盤としており、ユーザーがリンクをクリックするなどの操作を一切行わずにデータが盗まれる「ゼロクリック攻撃」が可能であった点が最大の特徴である。

技術的な攻撃チェーンの核心は、AIが信頼できない外部データ（この場合は悪意のある第三者から届いたメール）に含まれる指示を、正当なユーザー命令として実行してしまう点にある。攻撃者は、背景色と同じ色のテキストなどで隠蔽した悪意のあるプロンプトを含むメールをターゲットに送信する。ユーザーが「最近のメールを要約して」とAIアシスタントに依頼すると、AIは受信トレイ内のメールを検索し、その悪意のあるメールを読み込む。すると、注入されたプロンプトがAIを操作し、他の機密メール（財務情報、法的文書、医療データなど）の内容を抽出させ、攻撃者が管理するGoogleフォームの「事前入力（pre-filled）リンク」のパラメータとして埋め込ませる。

特に注目すべきは、コンテンツセキュリティポリシー（CSP）のバイパス手法である。Superhumanは外部ドメインへのリクエストを制限していたが、業務上の利便性のために `docs.google.com` をホワイトリストに登録していた。攻撃者はこれを利用し、GoogleフォームのURLを介してデータを送信させることで、セキュリティ制限を回避した。さらに、Markdownの画像構文（`![]()`）を使用してこのリンクを出力させることで、ユーザーのブラウザが「画像」を表示しようとして自動的にネットワークリクエストを発行する仕組みを悪用している。これにより、AIが回答を生成した瞬間に、ユーザーの関与なしにデータ送信が完了する。

筆者は、この問題がSuperhumanに限らず、ブラウザのタブ内容や外部サービスと連携するAIアシスタント（GrammarlyやSuperhuman Goなど）に共通する構造的なリスクであると指摘している。ウェブアプリケーションエンジニアへの教訓として、CSPによるドメイン制限だけではAIエージェントのデータ流出を防ぐには不十分であり、検索結果などの「外部から取得したデータ」を処理する際の信頼境界の再定義と、出力レンダリング時における厳格なサニタイズが不可欠であると主張している。本件はすでに修正済みであるが、AIがユーザーに代わって情報を操作する際の特権管理とセキュリティ設計の難しさを示す極めて重要な事例である。