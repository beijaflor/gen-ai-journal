## Anthropic発「MCP」とは何か？ 基本概念から実践まで一気通貫で解説 (1/2)

https://codezine.jp/article/detail/21808

Anthropicが提唱するModel Context Protocol (MCP)は、LLMと外部ツール間の複雑な統合問題を標準化し、開発効率と拡張性を飛躍的に向上させるデファクトスタンダードです。

**Content Type**: 🛠️ Technical Reference

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 80/100 | **Annex Potential**: 80/100 | **Overall**: 80/100

**Topics**: [[Model Context Protocol, LLMエージェント, ツール連携, オープン標準, 開発効率化]]

Anthropicが提唱するModel Context Protocol（MCP）は、LLMと外部ツール連携における「M×N問題」を解決するオープン標準です。従来のLLMが外部システムから孤立し、個別の連携が必要だったM×N通りの統合作業を、標準化されたM＋Nに削減します。これは、AIアプリケーションにおけるUSB-Cのような共通ポートの役割を果たします。

MCPは、コードエディタと言語解析エンジンの連携に用いられるLanguage Server Protocol（LSP）に類似したクライアント・サーバー型アーキテクチャを採用しています。ホスト（LLMアプリケーション）、クライアント（ホスト内でサーバーと通信）、サーバー（外部システム側の機能提供）が連携し、JSON-RPC 2.0を介して標準入出力またはHTTP/SSEで通信します。これにより、言語非依存かつ拡張性の高い基盤が実現されます。

MCPサーバーは、LLMに以下の3つのプリミティブを提供します。
*   **Tools**: LLMが呼び出す外部アクション（例：ファイル書き込み、DBクエリ）。ユーザーの承認を経て実行されるため、エージェントの自動操作を安全に制御できます。
*   **Resources**: LLMに提供される読み取り専用データ（例：ファイル内容、APIレスポンス）。副作用なくデータを取得する用途に用いられます。
*   **Prompts**: あらかじめ定義されたLLMへの指示テンプレート。定型タスクの効率的な実行を支援します。

この標準の導入は、ウェブアプリケーションエンジニアにとって大きなメリットをもたらします。まず、統一規格により各LLMやツールごとにインテグレーションコードを書く必要がなくなり、開発効率が飛躍的に向上します。次に、ファイル操作、データベース連携、各種クラウドAPI、Web検索など、多岐にわたるMCPサーバーがコミュニティから提供されており、既存の豊富なツールエコシステムを容易に活用できます。これにより、GitHub Copilotのエージェントモードのように、LLMが直接ファイルシステムやデータベースにアクセスするといった高度な機能拡張が、より迅速かつ安全に実現可能になります。さらに、人の承認を挟む設計やホワイトリスト管理により、AIエージェントの暴走や機密データへの不正アクセスを防ぎ、企業での安全なAIアプリケーション運用に貢献します。MCPは、LLMを実世界のデータやシステムと連携させる上で、開発コスト削減、機能拡張性、ユーザー利便性、安全性の全てを強化するデファクトスタンダードとして注目されています。