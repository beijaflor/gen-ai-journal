## XのGrokやGoogleのAI概要が津波に関する誤情報を拡散し非難を浴びる

https://gigazine.net/news/20250731-tsunami-warning-ai/

XのGrokやGoogleのAI概要が津波警報に関する誤情報を拡散し、リアルタイムの危機管理におけるAIの信頼性の低さを露呈しました。

**Content Type**: 🎭 AI Hype

**Scores**: Signal:3/5 | Depth:2/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 74/100 | **Annex Potential**: 76/100 | **Overall**: 68/100

**Topics**: [[AIの信頼性, リアルタイム情報処理, 大規模言語モデルの限界, 危機管理システム, AIの誤情報拡散]]

2025年7月30日、ロシアのカムチャツカ半島沖で発生した地震に伴う津波警報に関して、XのAI「Grok」およびGoogle検索の「AIによる概要」が相次いで誤情報を拡散し、広範な批判を浴びました。米サンフランシスコのニュースサイトSFGATEの報道によると、Grokは津波警報が「顕著な波が確認されなかったため取り消された」と誤って伝えましたが、実際には警報が発令され、ハワイを含む広い範囲で津波が観測されていました。GoogleのAI概要も「アラスカ沿岸地域以外では津波警報は発令されていない」と誤った情報を提供したと報じられています。さらに、Grokは同じユーザーに対してすら、津波警報に関して矛盾する回答を生成する一貫性の欠如も示されました。

この深刻な誤情報の拡散は、ウェブアプリケーションエンジニアにとって、リアルタイムかつ生命の安全に直結するクリティカルな情報を取り扱うAIシステムの根本的な信頼性に関する重要な教訓を提示します。大規模言語モデルは、あくまで人間が話すような自然な言語を生成する能力に長けていますが、その出力内容の事実性や正確性は一切保証されません。特に、刻一刻と状況が変化する災害時のような緊急事態においては、AIが最新の検証済み情報を正確に反映し、一貫した事実を提供することは現在の技術では非常に困難であることが、今回の事例で改めて露呈しました。

「AIが言うことは正しい」と盲目的に信じる利用者が後を絶たない現状は、単なる混乱に留まらず、避難行動の遅れや誤った判断を誘発するなど、現実世界に甚大な被害をもたらすリスクをはらんでいます。Googleは問題の表示を迅速に停止する対応を取りましたが、本件は、AIを活用したサービスや機能を設計・開発する私たちエンジニアに対して、倫理的かつ実用的な観点から大きな警鐘を鳴らします。災害情報、医療診断、金融取引といった人命や資産に直結するクリティカルな分野でAIをシステムに組み込む際には、AIの技術的限界を深く理解し、堅牢なフォールバック機構、多重の情報源照合、人間による最終的な検証プロセスといったセーフティネットを組み込むことが不可欠です。AIの進歩は目覚ましいものがありますが、その性能に対する過度な期待を排し、その特性を冷静に評価し、責任ある形で適切に活用することが、なぜ今私たちに問われているのか、その核心を示しています。