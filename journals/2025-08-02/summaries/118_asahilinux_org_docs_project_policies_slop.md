## Generative AI Policy

https://asahilinux.org/docs/project/policies/slop/

Asahi Linuxプロジェクトは、知的財産権侵害、資源浪費、非倫理的な利用、および根本的な技術的制約を理由に、プロジェクト貢献における生成AIツールの使用を全面禁止した。

**Content Type**: 🎭 AI Hype

**Scores**: Signal:5/5 | Depth:3/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 92/100 | **Annex Potential**: 94/100 | **Overall**: 88/100

**Topics**: [[生成AIポリシー, オープンソース開発, 知的財産権, LLMの限界, AI倫理]]

Asahi Linuxプロジェクトは、オープンソースソフトウェア開発における大規模言語モデル（LLM、通称「Slop Generators」）の使用を全面的に禁止する異例のポリシーを発表しました。これは、生成AIが持つ根本的な問題と、それがソフトウェア開発にもたらすリスクに対する厳しい警告です。

最大の懸念は、知的財産権（IP）侵害のリスクです。LLMは著作権侵害の可能性があるデータで学習されており、生成されたコードやテキストが元のトレーニングデータ、特に機密情報を再現し、法的な問題を引き起こす危険性があります。Asahi Linuxのような特定のハードウェアを扱うプロジェクトでは、Appleの内部情報がLLMを通じて流出する可能性も指摘されており、FOSSプロジェクトが訴訟リスクを負うことはできません。これは、企業がAIツールを導入する際にも、IPクリアランスと責任の所在を深く検討すべき重要な警鐘となります。

次に、LLMのトレーニングと推論に消費される膨大なエネルギー、水、ハードウェア資源による環境負荷も問題視されています。AIツールの利便性だけでなく、その持続可能性と社会的コストを考慮すべきです。

さらに、プロジェクトは、ユーザーの質問をLLMに丸投げし、生成された回答をそのまま返信する「LMGTFY」症候群と呼ぶ行為を非難しています。これはコミュニケーションの質を低下させ、本質的に無益であり、AIツールの盲目的な利用がチーム内の知識共有や問題解決能力を損なう可能性を示唆しています。

最も強調されるのは、LLMが「思考」や「推論」を行わず、単なる「行列計算」に基づいた統計的な単語予測に過ぎないという、その根本的なメカニズムです。LLMは自信を持って誤った情報を生成することが多く、真実性や正確性が不可欠な場面では不適切です。我々ウェブアプリケーションエンジニアは、AIが生成したコードやテキストを鵜呑みにせず、常にその正確性を深く検証する必要があるという、実用的な教訓を得るべきです。

このポリシーは、生成AIに対する過度な期待（ハイプ）への現実的な視点を提供し、その技術的、倫理的、法的限界を開発者コミュニティ全体が深く理解することの重要性を強く訴えかけています。