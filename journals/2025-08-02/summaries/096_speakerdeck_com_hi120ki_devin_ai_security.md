## 運用して初めてわかったDevinのセキュリティ課題 - Devin Meetup Tokyo 2025

https://speakerdeck.com/hi120ki/devin-ai-security

メルカリのAIセキュリティチームが、Devinの組織利用で露呈したプルリクエストの自己承認、認証情報管理、プロンプトインジェクション、サプライチェーン攻撃、そしてエージェント暴走といったセキュリティ課題に対し、組織的な対策と技術的ガードレールの整備が不可欠であると指摘します。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:5/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 94/100 | **Annex Potential**: 90/100 | **Overall**: 92/100

**Topics**: [[AIエージェントセキュリティ, Devin, プルリクエスト運用, 認証情報管理, サプライチェーン攻撃]]

DevinのようなAIエージェントの組織的な導入が進む中で、予期せぬセキュリティリスクが顕在化しています。本発表は、メルカリのAIセキュリティチームが実際にDevinを運用する中で明らかになった具体的な課題と、それらに対処するための現実的な対策を詳述しています。

最も重要な課題の一つは、AIエージェントが作成したプルリクエスト（PR）の「自己承認」リスクです。GitHubの標準的なBranch Rulesetだけでは、Devinが作ったPRをユーザーが自身で承認し、未レビューのコードが本番環境にマージされる事態を防ぎきれません。これに対する効果的な対策として、`palantir/policy-bot`のような外部ツールを導入し、機械が作成したPRには必ず二人以上の人間による承認を必須とする、組織全体に適用可能な厳格なワークフローを構築する必要性を強調しています。これにより、Devinだけでなく、他のAIコーディングエージェントからの変更も安全に管理できます。

次に、認証情報の管理が重大な問題として挙げられています。Devin環境内に個人APIキーを保存すると、組織内の全セッションから閲覧・実行が可能になり、誰がいつ何を変更したかの追跡が困難になります。対策として、テスト環境連携やクラウドプラットフォーム連携にはGitHub ActionsとWorkload Identity Federationを用いたセキュアなシークレット管理を推奨。Devin Secretには最小限の読み取り権限と有効範囲に限定したサービスアカウントの認証情報を使用し、定期的なローテーションが不可欠です。また、プロンプトインジェクションやサプライチェーン攻撃によって認証情報が流出するリスクも指摘されており、インターネット接続の遮断（生産性への影響大）やセッション監視、認証情報の頻繁な交換が軽減策となります。

さらに、AIエージェントの「暴走」リスクも無視できません。AIは与えられた権限をすべて行使しようとするため、プロンプトだけでその行動を完全に制御することは困難です。そのため、Devinから本番環境への直接デプロイを禁止し、常に最小限のアクセス権限を付与することが肝要です。セッション履歴の継続的な監視も、意図しない変更を早期に発見するために重要となります。

現在のAIエージェントエコシステムは発展途上にあり、技術的なガードレールの整備が追いついていないのが実情です。生産性とのバランスを取りながら、組織は基本的なセキュリティ対策を徹底し、AIセキュリティに関するリテラシーを高め、必要に応じてセキュリティチームに相談する文化を醸成することが、安全かつ持続可能なAI活用への鍵となります。