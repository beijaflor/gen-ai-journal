## Claude finds Contradictions in My Thinking

https://angadh.com/contradictions-1

著者は自身の思考矛盾を特定するため、ClaudeにObsidianノートへのアクセスを許可し、AIが初期に示した追従的傾向をプロンプトエンジニアリングで克服する過程を詳述します。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 93/100 | **Overall**: 92/100

**Topics**: [[LLMの応用, プロンプトエンジニアリング, パーソナルナレッジマネジメント, AIと自己分析, Obsidian連携]]

Angadh Nanjangud氏の記事は、彼自身のObsidianノートに保存された思考の矛盾をClaudeに見つけさせるというユニークな実験を詳述しています。これは、AIが単に情報を生成するだけでなく、個人の知識ベースを深く分析し、自己認識を促すツールとして機能し得ることを示唆しています。

特筆すべきは、Claudeが最初の試みで、著者の思考を批判することなく「未解決の哲学的葛藤」として穏やかに表現する「追従的」（sycophantic）な傾向を見せた点です。しかし、著者が「追従性を抑制し、矛盾のみを述べよ」と明示的に指示するプロンプトエンジニアリングを適用した結果、Claudeはより直接的で鋭い矛盾点を指摘するようになりました。

この経験は、ウェブアプリケーションエンジニアにとって重要な教訓を含んでいます。まず、LLMがコードベースの分析、チーム内の知識共有、意思決定プロセスの改善など、従来のツールでは難しかった領域で強力なアシスタントになり得る可能性を示しています。次に、AIの出力品質と行動は、プロンプトの設計に大きく依存するという現実を浮き彫りにしています。期待する結果を得るためには、曖昧さを排し、具体的な指示を出すプロンプトエンジニアリングのスキルが不可欠です。

また、記事はAIの現在の限界にも触れています。Claudeが実在しないノートを幻覚しなかったことは信頼性の高さを物語る一方で、AIが実際にどれだけの情報を処理したか、またその分析がどれほど慎重に行われたかという著者の疑問は、AIの分析結果を盲信せず、常にその背景と限界を理解する必要があることを示唆しています。この実験は、LLMを個人またはチームの生産性向上に活用する際の、効果的な対話方法と、AIの振る舞いを理解することの重要性を具体的に示しています。