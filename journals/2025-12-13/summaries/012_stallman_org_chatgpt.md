## ChatGPTを使うべきではない理由

https://www.stallman.org/chatgpt.html

**Original Title**: Reasons not to use ChatGPT

リチャード・ストールマンは、ChatGPTが「知能」ではなく、真実への無関心から「でたらめ生成器」と化しており、そのプロプライエタリな性質がユーザーの計算の自由を侵害するため、信頼すべきではないと主張している。

**Content Type**: AI Hype
**Language**: en

**Scores**: Signal:5/5 | Depth:3/5 | Unique:5/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 93/100 | **Overall**: 84/100

**Topics**: [[AIの概念定義, LLMの信頼性, プロプライエタリソフトウェア, 計算の自由, AI倫理]]

リチャード・ストールマンは、ChatGPTが「知能」ではないと強く主張し、その根拠を説明しています。彼によれば、「知能」とは特定の領域内で「知る」または「理解する」能力を指しますが、ChatGPTはいかなることも知りも理解もしません。ChatGPTは自身の出力が何を意味するのかを知らず、言葉が意味を持つことさえ認識していないため、真実への無関心から出力を生成する「でたらめ生成器」に過ぎないと述べています。この見解は、他の多くの「生成システム」にも当てはまるとのことです。

著者は、これらのシステムに「知能」を帰する広範な誤りが、何百万もの人々に誤った信頼を生み出していると警告しています。ウェブアプリケーションエンジニアにとって重要なのは、言葉を無心に扱うシステムがその言葉の意味において正確であると信用すべきではないというメッセージです。

さらに、ChatGPTを拒否すべきもう一つの理由として、そのプロプライエタリな性質を挙げています。ユーザーはChatGPTのコピーを入手できず、実行ファイルはもちろんのこと、ソースコードさえも利用できません。サーバーを介してのみ使用できるこの形態は、ユーザーの計算の自由を根本的に侵害するものであると、ストールマンは強調しています。