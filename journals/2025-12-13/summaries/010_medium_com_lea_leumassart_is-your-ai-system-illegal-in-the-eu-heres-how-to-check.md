## あなたのAIシステムはEUで違法か？確認方法を紹介

https://medium.com/@lea.leumassart/is-your-ai-system-illegal-in-the-eu-heres-how-to-check-b92e2a5fb739

**Original Title**: Is your AI system illegal in the EU? Here’s how to check

EU AI ActがAIシステムのEU市場での合法性を判断するためのリスク分類、適用範囲、および企業が取るべき具体的なコンプライアンス要件を詳述する。

**Content Type**: 📖 Tutorial & Guide
**Language**: en

**Scores**: Signal:5/5 | Depth:3/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 78/100 | **Overall**: 80/100

**Topics**: [[AI法規制, AIコンプライアンス, リスク評価, 高リスクAIシステム, データガバナンス]]

「EU AI Actは、EU市場にサービスを提供するAIシステムに対し、その拠点を問わず広範囲に適用される。」という著者の主張から記事は始まる。多くの企業、特にスタートアップは「うちは小規模だから関係ない」と考えがちだが、AI Actは企業規模ではなく「ユースケース」に基づいて適用されるため、この認識は誤りであると著者は強調する。

本記事は、AIシステムをリスクレベルに応じて「許容できないリスク（禁止）」「高リスク」「限定的リスク」「最小限リスク」の4段階に分類し、それぞれの具体例を提示する。「許容できないリスク」には教育機関での学習者の感情認識や潜在的な行動操作が含まれ、「高リスク」には交通、エネルギーといった重要インフラ、生体認証、教育、法執行、そして多くの企業が利用する履歴書スクリーニングAI（基本的なキーワードフィルターも含む）などが明示的に挙げられている。著者は、履歴書スクリーニングが「高リスク」に該当するという認識が不足していることを指摘し、注意を促す。

高リスクに分類されるAIシステムをEU市場で販売するには、CEマークの取得、EUデータベースへの登録、リスク管理システムの導入、データガバナンス（バイアスのないデータ保証）、包括的な技術文書、品質管理システムの確立、適合性宣言書の作成、トレーサビリティと透明性の確保、人間の監視、堅牢性、精度、サイバーセキュリティの保証といった厳格な要件を満たす必要がある。

開発者や企業向けに、AIが人に関する自動的な意思決定を行うか、重要インフラで運用されるか、生体認証を使用するか、人間が容易に介入できるか、精度や堅牢性の文書があるか、意思決定プロセスを説明できるかといった自己診断チェックリストが提供されている。

最後に、著者は、AIシステムが「高リスク」に該当する可能性がある場合、Annex IIIを参照し、システムの意図された目的と制限を文書化し、コンプライアンスロードマップの構築を直ちに開始すべきだと助言する。EU AI Actの施行スケジュールも示されており、高リスクAIシステムへの完全適用は2026年8月2日からである。また、規制サンドボックスの活用も推奨されており、企業は規制当局の監督下でAIシステムをテストし、法的確実性を得ながらコンプライアンスを促進できる。

この法律は、AI開発者に対し、技術的な側面だけでなく、倫理的、法的側面にも配慮した開発プロセスを強く求めている。特に、多くのWebアプリケーションエンジニアが関わる採用支援AIのようなシステムも厳しく規制される点を理解し、早期の対応が不可欠である。