## 【Claude Code】プロンプトのスキルアップに役立つプロンプト評価カスタムコマンド #ChatGPT

https://qiita.com/t0hara/items/022f351d995992dc0ad0

開発者が生成AIとの協働を効果的に進めるため、Claude Code用のカスタムコマンド「prompt-review」がプロンプトの質を客観的に評価し、改善サイクルを支援します。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 89/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[プロンプトエンジニアリング, Claude Code, カスタムコマンド, プロンプト評価, 開発ワークフロー改善]]

生成AIの活用が進む中で、開発者が直面する「漠然とした指示による期待外れの回答」「曖昧な完了条件」「成功と失敗の要因不明」といった課題に対し、筆者はプロンプトの質を客観的に評価する仕組みの欠如が根本原因であると指摘しています。この「正解のない問い」への対処を支援するため、Claude Code向けのカスタムコマンド「prompt-review」が開発されました。

このコマンドは、Claude Codeとの直近の会話履歴からユーザーのプロンプトを抽出し、「目的・Done定義」「制約の具体性」「文脈共有」「段階的進行」「デバッグ／検証」「リファクタ安全／セキュリティ」「スコープ管理」という7つの観点に基づいた評価フレームワークにより、0～10点でスコアリングします。最大5つの良い点と、具体的な改善案付きの悪い点をMarkdown形式で提示することで、プロンプトの品質を「見える化」し、継続的な改善サイクルを可能にします。評価対象はAIの応答ではなく、あくまで人間が提示したプロンプトそのものであるため、開発者自身のプロンプト作成スキル向上に直結します。

実装面では、評価ロジックをテンプレートファイルとして分離することで、プロジェクトごとの評価基準のカスタマイズ性を確保。また、最新のセッションJSONLファイルを自動検出し、末尾2000行を読み込むシンプルな仕組みにより、特別な設定なしに現在の作業セッションのプロンプトを評価できる使い勝手を実現しています。

記事では、ToDoアプリの作成を例に、「不十分プロンプト」（28点）と「改善プロンプト」（60点）の比較を通じて、プロンプトの曖昧さがAIの理解度やアウトプット品質に与える影響を明確に示しています。特に、完了条件、UI仕様、制約、検証方法といった具体的な記述がスコアと生成結果を大きく向上させることが明らかになりました。

「prompt-review」コマンドは、プロンプトの良し悪しを数値と根拠に基づいて振り返ることで、開発者が生成AIとの協働をより効果的に進め、学習効率や開発速度を高めるための強力なツールとして機能します。今後、評価項目のカスタマイズなど、用途に応じた柔軟な運用が期待されます。