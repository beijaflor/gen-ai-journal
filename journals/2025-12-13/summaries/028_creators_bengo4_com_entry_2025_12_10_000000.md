## 「モデル追加は突然に」 LiteLLM 運用で学んだセルフホスティングの大変さと楽しさ

https://creators.bengo4.com/entry/2025/12/10/000000

弁護士ドットコムSRE室のエンジニアが、社内でのLiteLLM Proxy Server運用を通じて直面した課題と得られた喜びを具体的に解説します。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 76/100 | **Annex Potential**: 73/100 | **Overall**: 76/100

**Topics**: [[LiteLLM, プロキシサーバー, LLM運用, セルフホスティング, SRE, OSS貢献]]

弁護士ドットコムのSRE室が社内でLiteLLM Proxy Serverをセルフホスティングし、大規模言語モデル（LLM）へのアクセスを一元管理する運用を開始しました。本稿では、その運用過程で直面した具体的な課題と、予想外の楽しさについて詳細に語られています。

運用上の主な課題は、GPT-5.1、Claude Sonnet 4.5、Haiku 4.5といった新モデルの「突然の」追加と、それに伴うLiteLLMへの迅速な対応の必要性です。新しいモデルの発表と同時にクライアント側のデフォルトモデルも更新されるため、対応が遅れるとエラーや料金計算の間違いにつながるプレッシャーが挙げられています。また、生成AIクライアントの頻繁な更新による仕様変更への対応や、Claude CodeやCodex、VS Code拡張機能など、想定外に増加するクライアントの種類への対応も課題となりました。

一方で、運用を通じて得られた楽しさも強調されています。LiteLLMの導入は社内メンバーとの活発な交流を促し、問題解決や設定情報の共有を通じて一体感を生み出しました。さらに、Amazon Bedrockのモデル価格情報を追加するプルリクエストをLiteLLMのOSSプロジェクトに提出し、マージされた経験は、SREエンジニアとしてのOSS貢献の第一歩となり、大きな喜びとなっています。

著者は今後の展望として、LiteLLMの更新やモデル追加作業の完全自動化を掲げ、SREとしてトイル削減に注力していくことを表明しています。本記事は、セルフホスティングによるLLMプロキシ運用がもたらす技術的・組織的な学びと、エンジニアリングの楽しさを具体的に示しており、同様の導入を検討するウェブアプリケーションエンジニアにとって実践的な洞察を提供します。