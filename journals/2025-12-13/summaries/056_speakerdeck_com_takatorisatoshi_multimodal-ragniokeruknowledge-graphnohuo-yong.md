## マルチモーダルRAGにおけるKnowledge Graphの活用

https://speakerdeck.com/takatorisatoshi/multimodal-ragniokeruknowledge-graphnohuo-yong

マルチモーダル情報を統合する知識グラフベースのRAG手法「MMGraphRAG」が、従来のRAGの課題を克服し、複雑な質問応答における高い精度と解釈可能性を提供することを解説します。

**Content Type**: Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 100/100 | **Annex Potential**: 100/100 | **Overall**: 72/100

**Topics**: [[RAG, 知識グラフ, マルチモーダルAI, LLMの限界, 情報検索]]

大規模言語モデル（LLM）には、学習時点の知識のカットオフ、社内用語や特定ドメインの専門知識の欠如、ハルシネーション（嘘をつく）といった制限があります。これを補完するため、外部知識ベースから関連文書を検索してLLMに最新のコンテキストを提供するRAG（Retrieval-Augmented Generation）が活用されています。

しかし、従来のRAGはドキュメントをチャンク化し、埋め込みベクトルの類似度で検索するため、「過去10年間の学際的研究の傾向」のようなグローバルな意味構築や、「AはBであり、BはCである、ゆえにAはCである」といったMulti-hop推論に必要な「関係性」の理解が苦手という弱点がありました。

この課題を解決するため、知識をグラフ構造で組織化・検索するGraphRAGが登場しました。GraphRAGは情報の「つながり」を理解し多段推論を可能にするほか、全体を俯瞰した回答（Global Context）や高い解釈性を提供します。本発表では、このGraphRAGをさらにマルチモーダル領域へと拡張したMMGraphRAGを紹介しています。

MMGraphRAGは、テキストの知識グラフと画像の知識グラフを融合することで、複雑な質問に対して画像とテキストの間を網羅的に推論できる経路を追跡し応答を生成します。これにより、視覚的要素が重要な質問や、答えが存在しない場合に「答えられない」と正確に判断する能力において、既存手法を大幅に上回る性能をDocBenchとMMLongBenchというベンチマークで達成しています。また、訓練不要で多様なドメインに適用でき、解釈可能な推論経路を提供する点も強みです。

MMGraphRAGの構築は、まず入力文書からテキストと視覚情報を抽出し、それぞれテキストベースと画像ベースの知識グラフを構築します。次に、スペクトルクラスタリングとLLMを活用して、画像とテキストのエンティティをリンキングし、統合されたマルチモーダル知識グラフ（MMKG）を構築します。質問時には、このMMKGを用いてエンティティ検索とグラフ探索を行い、LLMが理解できるコンテキストを生成。その後、LLMによるテキストベースの回答と、MLLMによる画像解析を統合して最終回答を生成します。

実験では、架空の企業分析資料PDFを用いたデモンストレーションを実施。日本語に対応するようプロンプトをカスタマイズし、gpt-4.1、gpt-4o、日本語特化の埋め込みモデルruri-v3-310mを使用しました。「ピンクのアイコンの企業と共通の連携企業を持つ会社の名前と関係性」といった複雑な質問に対し、MMGraphRAGは正確な回答と関係性図を生成。さらに、「ライオンをモチーフとしたアイコンの企業の売上高」のような、データに存在しない情報に対するクエリに対しても、無理に回答を生成せず、正しく「答えがない」と判断できることを示しました。

しかし、Knowledge Graph構築にはLLMの呼び出しが多いため時間がかかり、リアルタイム性が求められる場面での利用は課題として残ります。また、Knowledge Graph自体の構築精度、特に重複した概念を適切に認識する難しさも重要な課題であり、人間やAIによる継続的な修正による精度向上が期待されます。