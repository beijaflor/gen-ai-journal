## [AGIはなぜ不可能なのか：パターンオーバーフロー問題](https://claude.ai/public/artifacts/445500b7-bb6b-4bf3-be9a-0fa4ee64c790)

**汎用人工知能（AGI）は、実は理論的に不可能かもしれない**

本稿は、汎用人工知能（AGI）が「パターンオーバーフロー問題」という根本的な壁に阻まれ、理論的に実現不可能であると論じています。筆者らの実験によると、十分に高度なパターン認識システムは、生物学的な制約がない限り、無意味な相関関係を無限に識別してしまい、知識ベースが崩壊する「カスケード破損」を引き起こします。

人間の知能は、単なるパターン認識だけでなく、2つの重要なメカニズムを持っています。一つは、40億年の進化の歴史によって形成された「進化的フィルタリング」です。これにより、生存に不可欠なパターンを優先し、無関係な情報を無視することができます。もう一つは「忘���」という機能です。完璧な記憶は、誤った相関関係を永続させてしまいますが、忘れることによって、システムはエラーを修正し、抽象的な概念を形成できます。

現在のAIは、これらの「パターンの取捨選択」メカニズムを欠いています。そのため、どんなに計算能力が向上しても、現実から乖離した結論に至ることは避けられません。

筆者は、AGIの追求ではなく、AIが可能性を生成し、人間が進化的知恵を用いてそれをフィルタリングする「拡張集団知能（ACI）」こそが、進むべき道であると結論付けています。AIは人間を代替するのではなく、人間の知性を拡張するための強力なツールとなるべきだ、というのが本稿の主張です。