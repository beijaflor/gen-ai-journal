## [言語モデルの起源、シャノン論文を読んでみる](https://www.m3tech.blog/entry/shannon_language_model)

**言語モデルの原点、シャノン論文から探る**

現代のAI開発に不可欠な大規模言語モデル（LLM）。その基礎となる「次の単語を予測する」というアイデアは、実は70年以上前の1951年に情報理論の父クロード・シャノンによって提唱されていました。シャノンは、情報の量を測る「エントロピー」という概念を用いて英語の情報量を計測するため、言語モデルを考案しました。

シャノンは、人間を「言語モデル」と見立て、次の文字を予測させるというユニークな実験を行いました。その結果、文脈が長くなるほど次の文字の予測が容易になる（エントロピーが低下する）ことを発見しました。この発見は、現代のLLMが長い文脈を扱うことで高い性能を発揮する理論的な裏付けとなっています。

驚く��きことに、当時の人間による予測精度は、初期のニューラルネットワークモデルを上回っていました。しかし、TransformerベースのGPT-2や近年のモデルは、ついに人間の予測能力を超える精度を達成しています。この記事は、シャノンの独創的な実験が、いかにして現代のLLMの発展に繋がったかを解き明かしています。