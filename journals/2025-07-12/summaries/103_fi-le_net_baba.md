## 言語モデルに「Baba is You」をプレイさせる試み

[https://fi-le.net/baba/](https://fi-le.net/baba/)

言語モデルがルールを操作するパズルゲーム「Baba is You」をプレイする試みは、現在のモデルが複雑な推論に苦戦していることを示唆しています。

[[言語モデル, パズルゲーム, AI推論, ゲームAI, 評価ベンチマーク]]

この記事は、言語モデルに「Baba is You」というルール操作型パズルゲームをプレイさせる挑戦について詳述しています。AIがゲームの状態を抽出し、ゲームを制御し、メニューを操作する上での技術的な課題が浮き彫りになっています。特に、Claude 4のような最新のモデルでさえ、このゲームの複雑な推論要件、たとえ単純なレベルであっても、著しく苦戦している点が指摘されています。この「Baba is Eval」と名付けられたプロジェクトは、ゲームをARC-AGI-3のような推論ベンチマークに変えることを目指しています。著者は、進歩はあったものの、「Baba is You」に対する完全に自律的なAIソリューションはまだ遠いと結論付けています。これは、単なるゲームプレイを超え、AIの汎用的な推論能力の限界と可能性を探る重要な試みと言えます。

---

**編集者ノート**: この記事は、現在のLLMが持つ「推論能力」の限界を具体的に示しており、Webアプリケーションエンジニアにとって非常に示唆に富んでいます。単にテキストを生成するだけでなく、複雑なルールセットを理解し、状況に応じて戦略を立てるような「エージェント」としてのAIの活用は、今後の開発ワークフローや自動化において不可欠な要素となるでしょう。しかし、「Baba is You」のようなシンプルなゲームでさえ苦戦するという事実は、現実世界の複雑なビジネスロジックやユーザーインタラクションをAIに完全に委ねるには、まだ大きな隔たりがあることを示しています。今後、より高度な推論能力を持つAIが登場すれば、テスト自動化、コード生成、さらには要件定義の自動化といった領域で、AIエージェントがより自律的に機能する未来が訪れるでしょう。しかし、そのためには、AIが「ルール」を理解し、「なぜ」その行動を取るのかを説明できるような、より透明性の高いモデルが求められます。

