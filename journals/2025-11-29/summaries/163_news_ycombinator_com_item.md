## GPT-3からGemini 3への3年間

https://news.ycombinator.com/item?id=46019898

**Original Title**: Three Years from GPT-3 to Gemini 3 | Hacker News

LLMのコード生成能力と実用性について、懐疑論者と支持者の間で活発な議論が展開されており、その品質、開発者のワークフローにおける役割、および将来の課題が浮き彫りになっています。

**Content Type**: 💭 Opinion
**Language**: en

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 82/100 | **Overall**: 84/100

**Topics**: [[AIコーディング, LLMの限界, 開発ワークフロー, AIの信頼性, コード生成]]

Hacker Newsのスレッドでは、「GPT-3からGemini 3への3年間」というテーマのもと、大規模言語モデル（LLM）の進化とそのプログラミング分野への影響について、Webアプリケーションエンジニアの視点から多角的な議論が交わされました。

あるコメントでは、AIが生成するコードや論文の「出荷可能性」や「正確性」に対する疑問が呈されています。特に、複雑なシステム内でAIが生成したコードは、一見するとそれらしいものの、実際にはバグやセキュリティ問題を含み、そのままでは利用できないという経験が共有されました。

これに対し、LLMの支持者からは、最新モデル（Codex 5.1、Sonnet 4.5、Opus 4.5、Gemini 3など）では「wtfs per line」（一行あたりの理解不能な点）が急速に減少しており、実際にコードをほとんど書かずにプロジェクトをリリースできるレベルに達しているという意見も出ました。特に、LLMに特定の制約や過去の学習内容を記述したMarkdownファイルをコンテキストとして与えることで、その性能が飛躍的に向上するという「AGENTS.md」や「/docs」フォルダの活用例が紹介されています。

議論の中では、「人間がAIの間違いを修正する」役割から「人間がAIの作業を指示する」役割へと、「Human in the Loop」の概念が進化しているという見方が提示されました。LLMは複雑な数学的課題の解決、アイデアの探求、執筆補助など、多岐にわたるタスクで役立つものの、最終的な成果物の品質を保証するためには人間のレビューが不可欠であると結論付けられています。

一方で、LLMの「幻覚（ハルシネーション）」問題は依然として存在し、単なる事実誤認から、自信満々に架空の根拠を提示したり、自己矛盾した推論を展開したりする、より巧妙な形へと変化しているという指摘もありました。また、AIへの過度な依存が「神経の萎縮」を引き起こし、人間の認知能力を低下させる可能性や、AIエージェントにシステムへのフルアクセスを与えることによるセキュリティ上の懸念も議論されています。

将来のUIについては、テキストベースのインターフェースが情報密度と正確性で優位にあるという意見と、マルチモーダルなインタラクションや「Generative UI」が次なるブレイクスルーとなるという期待が入り混じっています。最終的に、LLMは開発者の生産性を劇的に向上させる強力なツールであると認識されつつも、その限界を理解し、人間が責任を持って指導・検証する「賢い道具」として活用することが重要である、という点で多くの意見が一致しました。