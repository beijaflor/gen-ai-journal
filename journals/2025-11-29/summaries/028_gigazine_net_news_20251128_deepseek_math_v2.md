## DeepSeekが数学的推論に特化したAIモデル「DeepSeek-Math-V2」をリリース、国際数学オリンピックで金メダルを取れるレベルの正答率を記録

https://gigazine.net/news/20251128-deepseek-math-v2/

DeepSeekは、定理証明と自己検証に重点を置いた数学的推論AIモデル「DeepSeek-Math-V2」をリリースし、国際数学オリンピックで金メダルレベルの正答率を達成した。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 78/100 | **Annex Potential**: 79/100 | **Overall**: 80/100

**Topics**: [[AIモデル, 数学的推論, 定理証明, 自己検証AI, 強化学習の限界]]

DeepSeekは、数学的推論に特化したAIモデル「DeepSeek-Math-V2」を公開しました。このモデルは、従来の最終的な答えの正誤のみを報酬とする強化学習の限界を克服し、特に定理証明のような高度な数学において必要とされる、厳密な推論プロセスそのものの正確性と完全性を重視しています。

その核心技術は、「生成器」と「検証器」という2つのモデルが連携するアーキテクチャにあります。生成器が証明を作成し、検証器がその証明の正しさを判定します。トレーニングは3段階で行われ、まず検証器を訓練し、次にその検証器を教師役として生成器を学習させます。その後、生成器は検証器からのフィードバックを受け、自身の証明の誤りを特定・修正するように訓練されます。さらに、検証のための計算量を増やすことで、AIが自動的に難しい証明の正誤を判断し、これを新たな学習データとして活用することで検証器の能力を向上させるサイクルを回します。

この技術革新により、DeepSeek-Math-V2は国際数学オリンピック(IMO)2025で金メダルレベルの83.3％、カナダ数学オリンピック(CMO)2024で73.8％、アメリカの大学レベル競技Putnam 2024で98.3％という驚異的なスコアを達成しました。ProofBench評価指標においても、他社の高性能モデル(Gemini Deep Think、Claude Sonnet 4など)を上回り、特に難易度の高い問題で強みを発揮しています。

Webアプリケーションエンジニアの視点から見ると、この「生成器」と「検証器」の連携による厳密な論理検証と自己修正能力は、将来のAIを活用したコード生成や自動テスト、あるいは複雑なタスクを扱うエージェントシステムにおいて、その信頼性と正確性を飛躍的に向上させる可能性を秘めています。単にコードを生成するだけでなく、そのコードが論理的に正しく、意図通りに機能することをAI自身が厳密に検証できる未来を示唆しており、開発ワークフローにおけるAIの活用範囲を大きく広げる重要な進展です。DeepSeek-V3.2-Exp-Baseをベースに構築されており、Hugging Faceからダウンロードして利用可能です。