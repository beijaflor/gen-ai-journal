## LLM活用におけるアンチパターン

https://instavm.io/blog/llm-anti-patterns

**Original Title**: Anti-patterns while working with LLMs

著者は、LLMとの効果的な協調作業を妨げる5つの一般的なアンチパターンを特定し、それぞれの回避策を提案している。

**Content Type**: Tutorial & Guide
**Language**: en

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 88/100 | **Annex Potential**: 85/100 | **Overall**: 84/100

**Topics**: [[LLMコンテキスト管理, プロンプトエンジニアリング, LLMの限界, コード生成AI, エージェント開発]]

LLMとの協調作業における非効率性や問題を引き起こす5つのアンチパターンを筆者が提示している。

第一に、コンテキストは貴重なリソースであり、セッション内で同じ情報を繰り返し送信すべきではない。例えば、コンピュータ操作をLLMに伝える際に、わずかなマウスの動きごとにほとんど差のないスクリーンショットを送信し続けることは非効率的である。必要なのは、状態変化時や重要な差異があるスクリーンショットのみで、冗長な情報を排除することでコンテキストを最適化すべきだと著者は指摘する。

第二に、「魚に木登りを求める」ように、LLMが苦手なタスクを直接依頼するべきではない。例えば、文字列中の特定の文字数を数えるようなタスクは、LLMに直接計算させるのではなく、その計算を行う「コードを生成させる」方がはるかに正確な結果を得られる。LLMはコーディング能力に優れているため、より正確な回答が必要な場合はコード生成を促すアプローチが効果的だと主張している。

第三に、コンテキストが飽和状態のLLMにタスクを処理させるべきではない。128Kトークンなどのコンテキストウィンドウがほぼ満杯、あるいは溢れている状況では、LLMの精度は著しく低下する。長時間のセッションでは、LLMが以前の情報を忘却したり、誤った情報を生成したりするリスクが高まるため、大きなコンテキストを必要とする場合は、その精度低下を認識しておくことが重要である。

第四に、LLMは広く議論されているトピックや、自身のトレーニングデータカットオフ以降の不明瞭なトピックに対しては性能が低い傾向がある。もし扱うトピックがニッチである場合、LLMの精度は低いと仮定し、情報を補強するなどの対策を講じる必要がある。

最後に、アンドレイ・カルパシーが提唱する「バイブ・コーディング」のように、LLMの出力内容を盲目的に信頼すべきではない。開発者はLLMが生成するコードや情報の内容を常に監視し、潜在的なバグやセキュリティ脆弱性（例：パスワードハッシュの不必要な露出）を見落とさないようにする必要がある。LLMの出力を鵜呑みにすることは、最終的に開発効率と品質の低下につながるため、人間によるコードレビューと監視が不可欠である。