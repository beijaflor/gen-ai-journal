## 不透明なシステムを通じてオープンウェブをフィルタリングするとき、誰が得をするのか？

https://hidde.blog/filtered-open-web/

**Original Title**: Who wins when we filter the open web through an opaque system?

大規模言語モデル（LLM）がオープンウェブの主要なアクセス経路となることで、コンテンツの改変、収益化、プライバシー侵害、イデオロギー的な偏向といったユーザーへの潜在的リスクが生じることを著者は警告している。

**Content Type**: AI Hype
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 82/100 | **Annex Potential**: 84/100 | **Overall**: 76/100

**Topics**: [[オープンウェブ, 大規模言語モデル, 情報フィルタリング, イデオロギー的偏向, プライバシー]]

著者は、大規模言語モデル（LLM）がオープンウェブの主要なコンテンツフィルタリングシステムとなることに対する強い懸念を表明しています。従来の検索エンジンのクローリングはウェブサイトにトラフィックをもたらす恩恵があったのに対し、LLMのクローラーはウェブサイトのホスティング費用を増加させる一方で、ユーザーが情報源のウェブサイトを直接訪れることなくLLM内で完結させるため、ウェブサイトのビジネスモデルを脅かすと筆者は指摘しています。

この「不透明なシステム」によるフィルタリングがもたらす具体的なリスクとして、著者は以下の点を挙げています。

1.  **コンテンツの改変**: LLMが情報を要約・言い換えたり、誤った情報（例: レシピの誤った材料）を挿入したりするリスクがあります。特に、モデルポイズニングによって悪意のある情報が挿入される可能性も示唆されています。
2.  **コンテンツの収益化**: AIエージェントを介した取引（例: 旅行予約）において、不透明なシステムがマージンを追加する形で収益化を図る可能性があり、ユーザーが公正な取引を行えているか判断が難しくなります。
3.  **プライバシー侵害**: LLMがユーザーの問い合わせを分析し、より詳細なプロファイルを構築して収益化に利用する可能性があり、現在の検索エンジンよりもさらに広範なプライバシー侵害につながると懸念しています。
4.  **イデオロギー的な偏向**: 最も懸念される点として、LLMが特定のイデオロギーを情報に注入する可能性を指摘しています。これは、LLM開発企業の方針によるもの（例: 「反覚醒」AI）であったり、あるいは情報戦のために意図的にトレーニングデータを汚染する行為によって生じる可能性があります。Baldur Bjarnason氏の論を引用し、LLMをプロセスに組み込むことは「イデオロギーのダイヤル」を設置するようなものであり、そのダイヤルをLLMを開発・運用する組織が制御できると警鐘を鳴らしています。

著者は、多くのAI企業が製品の改善やバイアスの排除に努めていることは認めつつも、過去のテック企業の行動（収益追求のためのデータ収集や監視資本主義への加担）を鑑みると、財務やプライバシー、そしてイデオロギーの側面において、AI企業を十分に信頼することはできないと結論付けています。Web User Agentsに関するW3Cのドラフトノートがユーザーエージェントに課す「保護」「誠実さ」「忠誠」という三つの義務が、LLMベースのシステムにも適用されるべきだと筆者は強調しています。