## 【プロービング実験】Qwen3 235B が最終ブロックのみのLoRA適用で賢くなったことを、内部表現から評価する

https://qiita.com/fregean/items/debcafff2f843fb63fdf

Qwen3 235BのLoRA適用モデルが、LLM内部表現に妥当性判断情報をより明確に保持するようになったことをプロービング実験が示しました。

**Content Type**: Research & Analysis
**Language**: ja

**Scores**: Signal:4/5 | Depth:5/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 83/100 | **Overall**: 80/100

**Topics**: [[LLM内部表現, プロービング, QLoRA, ファインチューニング, HLEベンチマーク]]

この記事は、松尾研LLM開発コンペ2025でoNo.1チームが開発したQwen3 235B A22BベースのQLoRAモデルに対するプロービング実験の詳細を報告しています。著者は、このモデルがTransformerの最終ブロックにあるQwen3MoeAttentionの線形変換の重み行列にのみLoRAアダプタを適用して学習された点に注目しています。

コンペのベンチマークである「Humanity's Last Exam（HLE）」は、既存ベンチマークの飽和状態を解決するため、最先端LLMの学術的能力の限界を測る難問データセットとして重要であると説明されます。oNo.1チームのモデルは、ベースモデルと比較してHLEの正解率が2.32%向上し、15.89%を達成しました。

この外部出力における性能向上が、モデルの内部でどのように実現されたかを検証するため、「プロービング」手法が採用されました。プロービングとは、LLMの隠れ状態から特定の情報（この場合は問題文の妥当性）を線形分類器で予測し、その分類性能を測ることで、隠れ状態にその情報がどの程度エンコードされているかを調べる実験的な解析手法です。

実験では、AquA-RATデータセットを加工し、問題文に対する生徒の回答の「妥当性（CONSISTENCY/INCONSISTENCY）」を判断させるプロンプトを作成しました。Qwen3 235BのベースモデルとQLoRA適用モデルから、推論時の最後の4ブロック、96トークン分の隠れ状態を抽出し、それぞれのトークン位置とブロックごとにロジスティック回帰（Probe）を訓練。AUC（Area Under the ROC Curve）を用いて妥当性予測の性能が評価されました。

プロービングの結果を可視化したヒートマップは、QLoRA適用後のトップモデルにおいて、最終ブロック（L-1）の特定のトークン位置で妥当性判断に関する情報が非常にシャープに（AUCが0.8～0.9以上）現れていることを示しました。対照的に、ベースモデルでは最終ブロックに近づくにつれてこの情報が希薄になる傾向が見られました。

この知見は、Transformerの最終ブロックのみにLoRAを適用するという比較的小さな介入が、モデルの推論過程で重要な特徴を最終層まで保持する効果をもたらし、それが実際の外部出力の性能向上に寄与した可能性を強く示唆しています。著者は、この効果が「保持機構の強化」によるものか「不要なノイズ抑制」によるものかは、今回の実験だけでは特定できないとしつつも、LLMの内部動作を深く理解する上で重要な発見であると述べています。

ウェブアプリケーションエンジニアにとって、この研究は、LoRAのような効率的なファインチューニング手法がLLMの内部でどのように機能し、性能向上につながるかについての深い洞察を提供します。LLMの外部的な振る舞いだけでなく、その内部メカニズムを理解することは、より効率的で信頼性の高いAI搭載アプリケーションを開発・運用するための鍵となります。