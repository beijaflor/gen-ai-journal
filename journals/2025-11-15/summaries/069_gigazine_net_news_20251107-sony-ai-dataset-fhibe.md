## ソニーがAIモデルの公平性を評価するためのデータセット「Fair Human-Centric Image Benchmark(FHIBE)」を公開

https://gigazine.net/news/20251107-sony-ai-dataset-fhibe/

ソニーAIが、AIモデルの公平性を評価するための画期的なデータセット「Fair Human-Centric Image Benchmark(FHIBE)」を公開し、コンピュータービジョン分野における倫理的課題の解決を推進します。

**Content Type**: Tools
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 90/100 | **Overall**: 92/100

**Topics**: [[AI公平性, バイアス軽減, コンピュータービジョン, 倫理的AI, データセット]]

ソニーAIは、AIモデル、特にコンピュータービジョン分野における長年の課題であるバイアス、多様性の欠如、および被写体の同意なしに収集されたデータ利用の問題に対処するため、公平性評価に特化したデータセット「Fair Human-Centric Image Benchmark (FHIBE)」を公開しました。これは、人間中心のコンピュータービジョンタスクにおける公平性を評価するために構築された、多様性に富み、被写体の同意に基づいた初の公開データセットであると強調されています。

FHIBEの主な特徴は以下の通りです。まず「同意」に基づいている点が重要で、参加者全員から情報に基づいた取消可能な同意を得ており、データ収集はデータ保護法に準拠しています。次に、画像の対象者、注釈者、品質保証担当者には「公正な補償」が支払われ、参加者は報酬に影響を与えることなくいつでもデータを撤回可能です。また、データセットは年齢、代名詞、祖先、肌の色、目の色、髪質、目に見えるマーカーに関する詳細な情報を含み、人口統計・外見・ポーズ・環境における「最大限の多様性」を確保し、きめ細かなバイアス分析をサポートします。さらに、ピクセルレベルのラベル、33個のキーポイント、匿名化された注釈者IDにリンクされた28個のセグメンテーションカテゴリといった「包括的な注釈」が施されています。その「実用性」として、ポーズ推定、顔／体の検出、セグメンテーション、合成、視覚言語モデルといった幅広いコンピュータービジョンタスクの公平性評価に利用可能です。

ただし、FHIBEは公平性および偏りの検証にのみ利用可能であり、AIモデルのトレーニングには利用できません。バイアス軽減ツールのトレーニングには利用が認められています。ソニーAIは、倫理的なデータ収集は困難な課題であると認識しつつも、FHIBEがコミュニティにとって新たなベンチマークとなることを期待しています。AI倫理担当リードリサーチサイエンティストのアリス・シャン氏は、FHIBEがインフォームドコンセント、プライバシー、公正な報酬、安全性、多様性、有用性に関するベストプラクティスを取り入れた責任あるデータ収集が可能であることを証明し、AI業界における公正で透明性のある未来に向けた新たな先例を築くと述べています。