## 機械学習の2年間 vs プロンプトの1ヶ月

https://www.levs.fyi/blog/2-years-of-ml-vs-1-month-of-prompting/

**Original Title**: 2 Years of ML vs. 1 Month of Prompting

数年にわたる機械学習モデル開発で構築した保証請求分類システムを、わずか1ヶ月間のLLMプロンプトエンジニアリングで同等以上の性能で置き換え、データやアノテーションに依存しない新たな開発プロセスを確立した。

**Content Type**: ⚙️ Tools
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 96/100 | **Annex Potential**: 96/100 | **Overall**: 96/100

**Topics**: [[LLM活用, プロンプトエンジニアリング, 機械学習モデル開発, テキスト分類, 開発プロセス改善]]

自動車メーカーの保証請求分類プロジェクトに関する記事です。長年SQLクエリで分類してきましたが、記述の複雑化や意味的ニュアンスに対応できず限界がありました。

2023年、同社は教師あり機械学習モデルによる分類自動化プロジェクトを開始しました。
1.  **データ収集**: 数ヶ月かけて「症状」の定義を統一し、ドメインエキスパートによる数千件の手作業でのラベル付けを実施。しかし、数ヶ月かけても半分しか完了しませんでした。
2.  **前処理**: 9段階の前処理パイプラインを6ヶ月かけて構築。多言語対応や専門用語の処理など、複雑なテキストデータを整備しました。
3.  **モデリング**: 様々な手法を試した結果、TF-IDFとXGBoostの組み合わせが最も優れていると判明。しかし、本番環境への移行（クラウド化、UI開発、ベンダー連携、IT調整）には数年を要しました。
最初のモデル群のデプロイ後、プロジェクトの優先順位が変わり、データ不足が深刻化。新しいデータセットのラベル付けにはさらに数ヶ月かかる見込みでした。

当初、GPT-3.5による少量のプロンプト試行では精度、レイテンシ、コストの問題で失敗しました。しかし2年後、LLMの状況は劇的に変化。そこで同社は、自社のXGBoostモデルと6つの最先端LLMをベンチマークしました。初期段階ではXGBoostが平均で約15%優位でしたが、LLMも幅広いカテゴリで可能性を示しました。

費用対効果を考慮し、「Nova Lite」に焦点を当て、プロンプトの反復改善を開始。プロンプトの評価と推論を組み合わせ、予測とLLMの推論を比較し、失敗ケースからギャップを特定。それをより大きなLLMに渡し、プロンプトの改良を生成させるプロセスを6ラウンド繰り返しました。
結果として、Nova Liteは5つのカテゴリのうち4つで教師ありXGBoostモデルと同等か、わずかに上回る性能を達成。「cut-chip」カテゴリでは35ポイントも改善し、ベースラインを上回りました。「Superficial-appearance」は依然として課題でした。

**エンジニアにとってなぜこれが重要か**: 著者は、これは単にモデルを置き換えたのではなく、「プロセス全体を置き換えた」と強調しています。従来の教師あり機械学習は、安定した分類目標、膨大なラベル付きデータ、大規模なパイプライン開発を必要とします。しかし、LLMはこのプロセスを根本から変革します。分類のタクソノミーが頻繁に変動する場合、データが不足している場合、あるいは要件がアノテーションよりも速く変化する場合、LLMは「不可能なバックログ」を「プロンプトの反復ループ」へと変える力を持っています。これにより、データ収集、アノテーションサイクル、パイプラインエンジニアリングに縛られることなく、迅速かつ柔軟な分類ソリューションが可能になるという点で、ウェブアプリケーションエンジニアにとって重要な知見です。