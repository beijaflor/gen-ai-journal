## Metaが1600以上の言語に対応した文字起こしAI「Omnilingual ASR」を公開

https://gigazine.net/news/20251111-meta-omnilingual-asr/

Metaは、1600以上の言語に対応し、学習データを削減したオープンソースの文字起こしAI「Omnilingual ASR」を公開しました。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 80/100 | **Overall**: 80/100

**Topics**: [[AI音声認識, 多言語対応, オープンソースAI, 機械学習モデル, データセット]]

Metaは、1600以上の言語をサポートするオープンソースの自動音声認識（ASR）モデル「Omnilingual ASR」をリリースしました。このモデルは、ウェブアプリケーションエンジニアが多言語対応のサービスを構築する上で、非常に重要な進展となると筆者は指摘しています。

Omnilingual ASRの主要な技術的特徴は、70億のパラメーターを持つ音声エンコーダー「wav2vec 2.0」を利用することで、従来のASR開発で必要とされた膨大な学習データを大幅に削減している点です。これにより、リソースが限られた環境でも広範な言語に対応したモデルを効率的にトレーニングできるようになりました。実際に、対応言語の78%で文字誤り率（CER）が10%を下回る高精度を達成しており、多くの言語が50時間未満、中には10時間未満の学習データでトレーニングされたと説明されています。

さらに、このモデルは大規模言語モデルで採用されているコンテキスト内学習（In-Context Learning）をサポートしており、少ない操作で新たな言語への対応を拡張できる点が強調されています。この機能は、Whisperなどの既存モデルと比較して圧倒的に多くの言語をカバーするOmnilingual ASRの大きな強みであり、特定の地域やニッチな市場向けのアプリケーション開発において、開発者がより迅速かつ柔軟に対応できることを意味します。

Metaは、Omnilingual ASRのソースコード、ドキュメント、および開発時に収集した大規模な音声データセット「Omnilingual ASR Corpus」をGitHubとHugging Faceで公開しています。デモページも提供されており、実際に試用してその性能を確認できます。筆者は一部の音声認識エラーの例を挙げつつも、その卓越した多言語対応能力と拡張性、そしてオープンソースとしてのアクセシビリティが、グローバルなウェブサービス開発や多言語音声インターフェースの構築に計り知れない価値をもたらすと評価しています。