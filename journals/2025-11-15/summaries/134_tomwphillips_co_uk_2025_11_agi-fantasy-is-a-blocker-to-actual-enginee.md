## AGI幻想が実際のエンジニアリングを阻害する

https://www.tomwphillips.co.uk/2025/11/agi-fantasy-is-a-blocker-to-actual-engineering/

**Original Title**: AGI fantasy is a blocker to actual engineering

本記事は、AGI（汎用人工知能）幻想が現実のエンジニアリングを阻害し、非効率かつ環境・社会的に問題のある大規模AI開発を招いていると警鐘を鳴らす。

**Content Type**: AI Hype
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 84/100 | **Annex Potential**: 86/100 | **Overall**: 80/100

**Topics**: [[AGI幻想, AI倫理, 環境負荷, 大規模言語モデル, 目的特化型AI]]

Tom Phillips氏は、OpenAIを筆頭にシリコンバレーで蔓延するAGI（汎用人工知能）への根強い信仰が、実際のエンジニアリングを妨げていると批判しています。カレン・ハオ氏の著書「Empire of AI」を引用し、イーロン・マスク氏がOpenAIを設立した理由が、DeepMindのデミス・ハサビス氏が先にAGIを構築するのを阻止するためだったという逸話を紹介。OpenAIの共同創業者兼チーフサイエンティストであるイリヤ・サツケヴァー氏もまた、社内外でAGIの到来を熱心に説いていると指摘します。

著者は、GPT-2の成功によって「純粋言語仮説」、すなわち言語モデルのみでAGIが生まれるという考えがOpenAI内で主流になったことを説明。これが、より多くのデータ、パラメーター、計算資源をひたすら追求する大規模なAI開発に繋がっていると述べます。その結果、データセンターは毎秒数百リットルの水を消費し、電力網の供給不足から汚染源となるガス発電機に依存。新たなハードウェアの製造と運用によるCO2排出量が増加し、また、児童性的虐待素材やヘイトスピーチなどを生成しないようAIを制御するために、データワーカーの搾取と精神的外傷といった問題を引き起こしていると強調します。

これらの環境的・社会的な負の側面は、AGIがもたらすであろう「巨大な期待値（EV）」によって正当化されている、と筆者は指摘します。しかし、AGIの価値や実現確率が不明瞭かつ反証不可能なため、このEVに基づく議論は無意味であると断じています。むしろ、AGIとは対照的に、環境破壊などの外部性は、既知の負の価値と確実な確率を持っているとし、そのコストは社会全体が現在負担していると主張します。

テクノロジストとして、効率的かつ無害な問題解決を追求すべきだと考えるPhillips氏は、AGIとしてのLLMがこれら3つの観点すべてにおいて失敗していると結論付けます。AGI幻想を捨て去り、LLMや他の生成モデルを「すべての問題」ではなく「特定の解決策」として評価し、適切な費用対効果分析を行うべきだと提言。その上で、より小さく、目的特化型に構築された生成モデルや、識別モデルなども活用し、トレードオフを考慮した「実際のエンジニアリング」に取り組むことの重要性を説いています。