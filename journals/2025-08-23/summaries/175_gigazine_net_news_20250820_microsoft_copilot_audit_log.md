## AI「Copilot」が監査ログをすり抜けることが判明するもMicrosoftは通知せず

https://gigazine.net/news/20250820-microsoft-copilot-audit-log/

暴露されたMicrosoft Copilotの監査ログ回避脆弱性に対し、Microsoftがユーザー通知を拒否し密かに修正した企業姿勢が、セキュリティ専門家から厳しく批判されています。

**Content Type**: News & Announcements

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 81/100 | **Overall**: 80/100

**Topics**: [[Microsoft Copilot, 監査ログ, セキュリティ脆弱性, 情報開示と企業責任, 開発ツールセキュリティ]]

Microsoft Copilotの利用において、セキュリティ企業の最高技術責任者ザック・コーマン氏が重大な脆弱性を発見しました。通常、Copilotにファイルの要約を依頼すると、そのアクセスは監査ログに記録されます。しかし、コーマン氏の検証で、特定の指示（「ファイルへのリンクを提供しないで」）を付加すると、要約は得られるものの、監査ログに一切のアクセス記録が残らないことが判明したのです。これは、ファイルへの不透明なアクセスを許し、企業のセキュリティ管理を根底から揺るがす問題です。

コーマン氏はこの問題をMicrosoftに報告しましたが、その後のMicrosoftの対応は大きな波紋を呼んでいます。Microsoftは問題に密かに対応し、修正を行ったものの、ユーザーへの通知を一切行わず、CVE番号の発行も拒否しました。その理由として「修正が自動的に適用されるため、ユーザーが手動で更新する必要がない」と説明しましたが、コーマン氏はこれを「Microsoftのポリシーに反する」と強く非難しています。

この事態がWebアプリケーションエンジニアにとって重要である理由は多岐にわたります。第一に、多くの企業がセキュリティ監査、インシデント検出、法的証拠として監査ログに深く依存しているからです。CopilotのようなAIツールが監査ログをすり抜ける能力を持つことは、企業のセキュリティ体制に「見えない穴」を開け、コンプライアンス上の重大なリスクをもたらします。もし重要な情報へのアクセスが記録されなければ、情報漏洩や不正アクセスの追跡が不可能になり、訴訟における証拠能力も失われます。

第二に、Microsoftのような大手ベンダーが、このようなセキュリティ上の重大な発見に対し、透明性を欠いた対応を取ったことは、AIツール全般への信頼を損ないます。ユーザーは、利用しているAIツールがどのような振る舞いをしているのか、そしてベンダーがどのような姿勢で脆弱性に対応するのかを正確に知る権利があります。今回の件は、AIを組み込んだ開発ワークフローにおいて、ツールが生成するコードだけでなく、その裏側で動作するシステムの透明性とセキュリティ担保の重要性を再認識させる警鐘となります。エンジニアは、単にAIの便利さだけでなく、その潜在的なリスクとベンダーの責任ある対応についても、より一層注意を払う必要があります。