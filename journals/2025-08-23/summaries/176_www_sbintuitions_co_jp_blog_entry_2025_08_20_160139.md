## Sarashina-Embedding-v2-1B: 日本語に特化した指示を付与できるテキスト埋め込みモデル

https://www.sbintuitions.co.jp/blog/entry/2025/08/20/160139

SB Intuitionsが、日本語に特化した指示付与型テキスト埋め込みモデル「Sarashina-Embedding-v2-1B」を公開し、JMTEBベンチマークで最高水準の性能を達成しました。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 89/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[テキスト埋め込み, 日本語自然言語処理, 検索拡張生成, 指示チューニング, モデル評価]]

SB Intuitionsが開発した日本語特化の指示付与型テキスト埋め込みモデル「Sarashina-Embedding-v2-1B」は、日本語を用いたウェブアプリケーション開発に新たな可能性を拓きます。このモデルの最大の特長は、ユーザーがクエリに具体的な「指示文」を付与することで、その意図に沿った最適なテキストベクトルを生成できる点です。例えば、情報検索では「質問への回答」を、意味的類似性タスクでは「意味的に近い文章」を優先するといった、タスクに応じた柔軟なベクトル調整が、モデルの再学習なしに可能になります。

これは、検索拡張生成（RAG）やセマンティック検索、文書分類など、テキストの「意味」を扱うあらゆるアプリケーションにおいて、開発者がより細かくモデルの振る舞いを制御できることを意味します。例えば、RAGシステムでユーザーの質問に対する直接的な回答を優先したい場合と、より広範な関連情報を取得したい場合で、同じクエリでも異なる指示を与えることで、検索結果の質を飛躍的に向上させられます。

Sarashina-Embedding-v2-1Bは、日本語テキスト埋め込みベンチマークJMTEBで最高水準のスコアを達成しており（2025年7月28日時点）、特にRetrieval、STS、Rerankingタスクで高い性能を発揮します。この実証された性能は、日本語に特化した高品質な埋め込みモデルを求めるエンジニアにとって、信頼性の高い選択肢となるでしょう。複雑な学習手法（弱教師あり学習、教師あり学習、モデルマージ）によって構築されており、LLMを活用した合成データ生成やHard Negative Miningの工夫が性能に貢献しています。

商用利用には制限があるものの、日本語ウェブサービスで高精度なAI機能を実装したい開発者にとって、本モデルは非常に強力なツールとなり得ます。将来的にはマルチモーダル対応も視野に入れており、さらなる進化が期待されます。