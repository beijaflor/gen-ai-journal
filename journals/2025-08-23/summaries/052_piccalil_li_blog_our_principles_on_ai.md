## Our principles on AI

https://piccalil.li/blog/our-principles-on-ai/

Piccalilliは、LLMや生成AIに関する明確な方針を表明し、いかなるAI生成コンテンツも公開しないと宣言し、人間の読者向けに高品質なコンテンツを提供し続ける姿勢を強調します。

**Content Type**: 💭 Opinion & Commentary

**Scores**: Signal:5/5 | Depth:2/5 | Unique:4/5 | Practical:3/5 | Anti-Hype:5/5
**Main Journal**: 76/100 | **Annex Potential**: 78/100 | **Overall**: 76/100

**Topics**: [[AI生成コンテンツ, 品質基準, 開発ツール, AIの過剰な宣伝, コンテンツポリシー]]

フロントエンド教育プラットフォームPiccalilliは、LLMや生成AIに関する明確な方針を表明しました。彼らは、文章、コード、動画、音声、画像を含むいかなるAI生成コンテンツも決して公開せず、AIによって生成されたコンテンツの推奨や外部からの寄稿も受け入れません。これは、「人間が人間のために書く」という原則を徹底し、AIやクローラーではなく、人間の読書体験の最適化に焦点を当てるという強い意志の表れです。

記事では、AI生成コンテンツが「完全にゴミのように読める」と厳しく批判され、その低品質さが読者に対する冒涜であると指摘されています。また、AIを盗用や剽窃を繰り返す「ワードシャフラー」とまで表現し、自身が多大な投資をしてきた出版物でそのような作品を受け入れることはないと強調しています。

特に注目すべきは、彼らが実際に開発プロジェクトでAIツールを試した経験です。その結果、これらのツールは一部有用な点もあったものの、全体としては「過剰に宣伝され、無駄が多く、しばしば低品質な出力を生み出し、最終的に破棄せざるを得なかった」という結論に至ったと述べています。Piccalilliは流行に流されることなく、常に人間中心の高品質なコンテンツ提供を追求する姿勢を改めて表明しました。

この方針は、日々AIツールの利用を検討するウェブアプリケーションエンジニアにとって重要です。AI生成コンテンツの品質や信頼性に対する懸念を共有し、実践的な開発現場でのAIツールの現実的な限界を示唆しています。過度なAIへの期待をせず、人間による品質管理と創造性の重要性を再認識させる、貴重な視点を提供しています。