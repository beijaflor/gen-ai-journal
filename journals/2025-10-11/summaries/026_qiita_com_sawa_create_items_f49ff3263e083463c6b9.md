## LLMでPDFから事後学習データを自動生成するシステムを構築してみた

https://qiita.com/sawa-create/items/f49ff3263e083463c6b9

松尾研LLM開発コンペ参加者が、高難度ベンチマーク突破のため、LLMを活用してPDFから事後学習データを自動生成・検証するシステムの構築過程と課題を詳述する。

**Content Type**: Technical Reference

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 82/100 | **Annex Potential**: 83/100 | **Overall**: 84/100

**Topics**: [[事後学習データ生成, 合成データ, プロンプトエンジニアリング, OCR処理, LLM品質検証]]

松尾研LLM開発コンペ参加者であるTeam Caminoは、「Humanity’s Last Exam」のような高難度ベンチマーク突破を目指し、PDF形式の公開資料からLLMを用いて事後学習データを自動生成するシステムを構築しました。これは、高品質で特定の推論能力を強化する学習データが不足している現状に対し、エンジニアが直面する課題への具体的な解決策を提示します。

彼らのシステムは、まず科学文書・数式認識に優れたOCRツール「Nougat」でPDFをマークダウンに変換します。次に、生成用LLMが、厳格なプロンプトに従い、高難度で独立したQAペア（推論過程を含まず最終解答のみ）を生成。さらに、検証用LLMがこのデータの品質（ソース独立性、解答の直接性、論理的一貫性）を自動でチェックする、二段階の検証プロセスを採用しています。vLLMを活用した高速推論サーバー上でのパイプライン自動化は、効率的なデータ生成を可能にします。

この取り組みは、LLMを活用した合成データ生成の具体的な手法、効果的なプロンプト設計、多段階検証による品質保証の重要性を示唆します。一方で、複雑な数式抽出の難しさ、品質と量のトレードオフ、データ由来のドメイン偏り（OOD問題）、生成と検証に用いるLLMの選定（同一モデルか、異なるモデルか）といった実践的な課題も浮き彫りになりました。

これらの知見は、AIを活用したサービス開発において、既存のリソースから目的に合った高品質な学習データを効率的に生成したいと考えるウェブアプリケーションエンジニアにとって非常に価値があります。特に、LLMの能力を最大限に引き出すためには、データ自体の質と、それを担保するための自動化された検証プロセスの設計がいかに重要であるかを具体的に示しており、データパイプライン設計における現実的な視点を提供します。