## LLM（生成AI）から業務システムにMCPサーバーを経由してアクセスする #AIエージェント

https://qiita.com/miyakiyo/items/992e848291e5dfdef3a1

Model Context Protocol (MCP)が、LLMによる複数業務システムへの安全なアクセスと、情報取得からデータ更新までのAIエージェント自動化基盤をどのように実現するかを詳述します。

**Content Type**: 🛠️ Technical Reference

**Scores**: Signal:4/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 78/100 | **Overall**: 80/100

**Topics**: [[AIエージェント, 業務システム連携, Model Context Protocol (MCP), LLMオーケストレーション, API設計]]

この記事は、LLM（生成AI）が複数の業務システムへ安全にアクセスするための「Model Context Protocol (MCP)」に基づいたAIエージェント基盤の構築手法を詳述します。Webアプリケーションエンジニアにとって、これはLLM活用における大きな課題、例えば「最新かつ正確な社内データへの参照」や「細かな操作権限制御」を解決する具体的なアプローチを提供します。

MCPは、LLMと社内システム間のやり取りをJSON-RPC over HTTPで標準化し、業務システムの一覧取得や呼び出しを共通化します。ユーザーからの指示を受け取ったLLMは、アプリケーションを介してMCPサーバーへアクセスし、必要なツール（業務システム）を呼び出して最新情報をプロンプトに取り込みます。このアーキテクチャは、PDFからの情報抽出や非システム化データのグラフ化といった「情報取得」だけでなく、将来的には在庫予約やワークフロー起票などの「データ登録/更新」まで自動化する拡張性を持つ点が重要です。

MCPサーバーの主要機能として、Origin/APIキーによる厳格なセキュリティ認証、Mcp-Session-Idを用いたセッション管理、JSON Schemaによるツール（業務システム）定義の提供、入力検証を伴うツール呼び出しなどが挙げられます。これにより、LLMが社内データに触れる際の安全性が確保され、開発者は信頼性の高いAIエージェントを構築できます。また、ストリーミング実装や承認フロー、RAG連携といった将来的な強化アイデアも提示されており、Webアプリケーション開発において、複雑なAI統合を体系的に進めるための強力な足がかりとなるでしょう。