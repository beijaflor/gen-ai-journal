## AI agents at scale: Rox’s Vercel-powered revenue operating system

https://vercel.com/blog/ai-agents-at-scale-roxs-vercel-powered-revenue-operating-system

RoxはVercelのNext.js、サーバーレス機能、AI SDKを活用し、数千のAIエージェントをデプロイする収益オペレーティングシステムを迅速に開発・グローバル展開した。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:3/5
**Main Journal**: 77/100 | **Annex Potential**: 73/100 | **Overall**: 76/100

**Topics**: [[AI Agents, Vercel, Serverless Functions, AI SDK, Web Application Development]]

Vercelのブログ記事は、AIエージェントを大規模に展開するRoxの「Revenue Operating System」が、Vercelのプラットフォームを活用していかに高速な開発とグローバルなスケーラビリティを実現したかを解説している。

Roxは、見込み客の調査やエンゲージメントを行うために、数百から数千ものAIエージェントをリアルタイムで起動するシステムを構築した。この際、ブラウザのHTTP/2による同時接続数制限（100件）という技術的課題に直面する。Roxは、Vercelのサーバーレス関数を使ってこれらの呼び出しをバッチ処理することで、リクエストの停止を防ぎ、結果を効率的にストリーミングすることに成功した。これにより、中東やヨーロッパを含むグローバルな顧客に対しても、数秒で調査結果を提供できるようになった。

さらに、Roxのチャット駆動型インターフェース「Rox Command」はVercel AI SDKによって実現されている。このSDKを使うことで、大規模言語モデルからの応答ストリーミングが容易になり、会話型AIの迅速な統合を可能にした。Vercelのプレビューデプロイ機能は、新機能のレビューサイクルを大幅に短縮し、「Rox Command」を数週間でリリースできたと述べている。

ウェブアプリケーションエンジニアにとって重要なのは、AIエージェントのスケーリングにおける具体的な課題解決策だ。多数のAIエージェントからのAPI呼び出しをフロントエンドで効率的に処理するため、サーバーレス関数を用いたバッチ処理は、同時接続数の制限を回避し、ユーザーエクスペリエンスを損なわないための有効なアーキテクチャパターンを示している。また、AI SDKとプレビューデプロイを組み合わせた開発ワークフローは、会話型AI機能の迅速な市場投入を可能にする実践的なアプローチとなる。Vercelのインフラストラクチャは、3〜5分のデプロイ時間、P95ロード速度の2.5倍改善、複数地域でのシームレスなパフォーマンスを提供し、開発者はインフラ管理よりも製品開発に集中できるという、高い開発者体験を実現する。これは、AIを活用したウェブアプリケーション開発において、速度と信頼性、そして効率性を追求する上で非常に参考になる事例だ。