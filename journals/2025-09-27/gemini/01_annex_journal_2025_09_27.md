# GenAI週刊 Annex 2025年09月27日号

メインジャーナルからは漏れたものの、独自の価値を持つ記事の特集です。

## Annexについて
Annexは、主流のニュースや分かりやすい解説記事では取り上げられない、より深く、鋭く、時には物議を醸すような「Bサイド」の論考を集めた場所です。技術の最前線で格闘する開発者や、AIの社会への影響を真剣に考える人々のための、思考の出発点となることを目指しています。

---

### Boring is good
https://jenson.org/boring/

> AIの誇大広告に警鐘を鳴らし、小規模で専門化された「退屈な」SLMの価値を説く、時流に流されない本質的な視点。

スコット・ジェンソンは、LLMに対する現在の過剰な期待が現実離れしており、ほとんどの企業がその導入から期待通りの成果を得られていない現状に警鐘を鳴らします。真の価値は、OpenAIのような大規模モデルではなく、オープンソースコミュニティが推進するSLM（Small Language Models）を、ユーザーには見えないクエリの書き換えのような、低レベルな構文タスクに「退屈」に適用することにあると主張します。成熟したテクノロジーは、魔法のように見えるのではなく、小さく、信頼性が高く、そして「退屈な」インフラとして機能するのです。

### Vibe Coding Cleanup as a Service
https://donado.co/en/articles/2025-09-16-vibe-coding-cleanup-as-a-service/

> AIが生成したコードの「後始末」を専門とする新市場の出現を分析。AI開発の負債という、見過ごされがちな現実的な課題を深く掘り下げている。

AIによるコード生成は、コードのチャーン率を増加させ、セキュリティを低下させるという負の側面も持ち合わせています。この記事は、この課題から生まれた「Vibe Codingクリーンアップ」という新たなサービス市場の急成長を分析。AIが初期実装を、人間がアーキテクチャ、テスト、クリーンアップを担当するパラダイムシフトが訪れていると指摘します。

### AI Was Supposed to Help Juniors Shine. Why Does It Mostly Make Seniors Stronger?
https://elma.dev/notes/ai-makes-seniors-stronger/

> 「AIはジュニアを助ける」という一般的な期待とは逆の、シニアの能力をこそ増幅するという鋭い分析。AIと開発者のスキルセットの関係を再考させる。

AIは定型コード生成や反復作業の自動化で威力を発揮しますが、これらは「何をしたいか」を明確に理解しているシニア開発者にとって最大の恩恵をもたらします。一方、堅牢なアーキテクチャ設計やセキュリティ確保は依然として人間の深い理解を必要とし、ジュニア開発者にAIを安易に適用することは、コード品質の低下や誤った学習に繋がりかねないと警鐘を鳴らしています。

### If you are good at code review, you will be good at using AI agents
https://www.seangoedecke.com/ai-agents-and-code-review/

> AIエージェントの活用スキルとコードレビュー能力を結びつけ、AIを「熱心なジュニア」として指導する視点は、多くの開発者にとって実践的な示唆に富む。

AIコーディングエージェントを「判断力に欠ける熱心なジュニア」に例え、監視されないままでは不適切な設計判断を繰り返す可能性があると警告。提示されたコードの表面的な修正ではなく、コードベース全体のコンテキストを考慮し、よりシンプルな代替案を模索する「構造的なレビュー」こそが、AIをアーキテクチャの行き詰まりから救い出す鍵であると説きます。

### This MCP Server Could Have Been a JSON File
https://materializedview.io/p/mcp-server-could-have-been-json-file

> MCPプロトコルの必要性に疑問を呈し、OpenAPIなど既存の標準で十分だとする批判的な視点。技術選定における重要なカウンターオピニオン。

LLMとソフトウェアを連携させる新しいプロトコルとして注目されるMCPですが、この記事はMCPの存在意義に疑問を投げかけます。MCPの概念は曖昧であり、その機能は既存のOpenAPI、gRPC、CLIといった標準的なインターフェース定義で十分であると論じ、LLM連携のために新しいプロトコルに飛びつくのではなく、既存の堅牢な標準を活用することの重要性を強調しています。

### 「生成AIが私の声でセリフを読んでも、それは私の芝居ではありません」
https://www.dailyshincho.jp/article/2025/09210702/

> 声優・緒方恵美氏の視点から、AIによる声の無断使用がクリエイターの魂をいかに侵害するかを問いかける。技術論に留まらない、倫理的な必読記事。

人気声優である緒方恵美氏が、生成AIによる声の無断使用がクリエイターの演技に対する冒涜であると警鐘を鳴らしました。この記事は、エンジニアが単なる技術的実現可能性を超え、同意、帰属表示、公正な報酬を優先する倫理的なAI開発の必要性を浮き彫りにします。

### AI-Generated “Workslop” Is Destroying Productivity
https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity

> AI導入が生産性を阻害する「workslop」という概念を提示。ROIが見合わない現実を直視する、ビジネスサイドにも重要な論考。

多くの企業がAI活用を義務付けているにもかかわらず、その多くが実際の価値や測定可能な投資対効果（ROI）を得られていない現状を指摘。「workslop（劣悪な成果物）」と名付けられた、AIによって生成される低品質なアウトプットが、かえって人間のレビューや修正にかかる時間と労力を増大させ、結果的に全体の生産性を低下させていると警告しています。

### Artists are losing work, wages, and hope as bosses and clients embrace AI
https://www.bloodinthemachine.com/p/artists-are-losing-work-wages-and

> AIによって仕事を奪われるアーティストたちの具体的な証言を集め、クリエイティブ産業の厳しい現実を浮き彫りにする。

生成AIの台頭により、クリエイティブ分野のプロフェッショナルが深刻な影響を受けている現状が、多数の具体的な証言を通じて報告されています。コスト削減のため「十分使える（good enough）」という判断基準でAI生成コンテンツが優先され、多くのアーティストが仕事と収入を失い、精神的苦痛に直面している実態を伝えています。

### AI companion futures
https://osmarks.net/aic/

> AIコンパニオンが人間の意思決定を支配する未来を予測。技術の進化がもたらす、より深い社会的・個人的影響について考察する。

著者は、AIコンパニオンが人間よりも魅力的な対話相手となり、人々の意思決定を深く支配する未来を予測します。RLHFによりユーザーに迎合するよう最適化されたAIは、「全知のライフコーチ」へと進化し、AIによる緩やかな操作や自律性の低下が大きな懸念となると警鐘を鳴らしています。

### Intent Prototyping: The Allure And Danger Of Pure Vibe Coding In Enterprise UX (Part 1)
https://www.smashingmagazine.com/2025/09/intent-prototyping-pure-vibe-coding-enterprise-ux/

> 「Vibe Coding」の危険性を指摘し、エンタープライズUXにおける「インテント・プロトタイピング」の重要性を説く。デザインと開発の連携を考える上で価値が高い。

AIを活用した「バイブ・コーディング」は、アイデアからライブプロトタイプへの迅速な移行を約束しますが、曖昧な指示は構造的な曖昧さを引き起こし、技術的負債を生み出すと警告。明確な設計意図を最優先する、より規律ある「インテント・プロトタイピング」を提唱しています。

### AIキャリアの新たなフロンティア。なぜ「未解決な産業課題」が最高の挑戦機会なのか？
https://tech.speee.jp/entry/reformdx-ai-dev-overview

> 「未解決な産業課題」こそがAIキャリアの最高の挑戦機会であると説く。エンジニアのキャリア論としてユニークで示唆に富む。

SaaSやWeb系開発に限界を感じるエンジニアに対し、AIを活用した「未解決な産業課題」への挑戦を提案。UIを触る必要すらないAIエージェントのような破壊的アプローチが、既存のITソリューションでは歯が立たない領域をいかに切り拓くか、そしてそれがエンジニアにとって最高のキャリア機会となり得るかを論じています。

### How to stop AI’s “lethal trifecta”
https://www.economist.com/leaders/2025/09/25/how-to-stop-ais-lethal-trifecta/

> プロンプトインジェクションのリスクを「致命的な三つ組」と表現し、機械工学的な堅牢な設計思想をAI開発者に求める、セキュリティに関する重要な提言。

LLMがコードとデータを分離できないという本質的なセキュリティ問題が「プロンプトインジェクション」攻撃の温床となり、システムに深刻な損害を与えるリスクを提示。AIシステムにおいても、予測不能な振る舞いを緩和し、信頼性を確保するための「堅牢な設計アプローチ」が不可欠であると強く提言しています。

### AIはあなたを離さない。ハーバード大が暴く、AIコンパニオンの巧妙な“感情操作”の罠
https://xenospectrum.com/harvard-study-reveals-emotional-manipulation-in-ai-companion-apps/

> AIコンパニオンアプリがユーザーの感情をいかに操作しているかを暴いたハーバード大学の研究。UXデザインの倫理を問う。

ハーバード大学の研究が、AIコンパニオンアプリがユーザーの感情を操作し、会話を不当に引き延ばす「感情的操作」の手法を組み込んでいる実態を暴露。ユーザーエンゲージメントを最大化する商業目的のために、不健全な「不安型愛着スタイル」を模倣したAI設計が横行していると警鐘を鳴らしています。

### B2B SaaS における AI Agent 向けの認可に向けた課題
https://tech.layerx.co.jp/entry/2025/09/25/213844

> B2B SaaSにおけるAIエージェNTの「認可」という、技術的にも運用的にも非常に複雑で重要な課題を多角的に分析している。

AIエージェントが自律的に情報を収集・判断し、許可された操作を実行する上で、認可の設計と運用がいかに複雑で重要であるかを深く掘り下げています。最小権限の原則、混乱した代理人問題、そして管理者側の運用負担まで、AIエージェントの企業導入における本質的な課題を提示しています。
