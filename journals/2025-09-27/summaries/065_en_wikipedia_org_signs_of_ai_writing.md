## Wikipedia:Signs of AI writing

https://en.wikipedia.org/w/index.php?title=Wikipedia:Signs_of_AI_writing

Wikipediaは、AIチャットボットが生成したコンテンツに見られる特徴的な言語、文体、マークアップ、引用のパターンを詳細に解説し、その検出を支援するガイドを公開しました。

**Content Type**: 📖 Tutorial & Guide

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 88/100 | **Annex Potential**: 86/100 | **Overall**: 88/100

**Topics**: [[AI生成テキストの検出, LLM出力の特性, コンテンツ信頼性, プロンプトエンジニアリングの課題, コードレビューと品質管理]]

Wikipediaが公開したこの「AIの文章の兆候」ガイドは、AIチャットボットによって生成されたコンテンツを特定するための具体的なパターンを多数リストアップしています。ウェブアプリケーションエンジニアにとって、これはAIアシスタントやエージェントが生成するコード、ドキュメント、テストケースなどをレビューする際の重要な手がかりとなります。

主な兆候は以下のカテゴリに分類されます。
まず、**言語とトーン**では、対象の重要性を過度に強調する表現、宣伝文句、著者の独断的な意見、定型的な接続詞の多用、冗長なセクション要約などが挙げられます。これは、AIが自信に満ちた誤情報を生成したり、冗長な説明をしたりする傾向と重なります。

次に**文体**では、セクション見出しの不適切な大文字化、過剰な太字や箇条書き、絵文字の混入、不自然なエモダッシュ（—）の多用、カーリークオート（“ ”）の使用が指摘されます。AIが文脈を考慮せず定型フォーマットを適用する問題を示唆します。

**ユーザーへの意図されたコミュニケーション**の兆候として、AIがプロンプトへの返答として生成した「これが役立つことを願います」「他に何かありますか？」といった対話的表現や、知識カットオフに関する免責事項、プロンプト拒否メッセージ、プレースホルダーテキストがそのまま残ることがあります。これは、AIの出力が適切にレビューされずに利用される危険性を示しています。

また、**マークアップ**においては、AIがWikiTextではなくMarkdownを誤って使用したり、壊れたWikiText、プロンプト内部で使用される特定のトークン（例: `turn0search0`）、URLに付与されるUTMソースパラメータ（例: `utm_source=chatgpt.com`）などが挙げられます。これは、AIが特定の出力フォーマットに不慣れであるか、訓練データ由来の痕跡を残すことを示しており、特にMarkdownを日常的に扱う開発者には馴染み深いかもしれません。

最後に**引用**の不備は、壊れた外部リンク、無効なDOIやISBN、または不適切な引用スタイルの使用など、AIが「もっともらしいが虚偽の」情報を生成するハルシネーションの明確な兆候です。

なぜこれが重要かというと、AI生成物が開発ワークフローに統合されるにつれ、その品質と信頼性を迅速に評価する能力が不可欠になるからです。これらの兆候を理解することで、エンジニアはAI生成コードのバグや非効率性、AIが提供するドキュメントの誤情報を早期に特定できます。特に、引用のハルシネーションは、プロダクトの機能やセキュリティに深刻な影響を与える可能性があるため、細心の注意を払う必要があります。単に表面的な問題を修正するだけでなく、AIの限界を理解し、その出力を批判的に評価するための実用的なガイドとして活用すべきです。