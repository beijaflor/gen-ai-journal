## 「ChatGPTが“嘘をつかなくなる”？」SNSで話題の“ファクトベースAI”プロンプトが凄い！

https://www.smartwatchlife.jp/59860/

SNSで話題の「ファクトベースAI」プロンプトは、ChatGPTのハルシネーションを抑制し、根拠に基づいた正確で誠実な情報提供を促すことで、AIとの信頼性の高い対話を実現します。

**Content Type**: Tutorial & Guide
**Language**: ja

**Scores**: Signal:3/5 | Depth:3/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 100/100 | **Annex Potential**: 95/100 | **Overall**: 72/100

**Topics**: [[AI活用術, ChatGPT, プロンプトエンジニアリング, ハルシネーション対策, 信頼性向上]]

AI教育分野の専門家であるみやっち氏（@miyachi_ai）がThreadsで公開した「信頼性の高い情報を提示できる高精度なファクトベースAI」プロンプトがSNSで急速に拡散されており、ChatGPTのハルシネーション（もっともらしい嘘をつく現象）問題への有効な対策として注目されています。このプロンプトは、AIが知らないことでも自信満々に答えてしまうという長年の課題に対し、「わかりません」と正直に明言させることで、より誠実な情報提供を促すことを目的としています。

具体的なプロンプトルールとして、「わからない/未確認は『わからない』と明言する」「推測は『推測ですが』と明示する」「現在日付を必ず明記する」「根拠/出典（可能なら一次情報）を必ず添付する」「専門的知見が必要な場合は『専門家に確認を』と明記する」といった指示が含まれています。さらに、回答は【結論】【根拠】【注意点・例外】【出典】【確実性: 高/中/低】という特定のフォーマットで出力するよう求められています。

このプロンプトを適用すると、ChatGPTの回答は断定的な口調が減り、根拠に基づいた説明に変わり、出典が自動的に挿入され、推測であることを事前に断るようになります。これは、AIに正確さを保証するための「思考フレーム」を与える効果があり、まるで研究者のような慎重な回答スタイルに変化させると筆者は指摘しています。

本プロンプトが多くの支持を集めているのは、単に回答のフォーマットを整えるだけでなく、「AIに嘘をつかない姿勢」を求める倫理的な方向性が、ハルシネーション対策、透明性、エビデンス志向といったAI時代のリテラシーとして共感を呼んだためです。Webアプリケーションエンジニアの視点からは、AIが生成するコードスニペット、技術解説、デバッグ支援などがより信頼性の高いものになることを意味し、開発ワークフローの品質と効率に直結します。AIの出力を鵜呑みにせず、かつ敵視もしないというバランスの取れた「AIを賢く使う」ための実践的な手法として、このファクトベースプロンプトは、AIとの協働における新たなスタンダードを築く第一歩となるでしょう。