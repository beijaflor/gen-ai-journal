## AIを賢く動かすのは「指示力」ではなく「文脈設計力」

https://zenn.dev/aun_phonogram/articles/44d298f8d9d0fd

「指示力」に頼らず、LLMの制約を理解し「引き算」のアプローチで文脈を設計する「コンテキストエンジニアリング」が、AIコーディングにおける生産性向上と時間の浪費を防ぐ鍵となると筆者は解説する。

**Content Type**: Tutorial & Guide
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 88/100 | **Annex Potential**: 85/100 | **Overall**: 84/100

**Topics**: [[コンテキストエンジニアリング, LLMの制約, AIコーディング効率化, プロンプト設計, 開発ワークフロー最適化]]

AIコーディングにおいて、詳細なプロンプトを作成しても期待通りの結果が得られず、かえって時間が浪費されるという問題に対し、著者はその原因がLLM（大規模言語モデル）の根本的な制約にあると指摘する。LLMは次に続く単語を確率的に予測するシステムであり、その予測精度を大きく左右するのが「コンテキスト（文脈）」である。

会話が長引くと「コンテキストの腐敗（Context Rot）」が生じ、AIの注意が分散したり、「Lost in the Middle問題」として知られる情報の見落としが発生したりする。また、AIが処理できる情報量には「コンテキストウィンドウ」という明確な上限があり、これを越えると古い情報から忘れ去られるため、重要な指示が埋もれてしまうリスクがある。

こうした制約の中でAIを賢く動かすために提唱されるのが「コンテキストエンジニアリング」だ。これは、単にプロンプトを詳細にする「足し算」のアプローチではなく、限られたコンテキストウィンドウを最大限に活用するために、本当に必要な情報だけを残し、不要な情報を「引き算」で削ぎ落とす考え方である。

具体的な対処法として、著者は以下の点を挙げる。
- **会話のリセット**: タスクの切り替わりや進捗が見られない場合に新しい会話を開始する。
- **プロジェクトルールの見直し**: 不要なルールや細かすぎる指示を削除する。
- **MCPツール（多機能チャットボットプロンプトツール）の整理**: 直近のタスクで使うツールのみを有効化し、迷ったら無効にする。
- **関係ないファイルの除外**: `.gitignore`などを活用し、AIに見せる必要のないファイルを減らす。

これらの「引き算」を適切に行うには、コード構造、システム全体、問題の本質、そして最終的なゴールを理解する基礎力が不可欠であると強調されている。コンテキストの削減は、応答品質の向上だけでなく、入力トークン数の減少によるコスト削減やレート制限の回避といった副次的なメリットももたらす。

本稿で示されたコンテキスト管理の原則は、Claude Code、Codex CLI、Cursor、GitHub Copilotなど、あらゆるAIコーディングツールに共通して適用可能である。著者は、今後複数のAIエージェントを並行して動かす時代が到来する中で、「文脈設計力」がますます重要なスキルになると結んでいる。