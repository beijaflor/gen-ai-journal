## AIによる低品質報告がOSSセキュリティを脅かす問題

https://devansh.bearblog.dev/ai-slop/

**Original Title**: On AI Slop vs OSS Security

経験豊富なバグ報奨金専門家が、AIが生成する低品質な脆弱性報告「AIスロップ」がオープンソースソフトウェアのセキュリティとメンテナーの持続可能性をいかに脅かしているかを分析し、その解決策と根本原因に切り込む。

**Content Type**: 🎭 AI Hype
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 95/100 | **Annex Potential**: 96/100 | **Overall**: 92/100

**Topics**: [[AI生成脆弱性報告, オープンソースセキュリティ, メンテナーの燃え尽き症候群, CVEシステム危機, バグ報奨金プログラムの課題]]

バグ報奨金業界で10年の経験を持つ著者は、AIが生成する低品質な脆弱性報告、いわゆる「AIスロップ」がオープンソースソフトウェア（OSS）プロジェクトのセキュリティをいかに脅かしているかを詳述する。有効なAI生成報告は容認できるものの、AIにセキュリティ調査と検証を丸投げし、LLMが出力した根拠のない仮定に基づく報告は「AIスロップ」であり、これが最大の問題だと指摘する。

AIは、特定のプロジェクトの脅威モデルを理解せず、コードベースに存在しない関数名や攻撃シナリオを幻覚的に生成し、一見もっともらしいが虚偽の報告を大量に生み出す。これにより、curlプロジェクトではセキュリティ報告の約20%がAIスロップとなり、有効な報告はわずか5%にまで低下。本物の脆弱性1件に対し、4件の偽報告が存在する状況だ。

このような低品質報告の処理は、限られたOSSメンテナーの貴重な時間と労力を奪い、燃え尽き症候群を加速させている。メンテナーは無償で貢献しているにもかかわらず、幻覚的な報告の検証に膨大な時間を費やし、精神的な疲弊に直面しているのだ。さらに、CVEシステム自体も資金不足と処理遅延で機能不全に陥っており、AIスロップがこの危機を悪化させている。

著者は、単なる提出者のBANや「検証してから提出してください」といった要請は効果がないと主張。有効な対策として、以下の点を提案する。
1.  **AI使用の義務的開示**: curlやDjangoのように、AIツールの使用を開示させ、検証の責任を提出者に求める。
2.  **PoCの基準引き上げ**: スクリーンキャスト、統合テスト、Docker環境など、再現性を証明する厳格な技術的証拠を要求する。これにより、AIは生成できない実証済みの脆弱性のみが受理される。
3.  **レピュテーションと信頼システム**: 過去に有効な報告歴のあるユーザーにのみ投稿権限を与え、新規ユーザーには保証人を立てることを義務付ける。
4.  **経済的摩擦の導入**: 未熟なユーザーからの報告に対し、返金可能な少額の手数料を徴収する。
5.  **AIアシストによるトリアージ**: AIを活用してAIスロップを特定し、フィルタリングするシステム。
6.  **スロップの公開**: 虚偽の報告を公開することで説明責任を促し、抑止力とする。

しかし、著者はこれらが根本的な解決策ではないと強調する。AIスロップは、数十億ドルの商業活動を支えるOSSのメンテナーが、燃え尽き症候群と嫌がらせの中で無償の労働を強いられているという、より大きな問題の一症状に過ぎない。真の持続可能性のためには、企業からの直接的な資金提供、より良い自動化ツール、ワークロードの分散、文化の変革、そして政策レベルでの支援が必要だと結論付けている。現在、私たちはこの問題に対し「間違った選択」をしていると警鐘を鳴らし、技術的進歩の人的基盤を維持するかの岐路に立っていると訴える。