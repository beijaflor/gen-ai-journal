## Nous Research、BotIDを活用し大規模なボットによる不正利用を阻止

https://vercel.com/blog/how-nous-research-used-botid-to-block-automated-abuse-at-scale

**Original Title**: How Nous Research used BotID to block automated abuse at scale

VercelのBotIDを導入することで、Nous ResearchはオープンソースLLMの無料提供時に発生した大規模なボットによる不正利用とそれに伴う計算リソースの浪費を効果的に防ぎ、ユーザー体験を損なうことなくサービスの安定稼働を確保した。

**Content Type**: Tools
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:3/5
**Main Journal**: 97/100 | **Annex Potential**: 90/100 | **Overall**: 68/100

**Topics**: [[ボット対策, LLMサービス運用, Vercel BotID, 不正利用対策, コスト効率]]

Nous Researchがオープンソース大規模言語モデル「Hermes」を1週間無料で提供した際、サービスは自動化されたスクリプトによる大規模な不正利用に直面した。これらのスクリプトは数千もの偽アカウントを作成し、レート制限を回避して推論リクエストを大量に実行した結果、無駄な計算リソースの消費とIDプロバイダーの請求額増加を招いた。Cloudflare Turnstileを導入していたにもかかわらず、サインアップ時のボット保護は不十分であることが判明した。

この事態を受け、Nous Researchは無料枠の再開に先立ち、Vercelの最も高度なボット保護ソリューションであるBotID Deep Analysisを導入し、サインアップおよびチャットフロー全体を再構築した。BotIDは目に見えないCAPTCHAとして機能し、ユーザーエクスペリエンスを妨げることなく、人間になりすますボットを正確に識別・検証する。

具体的な導入方法として、認証フローのポータルでは、サインアップとサインインの前後両方でBotIDチェックを実行し、失敗した場合は即座に進行を停止させた。また、チャットUIレイヤーでは、APIスタイルの不正利用を防ぐため、ハートビートメカニズムを実装。チャットクライアントがtRPCを介して定期的にBotIDチェックをトリガーし、成功した検証はバックエンドで短期間キャッシュされる。これにより、推論リクエストは、最近の人間による検証が存在する場合にのみ処理される仕組みを構築した。この多層的なアプローチにより、エントリーポイントと継続的なアプリのインタラクションの両方を保護し、セキュリティとコスト効率を確保した。

この再構築後、プロモーションなしで無料枠を再開したところ、BotIDは数日以内にチャットに侵入しようとする大規模な協調攻撃を検知・軽減した。ピーク時にはチャットアプリへのトラフィックが3,000%増加したが、BotIDがトラフィックを特定してブロックしたため、攻撃者は推論を実行できなくなり、2時間で攻撃は終息した。数千件のサインアップ試行があったにもかかわらず、推論トラフィックとサービスの可用性は安定したままだった。特に興味深いのは、サインインポータルで「人間」とマークされたJA4フィンガープリントが、チャットでは最もブロックされたパターンとして現れたことだ。これは、巧妙な攻撃者が攻撃パターンを調整する能力があることを示しており、BotIDの深い行動分析が表面的な保護を超えた適応防御を提供していることを強調している。

この事例はWebアプリケーションエンジニアにとって非常に重要だ。特に無料サービスやAI APIを提供する際、ボットによる不正利用がいかに深刻な課題となり、それが計算リソースの浪費やIDプロバイダーへの不要なコストにつながるかを明確に示している。従来のCAPTCHAだけでは不十分であり、BotIDのような高度な行動分析に基づくボット保護を認証フローやアプリケーション内部の重要なチェックポイントに多層的に導入することが、サービスの安定稼働とコスト効率を確保する上で不可欠であることを実証している。また、ユーザー体験を損なうことなくセキュリティを強化できる点は、開発・運用における大きなメリットとなる。