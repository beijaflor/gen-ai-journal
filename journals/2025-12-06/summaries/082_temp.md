## 楽しいExtended Thinking

https://cloud.flect.co.jp/entry/2025/11/27/151039

LLMの推論能力をAPI経由で制御し、推論トークン量の変化が複雑な数学問題の回答精度に与える影響を実験を通じて詳細に解説します。

**Content Type**: Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 82/100 | **Annex Potential**: 83/100 | **Overall**: 84/100

**Topics**: [[LLM Reasoning, API Parameter Control, Claude Extended Thinking, Chain of Thought (CoT), LLM Debugging]]

本記事は、LLMの「reasoning（推論）」能力に着目し、特にAPI経由でこの機能をどの程度制御できるかについて探求しています。著者は、LLMが思考の段取りをして段階的に考えるプロセスを重視しており、これは内部的にCoT（Chain of Thought）などの手法が使われていると説明しています。各LLMモデル（OpenAI, Claude, Gemini）のAPIにおいて、ユーザーが推論を指示・制御できる細かさに違いがあることを指摘し、特にOpenAIが推論パラメータの指定がほとんどできないのに対し、ClaudeとGeminiはより詳細な制御が可能であると述べています。

著者は、最も推論制御が細やかなClaudeの「Extended Thinking」機能を用いて実験を実施しました。具体的には、LLMが内部で推論のために使うトークンの上限値である`budget_tokens`パラメータを変更し、その回答と思考過程の変化を観察しました。課題として、√2の無理数性の証明と、(√2)^√2を含む複数の数が有理数か無理数かの判定が与えられました。

実験の結果、`budget_tokens`を1024、2048、8192と増やしていくにつれて、Claudeの思考過程はより詳細になり、特に難解な(√2)^√2の判定において、初期は「不明」であった回答が、予算が増えることで「無理数（超越数）」と明確に正答を導き出すことが示されました。この際、ゲルフォント＝シュナイダーの定理に言及するなど、より高度な数学的知識に基づいた推論が展開されています。

著者はこの実験を通じて、推論トークンの量によってLLMの思考（reasoning）が変化し、複雑な問題に対する回答の質が向上することを実感したと述べています。この知見は、LLMを「魔法の箱」として捉えるだけでなく、その内部メカニズムを具体的に理解することに役立つと強調しています。実務においては、もしLLMが期待通りに動作しない場合に、それが推論部分の失敗によるものなのか、それとも他の要因なのかを切り分けて考えるためのヒントになると、その実践的な価値を提示しています。