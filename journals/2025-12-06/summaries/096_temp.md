## LLMは失敗作であり、新たなAIの冬が到来する

https://taranis.ie/llms-are-a-failure-a-new-ai-winter-is-coming/

**Original Title**: LLMs are a failure. A new AI winter is coming.

著者は、LLMが根本的な限界により幻覚を完全に排除できず、実用的な用途では失敗に終わる可能性が高いため、新たなAIの冬が訪れると主張している。

**Content Type**: 🎭 AI Hype
**Language**: en

**Scores**: Signal:4/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 93/100 | **Overall**: 88/100

**Topics**: [[AIの冬, LLMの限界, 幻覚問題, AIの過大評価, AIコード生成の課題]]

著者は、LLM（大規模言語モデル）が約束されたほどの性能を発揮せず、本質的に失敗であり、新たなAIの冬が到来すると強く主張しています。トランスフォーマーの登場は、記号AIが直面したNP完全性問題やスケーリングの限界を克服し、AI研究の長年の停滞を打ち破る可能性を秘めていました。実際、初期のLLMは驚異的な能力を示し、多くの人々がAIの冬の終焉を期待しました。

しかし、著者はトランスフォーマーには根本的な限界があると指摘します。その動作原理は、常に「最ももっともらしい次のトークン」を生成することにあり、コンテキストや学習データに関わらず出力が生成されるため、幻覚（ハルシネーション）を根本的に排除することはできません。この誤った出力は正しい出力と区別がつかないため、真の専門家でなければ見抜くことが極めて困難です。この問題は、モデルのスケーリングや微調整によっても解決できない、トランスフォーマーの基本的な特性に由来すると述べられています。

この幻覚問題により、LLMの実用的な成功率は60%から95%程度にとどまり、5%から40%は誤った結果を生み出すと著者は主張します。特に大規模モデルは非常に説得力のある誤った出力を生成するため、誤りを識別するには高度な専門知識が不可欠です。企業の生成AIプロジェクトの95%が失敗しているという噂があることも指摘し、ドットコムバブルの過熱との類似性を強調しています。

ウェブアプリケーションエンジニアにとって重要な点として、プログラミング支援やコード生成におけるLLMの利用が挙げられています。著者は、LLMが非プログラマーを「プログラマーになれる」と誤解させがちだが、結果は悲惨であると警告しています。生成されたコードの幻覚を見抜くには依然として真の専門知識が必要であり、もっともらしい誤ったコードは、深刻なバグやセキュリティホールにつながり、維持管理が困難な「恐ろしい負債」となり得ると述べています。人間に直接的または間接的な害を及ぼす可能性のある医療、教育、法執行などの分野では、LLMの失敗率は許容できないと強調しています。

著者は、このAIバブルが近く崩壊し、OpenAIのような企業が大きな打撃を受け、多くのAIスタートアップが消滅すると予測しています。技術自体が完全に消えるわけではないが、「キラーアプリ」と呼ばれる一部のユースケースのみが残り、他は消え去ると見ています。最後に、読者に対し、来るべきAIバブル崩壊へのエクスポージャーを可能な限り解消するよう忠告しています。