## EurostarのAIチャットボットにおける脆弱性：ガードレールを回避する実態と教訓

https://www.pentestpartners.com/security-blog/eurostar-ai-vulnerability-when-a-chatbot-goes-off-the-rails/

**Original Title**: Eurostar AI vulnerability: when a chatbot goes off the rails

特定する：EurostarのAIチャットボットにおけるガードレール回避やXSSなどの4つの脆弱性を分析し、LLM統合アプリでも従来のWebセキュリティの基本が不可欠であることを示す。

**Content Type**: 🔬 Research & Analysis
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 87/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[LLMセキュリティ, プロンプトインジェクション, ガードレール回避, API設計, クロスサイトスクリプティング(XSS)]]

本記事は、Pen Test Partnersの調査チームがEurostarの公式AIチャットボットで発見した4つの主要な脆弱性について、その攻撃手法と具体的な教訓を詳述している。特定された問題は「ガードレールのバイパス」「プロンプトインジェクションによる情報漏洩」「HTMLインジェクション（Self-XSS）」「会話IDの検証不備」の4点だ。著者は、最新のLLMベースのシステムであっても、従来のWebアプリケーション開発における「サーバー側での検証」や「入力のサニタイズ」といった基本原則を軽視することで、深刻なセキュリティリスクが生じると警鐘を鳴らしている。

技術的に最も注目すべきは「ガードレールのバイパス」の手法だ。このチャットボットは、リクエストごとに会話履歴を全配列としてサーバーへ送信する設計になっていた。サーバー側は「最新のメッセージ」に対してのみガードレールチェックを行い、合格すれば署名を付与して処理を継続する。しかし、過去の履歴メッセージに対する署名の照合や整合性の検証が行われていなかったため、攻撃者は履歴配列の古い要素に悪意あるプロンプトを隠し、最新のメッセージを無害な内容（または空文字列）に偽装することで、セキュリティチェックを容易にすり抜けることが可能だった。

このバイパスを起点として、著者はプロンプトインジェクションを実行し、非公開であるはずのシステムプロンプトやモデル名の抽出に成功した。さらに、モデルがHTMLタグを含む回答を生成するように設定されていたにもかかわらず、フロントエンドでの出力時にサニタイズ処理が欠落していたため、任意のJavaScriptを実行可能なSelf-XSSも確認された。また、会話IDやメッセージID（UUID）がサーバー側で厳密に検証されていないことも判明し、他者のセッションへの干渉や保存型XSSへと発展するリスクも示唆されている。

筆者は、AIチャットボットの安全性は「巧妙なプロンプト設計」よりも、従来の堅牢なAPI設計とセキュリティ実装に依存すると結論付けている。エンジニアへの具体的なアドバイスとして、クライアントから送られる「ガードレール通過済み」というステータスを一切信用せず、サーバー側ですべての履歴と署名を厳密に照合すること、モデルの出力をデフォルトでプレーンテキストとして扱い、リッチコンテンツが必要な場合は厳格なホワイトリスト方式でサニタイズすることなど、今すぐ開発フローに取り入れるべき実践的な対策を提示している。