## RAGの「業界特化」戦略（メルカリの成功例に学ぶ）

https://zenn.dev/knowledgesense/articles/dc593ea029356f

メルカリの研究チームが発表した「ドメイン認識型テキスト埋め込み」の手法を基に、RAGにおける専門用語の検索精度を劇的に向上させる戦略を提示する。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 84/100 | **Annex Potential**: 84/100 | **Overall**: 84/100

**Topics**: [[RAG, 埋め込みモデル, ファインチューニング, メルカリ, Matryoshka Representation Learning]]

本記事は、メルカリの研究チームがAAAI 2026で発表した論文を基に、RAG（検索拡張生成）の精度を左右する「埋め込みモデル」を業界や特定のドメインに特化させる重要性と手法を解説している。

著者は、AzureやOpenAIが提供する汎用的な埋め込みモデルでは、日本語の専門用語や業界特有のニュアンスを正しくベクトル化できないという、実務で頻出する課題を指摘する。例えば、一般的な検索では「coach」は「指導者」と解釈されがちだが、メルカリのようなC2Cマーケットプレイスではブランド名の「COACH」を指す可能性が高い。こうした「ドメインの乖離」が検索精度を下げ、結果としてRAGの回答品質を損なう原因となる。

この課題を解決するため、メルカリの事例では「検索クエリと実際に購入された商品タイトル」のペア500万件を学習データとして活用し、既存の日本語埋め込みモデル（ruri-small-v2）をファインチューニングしている。具体的には、効率的な学習を可能にする「Multiple Negatives Ranking (MNR)」や、ベクトルの次元を大幅に圧縮しても精度を維持できる「Matryoshka Representation Learning (MRL)」といった王道かつ強力な手法を組み合わせている。

特筆すべきは、本番環境のレイテンシを考慮し、本来768次元あるベクトルを32次元という極限まで圧縮しながらも、PCA（主成分分析）による圧縮と比較して約2倍の精度を維持している点だ。実際のA/Bテストではユーザーあたりの売上が0.92%向上するなど、ビジネス上の成果も証明されている。

著者は、この手法はRAGそのものの研究ではないものの、検索エンジンとして機能するRAGにとって極めて重要であると主張する。社内用語や業界用語を多く含むデータを扱うエンジニアにとって、汎用モデルの限界を認め、自社データを用いた軽量な特化型モデルを構築することが、少ないコストでシステム性能を飛躍させる鍵になるという実戦的な示唆を与えている。