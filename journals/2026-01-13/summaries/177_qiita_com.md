## Open WebUIの隠れたLLM呼び出し9種：Chat Completion以外で何が動く？（Prompt/API/設定）

https://qiita.com/ntaka329/items/7b05cd44897d9347c149

Open WebUIのソースコードを分析し、チャット応答の裏で実行される9つの「隠れたLLMタスク」のプロンプト構造と制御方法を詳解する。

**Content Type**: Technical Reference
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 89/100 | **Annex Potential**: 87/100 | **Overall**: 88/100

**Topics**: [[Open WebUI, LLM, Ollama, プロンプトエンジニアリング, リソース最適化]]

Open WebUIを単なるチャットインターフェースとして利用するだけでなく、その内部で行われている「隠れたLLM呼び出し」を理解することは、開発者にとってリソース最適化とユーザー体験（UX）のカスタマイズの両面で非常に重要です。本記事は、Open WebUIのソースコードを詳細に分析し、通常のチャット応答（Chat Completion）の裏側で自動的、あるいは操作に応じて実行される9種類の追加LLMタスクを体系的に整理しています。

著者が特定した9つの機能には、チャット完了後に自動実行される「関連質問の生成」「タイトルの自動生成」「タグ付け」といったUX向上機能や、RAG（検索拡張生成）やWeb検索に不可欠な「検索クエリ生成」、さらには複数の回答を統合する「MOA（Multiple Model Aggregation）」、音声対話に最適化された「音声モード」などが含まれます。各機能について、呼び出しのタイミング、対応するAPIエンドポイント、実際にバックエンドで使用されているプロンプトテンプレート、および制御用の環境変数が具体的に示されています。

筆者が強調する最大のポイントは、これら全てのバックグラウンドタスクが「環境変数によって無効化またはカスタマイズ可能である」という点です。例えば、ローカルLLM環境や小規模なインフラでは、デフォルトで有効になっているこれらのタスクが予期せぬ負荷となり、メインのチャット応答を遅延させる要因になり得ます。著者は、`ENABLE_FOLLOW_UP_GENERATION=false`などの設定値を具体的に挙げることで、不要な呼び出しを削減し、実行リソースを最適化する手法を提示しています。

また、プロンプトテンプレート自体が環境変数（例：`FOLLOW_UP_GENERATION_PROMPT_TEMPLATE`）で上書き可能であることも重要な知見です。これにより、日本語環境への最適化や、特定のドメイン（ビジネス、教育、医療など）に特化した補助機能の振る舞いをコードの改修なしに実現できます。

エンジニア視点では、`{{MESSAGES:END:6}}`といったOpen WebUI独自の変数記法や、JSON形式での出力を厳格に維持するためのプロンプトテクニックがソースコードベースで解説されている点が極めて実用的です。Open WebUIをセルフホストし、本番運用や社内基盤としてカスタマイズする際の構成設計において、リファレンスとして非常に価値の高い内容となっています。