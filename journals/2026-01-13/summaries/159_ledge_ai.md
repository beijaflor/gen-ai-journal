## LLMは「同じ質問を2回」入力すると精度が上がる──Google研究者ら、プロンプト反復の効果を短報で報告

https://ledge.ai/articles/prompt_repetition_improves_llm_accuracy

同一のプロンプトを2回繰り返して入力するだけで、LLMの推論精度が向上するというGoogle研究者らの調査結果を報告する。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 81/100 | **Annex Potential**: 81/100 | **Overall**: 84/100

**Topics**: [[Prompt Engineering, Google Research, LLM Accuracy, Inference Optimization, Developer Workflow]]

Googleの研究者らが発表した、LLM（大規模言語モデル）の精度向上に関する極めてシンプルかつ衝撃的な手法「プロンプト反復（Prompt Repetition）」について解説する。この手法は、ユーザーがLLMに対して全く同じ質問や命令を1つの入力コンテキストの中で2回繰り返すというもので、これだけでモデルの回答精度が有意に向上することが短報（Short Report）で示された。

エンジニアが注目すべきは、この手法が「追加の学習」や「複雑なChain of Thought（CoT）の設計」を必要とせず、入力の文字列をコピー＆ペーストするだけで即座に実行可能である点だ。著者は、なぜこのような単純な反復が効果を発揮するのかについて、モデルが特定の指示に対して注意（Attention）を向ける確率が高まるためだと示唆している。従来のプロンプトエンジニアリングでは、情報の重複はトークンの無駄と見なされることが多かったが、本研究はその常識を覆し、あえて「冗長性」を持たせることの有用性を実証した。

ウェブアプリケーション開発の現場において、これは極めて実用的な知見である。例えば、エージェント型のワークフローや自動コード生成において、特定の制約条件（「TypeScriptで記述せよ」「外部ライブラリは使用禁止」など）を2回繰り返して提示することで、LLMの「指示無視」を劇的に減らせる可能性がある。トークン消費量は物理的に増加するものの、推論の再試行（Retry）コストや、出力結果の検証・修正にかかるエンジニアの工数を考慮すれば、十分に投資対効果（ROI）が見合う最適化手法と言える。

筆者は、この現象をLLMの内部的な「重み付け」の強化プロセスとして捉えており、開発者がプロンプトテンプレートを設計する際、重要な制約や核となる問いを意図的に2回記述することが、新たなデファクトスタンダードになる可能性を提示している。精度向上に悩むエンジニアにとって、まず試すべき「最も安価な解決策」としての価値は高い。