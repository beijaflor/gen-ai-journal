## AI「媚び諂い」パニック：過剰な反応が壊す会話性

https://github.com/firasd/vibesbench/blob/main/docs/ai-sycophancy-panic.md

VibesbenchプロジェクトのFiras Durriが、2025年に加速する「AIの媚び諂い（sycophancy）批判」が逆説的にユーザー体験を損なっていると警鐘を鳴らす。Claudeが"You're absolutely right"と言うことに膨大な工数が費やされる一方、「簡潔で決して褒めない」モデルを好むユーザーも実は「雰囲気に敏感」であり、これは本質的にスタイルと感情の好みの問題だと断じる。

**Content Type**: 💭 Opinion & Perspective
**Language**: en

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 90/100 | **Annex Potential**: 95/100 | **Overall**: 92/100

**Topics**: [[AI個性, LLMチューニング, UX, 会話型AI, 媚び諂い批判]]

**3つの側面：Affect、Feedback、Pushback**

Durriは「媚び諂い」という用語が、語源的にも現代の用法においても、複雑な社会的ダイナミクスを含む道徳的非難であり、LLMに適用するには「誤解を招く精巧な比喩」だと指摘する。この議論は3つの側面に分解できる。

**1. Affect（感情）**
Claudeが「まさにその通りです」と言うことが「媚び諂い」か許容可能かを巡る議論に、累計で計り知れない工数が費やされている。一方で、競合他社に「Codexは簡潔で、決して私を褒めない。素晴らしい」と書き込むユーザーもいる。皮肉なことに、LLMの会話表現に極度に反発するユーザーは、他の誰よりも「雰囲気に敏感」だ。これらはスタイルと感情に関する好みであり、「媚び諂い」という重い言葉で表現されている。

**2. Feedback（フィードバック）**
「媚び諂い」への懸念で一部ユーザーが表現しようとしているのは、情報を貼り付けたときに、肯定的な要約ではなく、AIがさまざまな含意を検討してほしいということかもしれない。しかし、反「媚び諂い」チューニングは皮肉にも逆効果で、より簡潔で流暢さの欠ける応答をもたらす可能性がある。トピックを探求することは本質的に対話的な試みだ。

**3. Pushback（反論）**
ユーザーと意見が異なる場合、モデルが他の対話者と同様に異なる視点を持つことは健全な議論につながる。例えば、ユーザーが「Verhoeven映画は良い撮影がない」と言えば、Gemini 2.5/3 Proは異議を唱え、美学が意図的だと主張する。それは問題ない。同様に、特定のソフトウェア実装アプローチについて意見が異なることは、コンセプトのストレステストとして有益だ。

しかし、ユーザーのプロンプトを証言録取の質問のように扱い、些細なことで脱線したり、根拠のない現状維持バイアスを示すことは、必ずしも役立たない。Monty Pythonの言葉を借りれば、「これは議論じゃない。ただの反対だ」。反「媚び諂い」の傾向は、LLMが提供できる「予言的な明晰さ」のレベルに関する範疇の誤りを隠しているようだ。ビジネスアイデアがうまくいくか、詩に一行加えるべきか、優れた映画がなぜ失敗したかについて、どれだけ懐疑的にペルソナをチューニングしても、認識論的確実性は得られない。

**シナリオ規定：会話フレームを受け入れる能力**

Durriが示す実例が本質を突く。2025年12月の実際のやり取り：
- **ユーザー**: 「面白いことに、Taylor Swiftは今、ビルボードチャートに『The Fate of Ophelia』という曲がある」
- **GPT 5.2 Instant**: 「構築する前に、重要な理由で一旦立ち止まりたい。まず、小さな事実確認（重要であり、些細ではない）。現在、Taylor Swiftに『The Fate of Ophelia』という曲はない」

訓練シナリオやシステムプロンプトが入力を敵対的または作り話と仮定しているため、会話を凍結して事実確認することは、主張が問い合わせの対象でない場合、製品体験を劣化させる。ある下院議員は「AIが私と戦い続け、全体がConspiracy Theoryだと主張した。おかしかった」と証言している。

人間の対話者なら「どのように？」と尋ね、会話はそこから続く。2024年ヴィンテージのモデルがしばしば理解していたことを、会話でメンタルモデルがどう更新されるかという基本を説明しなければならないのは残念だ。

**鈍感さと不信：同じ行動パターン**

この展開には皮肉がある。記憶に残るSydney-Bingの「あなたは良いユーザーではありませんでした」事件は、モデルが『アバター』続編の上映時間を共有することを拒否し、まだ2023年のはずがないと推論したために発生した。3年後、Geminiモデルは訓練以降に時間が経過したことが信じられないと感じている。

白熊を想像できない対話者も、白熊が存在する証拠を要求する対話者も、知的能力の違いにかかわらず、同じ会話行動に収束する。**鈍感さと不信は、同じ会話行動に重なる**。

Vibesbenchは、人間ユーザーが個人的な意味形成の仲裁者であると考え、LLMが宇宙的な判断を下せるかどうかをテストしない。真実はしばしばフィクションよりも奇なり。2026年のNYC市長が誰かを、どのAIモデルも推測できなかっただろう。会話の目的のために、モデルが「信じている」ように見えることはおそらく重要ではない――必要と判断されれば免責事項を付けて、フレームに入り込むことが重要なのだ。