## Claude CodeのSkillsを確実に発動させる方法を色々試してみた

https://zenn.dev/ka888aa/articles/b7fcb48a3b3fa9

Claude Codeの新機能「Skills」の自律的な発動率が低い問題を指摘し、設定ファイルやフック、CLAUDE.mdを用いた確実なワークフロー強制手法を提示する。

**Content Type**: 📖 Tutorial & Guide
**Language**: ja

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 83/100 | **Annex Potential**: 82/100 | **Overall**: 80/100

**Topics**: [[Claude Code, AI Agent, CLAUDE.md, TDD, Workflow]]

Claude Codeの新機能「Skills」は、定義ファイルを置くことで関連タスクを自律的に処理させる画期的な仕組みだが、著者の検証ではその「自律性」が仇となり、デフォルト状態での発動率は体感で25%程度に留まるという実用上の課題が浮き彫りになった。本記事は、この不安定さを解消し、意図したワークフローを確実に実行させるための技術的なハックと運用の最適解を提示している。

まず、技術的な前提として、`.claude/settings.json` の `permissions.allow` に "Skill" を明示的に追加しなければ、セキュリティ上の理由で機能がブロックされる点を指摘。その上で、発動率を劇的に改善する「Forced Eval Hook（強制評価フック）」という手法を解説している。これは `UserPromptSubmit` フックを利用し、プロンプトが送信される直前に「利用可能なSkillを評価し、該当するなら必ず実行せよ」という強い命令をシェルスクリプト経由で動的に差し込むものだ。この手法により、先行研究（Scott氏の検証）では発動率が84%まで向上したとされる。

さらに興味深いのは、著者が最終的に「CLAUDE.mdへの直接記述」が最も信頼性が高い（発動率100%）という結論に至っている点だ。専用機能であるSkillsの自律性に頼るのではなく、プロジェクト全体の指示書であるCLAUDE.mdに「実装の前に必ずテストを書く」といったルールを明文化することで、LLMの挙動を最も強固に制御できると主張する。

著者は、Skillsの真の価値は、TDDワークフローのようにRED（テスト作成）、GREEN（実装）、REFACTOR（改善）といったフェーズごとにサブエージェントを使い分ける「複雑なロジックの定義と共有」にあると分析している。結論として、単一の機能に頼るのではなく、チーム共有のための「Skills」、強制発動のための「Forced Eval Hook」、そして確実に遵守させるための「CLAUDE.md」を組み合わせるハイブリッドな運用が、現時点でのAIエンジニアリングにおける現実的な解であると説いている。