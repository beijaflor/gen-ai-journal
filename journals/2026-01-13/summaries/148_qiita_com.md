## 【狂気の実証実験2】GPTsに電気ショック権限を付与してみた

https://qiita.com/motoya0118/items/bd5266a987d082caea16

AIエージェントに物理的な「罰」を与える権限を委ねることで、既存の管理ツールでは改善できなかった生活習慣を強制的に是正する仕組みを構築し、その実効性を検証する。

**Content Type**: 📖 Tutorial & Guide
**Language**: ja

**Scores**: Signal:5/5 | Depth:3/5 | Unique:5/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 76/100 | **Annex Potential**: 82/100 | **Overall**: 80/100

**Topics**: [[ChatGPT, GPTs, Pavlok, API連携, 行動変容]]

生活習慣の乱れを自力で改善できないエンジニアが、物理的な電気刺激デバイス「Pavlok」とChatGPT（GPTs）をAPI連携させ、AIがユーザーに物理的な「罰」を下す仕組みを構築した実験レポートである。

著者は、リマインダーやToDo管理ツールが機能しない根本的な理由は「守らなくても痛くない」からだと断じ、AIエージェントに「物理的コスト」を執行させる権限を付与した。技術構成としては、Pavlokが提供するAPIを利用し、GPTsのActions機能から「バイブレーション（vibe）」「ビープ音（beep）」「電気刺激（zap）」を呼び出す仕組みだ。プロンプトにはアニメ『PSYCHO-PASS』の「シビュラシステム」のような冷徹なコーチング人格を定義し、ユーザーが良い習慣（早起き、ジム、エンジニアリング学習など）を報告すれば褒め、悪い習慣（パチンコ、深夜のラーメン、スマホゲームなど）を報告すれば、その深刻度に応じて100段階の強度で電気ショックが実行されるよう設計されている。

実装と運用を通じて得られた知見として、著者は「物理刺激権限を持つAIの存在が人の行動を大きく変えうる」と強調している。特に、GPTsの仕様上、外部API呼び出しのたびにユーザーの「承認」が必要となる点が、皮肉にも「自らの罪を認め、罰を自ら確定させる」という強い反省を促すUXとして機能している点が興味深い。一方で、GPTsには定期実行機能がないため、能動的な「監視者」としては機能せず、あくまでユーザーが自発的に罪を報告する「懺悔部屋」としての活用に留まるという技術的な限界も指摘されている。

商用サービスでは倫理的に実装困難な「物理的制裁による行動変容」を、OSS的発想とパーソナルな開発環境で試行した本作は、AIエージェントの権限設計における新しい（かつ過激な）視点を提供している。単なるジョーク企画に留まらず、API連携によるAIの物理世界への干渉が、人間の心理や習慣にどのような影響を及ぼすかを示す、示唆に富んだ検証内容となっている。