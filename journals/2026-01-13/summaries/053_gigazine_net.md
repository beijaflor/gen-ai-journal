## 日本語特化の小型AIモデル「LFM2.5-1.2B-JP」を含むオンデバイス重視のオープンモデル「LFM2.5」シリーズが登場

https://gigazine.net/news/20260107-lfm2-5-on-device-ai/

Liquid AIが、非トランスフォーマー構造を採用したオンデバイス動作特化の軽量AIモデル「LFM2.5」シリーズを公開し、日本語特化モデルを含む5種類をオープンモデルとして提供開始した。

**Content Type**: 📰 News & Announcements
**Language**: ja

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 85/100 | **Annex Potential**: 81/100 | **Overall**: 80/100

**Topics**: [[LFM2.5, オンデバイスAI, Liquid AI, 日本語LLM, エッジコンピューティング]]

MIT発のスタートアップLiquid AIが、独自の「Liquid Foundation Model（LFM）」アーキテクチャに基づく最新シリーズ「LFM2.5」をリリースした。最大の特徴は、一般的なTransformerベースではなく、動的なシステム理論を応用した独自の構造を持つ点にある。今回公開されたのは、1.2B（12億パラメータ）のベースモデルおよび指示追従モデル、視覚モデル（VL）、音声モデル、そして特筆すべきことに、英語以外で唯一の言語特化モデルとして「LFM2.5-1.2B-JP（日本語特化モデル）」がラインナップされている。

ウェブアプリケーションエンジニアにとっての核心的な価値は、クラウドAPIに依存しない「真のローカル推論」が現実的なパフォーマンスで手に入る点だ。LFM2.5-1.2B-Instructは、最新のスマートフォン（Galaxy S25 Ultra）で毎秒71トークン、AMD Ryzen AI Max+搭載PCでは毎秒239トークンという圧倒的な出力速度を記録している。これは、ユーザーインターフェースにおける「待ち時間」をほぼゼロにし、プライバシーとコスト効率を両立したオンデバイスAIエージェントの実装が可能であることを示唆している。

著者は、このモデルが同規模のオープンモデル（Llama 3.2 1BやQwen3-1.7Bなど）と比較しても高いベンチマークスコアを記録していることを強調している。特に日本語特化モデルの存在は、日本市場向けのアプリケーション開発において、軽量かつ高性能な日本語処理エンジンをデバイス側に配置できる大きなアドバンテージとなるだろう。

Liquid AIのCEOラミン・ハサニ氏はCES 2026にて、2026年中に「LFM3」を公開する計画も明らかにした。次世代モデルでは、リアルタイムの音声・画像認識を統合した高度なエージェント動作の最適化が進む見通しだ。開発者はHugging Faceを通じてこれらのモデルを今すぐ試用でき、エッジ側での推論を活用した新しいUXのプロトタイピングを開始できる段階にある。クラウドLLMの呼び出しコストやレイテンシに課題を感じているエンジニアにとって、LFM2.5は無視できない選択肢となるはずだ。