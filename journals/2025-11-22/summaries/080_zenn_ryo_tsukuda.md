## ローカルで稼働するOpen Notebook を実際に使ってみた

https://zenn.dev/ryo_tsukuda/articles/d1ae2b44a45709

筆者は、機密情報を安全に扱うためにローカルで動作するNotebookLMの代替となる「Open Notebook」を実際に導入・評価し、その機能と課題を報告している。

**Content Type**: ⚙️ Tools
**Language**: ja

**Scores**: Signal:4/5 | Depth:3/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 71/100 | **Annex Potential**: 70/100 | **Overall**: 72/100

**Topics**: [[Open Notebook, ローカルLLM, 機密情報, RAG, Docker]]

著者は、機密性の高い文書を扱う際にクラウド型LLMサービス「NotebookLM」が抱えるセキュリティ上の課題に着目し、その解決策としてローカル環境で動作する「Open Notebook」の導入と活用について詳細に報告している。Webアプリケーションエンジニアが自社の機密情報を安全に扱うための実践的なアプローチとして、このツールを評価した内容が示されている。

導入手順として、まずDockerを用いた環境構築について具体的に解説されている。提供されている`docker-compose.yml`ファイルを編集し、OpenAIのAPIキーを設定するだけで簡単にWeb UIとAPIサーバーを起動できることを示している。モデル設定では、`gpt-4o-mini`と`text-embedding-3-small`を組み合わせて利用する基本的な構成が紹介されている。

次に、個人識別情報（PII）を含む社員情報や企業の新規事業戦略メモといった機密性の高いサンプルデータを「ソース」としてOpen Notebookに追加し、その機能検証を行っている。チャット機能では、追加したソースに基づいて質問応答が可能であり、特に「Ask and Search」タブでは、複数のソースブックにまたがって検索し、引用を含む要約を生成できる点が評価されている。これにより、大量の機密文書から必要な情報を迅速に抽出できる可能性が示唆されている。

しかし、著者はOpen Notebookの限界と課題についても率直に指摘している。ローカルで動作するとはいえ、デフォルトではOpenAIなどの外部APIに情報が送信されるため、真に高いセキュリティを求める場合は自社サーバーへの展開や完全にローカルで完結するLLM（Ollamaなど）との連携が必要であると述べている。また、「Insights」機能の精度がまだ低い点や、1ファイルあたりのアップロード容量制限（50MB）といった実用上の課題も挙げられている。

結論として、Open Notebookは機密情報を扱う開発現場におけるRAG（Retrieval Augmented Generation）のローカル検証ツールとして有用である一方、企業での本格導入にはさらなるセキュリティ対策と機能改善が求められるというのが筆者の見解だ。ローカルLLMとの連携の可能性も示唆されており、今後の発展に期待が寄せられている。