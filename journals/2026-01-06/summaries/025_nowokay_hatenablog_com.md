## 規約ベースのフレームワークはAI処理に不利だと思う

https://nowokay.hatenablog.com/entry/2025/12/28/045145

主張する、AI時代においては規約による暗黙的な定義よりもアノテーションなどの明示的な記述の方が、LLMの推論効率とコストの両面で有利であることを。

**Content Type**: 💭 Opinion & Commentary
**Language**: ja

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:3/5 | Anti-Hype:4/5
**Main Journal**: 86/100 | **Annex Potential**: 87/100 | **Overall**: 84/100

**Topics**: [[Rails, LLMアテンション, 設定より規約, AI駆動開発, 経済的効率]]

筆者のきしだ氏は、Ruby on Railsに代表される「設定より規約（Convention over Configuration: CoC）」を採用したフレームワークが、生成AI（LLM）によるコード理解や生成において不利に働く可能性を指摘している。

主な理由はLLMの「アテンション（注意）」の仕組みにある。CoCでは、クラス名とテーブル名の紐付けなどが暗黙的なルールに基づいているため、LLMがコードを読む際、注目すべき情報が広範囲に分散してしまう。一方、アノテーションベースのフレームワークのように、コード内にメタデータが明示的に記述されていれば、LLMは必要な情報の近くに注意を集中させることができ、処理の精度と効率が向上する。

また、この問題は「経済的な不利」にも直結すると筆者は主張する。規約ベースのコードを正確に扱うには、Claude 3 Opusのような高性能（かつ高コスト）なモデルが必要になるが、明示的なコードであれば、より小規模で安価なモデルでも十分に処理できる可能性があるからだ。開発組織がコスト効率を重視してオープンウェイトモデルなどの活用を進める際、フレームワークの設計思想が「AIにとっての扱いやすさ」に与える影響は無視できないものとなる。

具体例として、Railsのモデルクラスを挙げている。Railsではフィールド情報がクラス内に記述されず、マイグレーションファイルなどの別箇所に置かれることが多い。この情報の地理的な乖離が、LLMのアテンションを弱める要因となる。対照的に、アノテーションを用いたJavaなどのアプローチは、その場に情報を「ベタ書き」するのに近く、AIにとってはコンテキストを把握しやすい。

筆者は「設定より規約」がかつて解決しようとした問題（大量の設定コードの削減）は、現代のアノテーションベースの仕組みやAIによる支援があれば、もはや大きな課題ではないと示唆している。むしろ、AIがコードを読み書きする現代においては、人間にとっての「記述の短さ」よりも、AIにとっての「情報の明示性」が開発速度を左右する指標になりつつある。AIに「忖度」させるための計算資源を消費するよりも、AIが理解しやすい形式で記述する方が合理的であるという、AI駆動開発時代における設計指針の転換を促す内容となっている。