## LLMの「内部表現」を可視化する：Gemma Scope 2を用いたアニメ・漫画領域での安全性メカニズム検証

https://note.com/cyberagent_ai/n/n111eaa3b772c

疎自己符号化器（SAE）を用いてLLMの内部表現を解きほぐし、アニメ・漫画コンテンツが過剰拒絶される原因が特定の固有名詞の汚染ではなく、カテゴリ認識に伴う安全判定閾値の変動にあることを実証する。

**Content Type**: 🔬 Research & Analysis
**Language**: ja

**Scores**: Signal:5/5 | Depth:5/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 92/100 | **Annex Potential**: 88/100 | **Overall**: 96/100

**Topics**: [[Gemma Scope 2, Sparse Autoencoders (SAE), AI Interpretability, AI Safety, Over-refusal]]

大規模言語モデル（LLM）が、本来クリーンなはずのアニメや漫画の固有名詞に対して「安全性の問題」として回答を拒否する「過剰拒絶（Over-refusal）」の問題に対し、サイバーエージェントのエンジニアが最新の解釈可能性ツールを用いてその深層心理を解剖した。

筆者は、2024年12月に公開された「Gemma Scope 2」を活用し、LLMの内部表現を人間が理解可能な「概念（特徴量）」に分解する疎自己符号化器（SAE）を用いて検証を行った。当初の仮説は「ネット上の膨大な二次創作データにより、固有名詞が直接的にセンシティブな概念と結びついている」というものだったが、実験結果はこの仮説を明確に否定した。Gemma 3 4Bの内部では、有名な版権キャラクター名はそれ自体では性的な特徴量を全く刺激しておらず、むしろ一般名詞（男性、女性など）よりも「安全」と評価されていた。

真の原因として浮上したのは「概念的な隣接」による判定閾値のシフトである。実験②のSteering（概念操作）において、「アニメ・漫画」を司る特徴量を意図的に抑制したところ、境界線上の単語（メイドなど）に対する安全判定の確信度が劇的に向上した。つまり、LLM内部で「アニメ・漫画」というカテゴリが活性化するだけで、安全フィルターの解像度が低下し、「念のため拒絶する」という過剰反応を引き起こしている。

さらに、AIが自動生成した特徴量ラベル（Auto-Interp）の誤りについても言及しており、表面的なラベルに惑わされず生の活性化サンプルを人間が検証することの重要性を説いている。本記事は、ブラックボックス化しがちなAIの「拒絶理由」を可視化することで、より公平で高精度なガードレールを構築するための具体的な技術的視座を提供している。特定の固有名詞を避けるといった表面的なプロンプトエンジニアリングではなく、モデル内部のカテゴリカルなバイアスを理解し、物理的に引き離すアプローチが重要であると結論付けている。