## AIエージェントのための「コンテキスト・エンジニアリング」スキル集

https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering

**Original Title**: Agent-Skills-for-Context-Engineering

AIエージェントのコンテキスト窓を最適化し、性能低下を防ぐための「コンテキスト・エンジニアリング」の手法と、Claude Code等で即利用可能なプラグイン群を公開する。

**Content Type**: ⚙️ Tools
**Language**: en

**Scores**: Signal:5/5 | Depth:5/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 94/100 | **Annex Potential**: 90/100 | **Overall**: 92/100

**Topics**: [[Context Engineering, AI Agents, Claude Code, Multi-agent Systems, LLM Memory]]

エージェント開発において、単なるプロンプト調整（プロンプト・エンジニアリング）を超えた、トークン管理の体系的アプローチを提案するリポジトリである。著者は、LLMの限られた「注意（Attention）」の予算を最適化し、必要な情報のみをモデルに提供する規律を「コンテキスト・エンジニアリング」と定義している。

なぜこれが重要なのか。筆者によれば、コンテキスト長が増大するにつれ、LLMは「Lost-in-the-middle（情報の埋没）」や注意力の欠如といった特有の性能劣化パターンを示すからだ。本リポジトリは、この課題を解決するために「高シグナルなトークン」のみを選択・構築するための具体的な「スキル（手順書・ツール）」を整理している。

内容は多岐にわたり、コンテキスト劣化の回避策、セッションの圧縮、マルチエージェントの設計パターン、さらには「LLM-as-a-Judge」を用いた高度な評価手法まで網羅されている。特に、Claude Codeのプラグインマーケットプレイスとして機能するように設計されており、コマンド一つで環境に導入できる実用性が極めて高い。

技術的な特筆点として、エージェントが必要な時にだけ詳細な指示を読み込む「Progressive Disclosure（段階的な情報開示）」という設計思想が挙げられる。これにより、起動時のトークン消費を抑えつつ、複雑なタスクに対応できる構造を実現している。実装例として、創業者向けの「デジタル・ブレイン」システムや、X（旧Twitter）の投稿から電子書籍を生成するマルチエージェントシステムなど、本番環境を見据えたユースケースが提供されている。

Webアプリケーションエンジニアにとって、CursorやClaude CodeといったAIコーディングツールの裏側にあるコンテキスト管理の仕組みを理解し、自作エージェントの精度を劇的に向上させるためのバイブルとなり得るリソースである。