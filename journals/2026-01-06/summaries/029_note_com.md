## AIエージェントのためのコンテキストエンジニアリング：Manus構築から得た教訓

https://note.com/manus_ai/n/n3ceacf089164

独自のモデル訓練を避け、最先端LLMの文脈内学習能力を最大限に引き出すための実践的な設計指針を提示する。

**Content Type**: 🛠️ Technical Reference
**Language**: ja

**Scores**: Signal:5/5 | Depth:5/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 94/100 | **Annex Potential**: 91/100 | **Overall**: 92/100

**Topics**: [[AI Agents, Context Engineering, KV Cache, Memory Systems, Prompt Engineering]]

Manus AIの最高科学責任者（CSO）であるPeak氏が、次世代AIエージェント「Manus」の開発プロセスで得た、モデルの推論能力を最大限に引き出すための「コンテキストエンジニアリング」の極意を解説している。著者は、独自の基盤モデルをファインチューニングする従来のアプローチは、モデル自体の進化スピードに追い越されるリスク（Pre-PMFでの致命的な遅れ）があるとし、既存の最先端モデルの文脈内学習（In-context learning）能力を前提とした設計に注力する戦略的転換の重要性を説いている。

技術的側面において、著者が最も重視するのは「KVキャッシュ」の最適化だ。エージェントはツール実行と観測を繰り返す一連のループの中で、入出力トークン比が100:1に達することもあり、入力処理の効率がコストとレイテンシに直結する。プロンプトの接頭辞を固定し、コンテキストを追記専用（Append-only）に保つことで、キャッシュヒット率を最大化する設計が実戦では不可欠となる。また、ツールの動的な追加・削除はキャッシュを破壊しハルシネーションを誘発するため、状態機械を用いて特定のツールを「マスク」する手法が推奨されている。

また、コンテキストウィンドウの限界に対しては、ファイルシステムを「永続的な外部メモリ」として定義し、情報を完全に削除するのではなくURL等のポインタを残すことで復元可能性を担保する戦略を採用している。特に注目すべきは、AIに`todo.md`を作成・更新させることで目標を「暗唱」させ、長大なステップにおいてもアテンション（注意）を逸らさない自己制御技術だ。これは、特別なアーキテクチャ変更なしに自然言語のみで精度を維持する巧妙な手法である。

著者は、これらの一見泥臭い試行錯誤を「Stochastic Graduate Descent（確率的大学院生降下法）」とユーモアを交えて呼び、失敗の記録をあえてコンテキストに残すことでモデルの自己修正能力を高めるなど、ベンチマークスコア以上に「実戦での堅牢性」を追求する姿勢を示している。AIエージェントを構築するエンジニアにとって、モデルを海底に固定された柱ではなく、進化の波に乗る「船」として設計するための極めて具体的な知見が凝縮されている。