## Brainf*ck：AGI（汎用人工知能）を測る究極のテスト

https://teodordyakov.github.io/brainfuck-agi/

**Original Title**: Brainf*ck: The Ultimate AGI Test

Brainf*ckを、データの希少性と論理的推論の必要性からLLMの真の知能を測る究極のベンチマークとして定義する。

**Content Type**: 💭 Opinion & Commentary
**Language**: en

**Scores**: Signal:4/5 | Depth:3/5 | Unique:5/5 | Practical:2/5 | Anti-Hype:4/5
**Main Journal**: 76/100 | **Annex Potential**: 79/100 | **Overall**: 72/100

**Topics**: [[Brainf*ck, AGI, LLMベンチマーク, 論理的推論, データ希少性]]

筆者のTeodor Dyakov氏は、極小の命令セットしか持たない難解プログラミング言語「Brainf*ck」こそが、大規模言語モデル（LLM）が真の汎用人工知能（AGI）に到達したかを測る究極の試金石であると主張している。現在のLLMはJavaScriptなどの膨大な学習データに依存し、パターンの模倣によってコードを生成しているに過ぎないが、Brainf*ckはこの「模倣」を無効化するという。

筆者が挙げる第一の理由は「データの希少性」だ。ネット上に存在するBrainf*ckの有効なコード量は、主要言語に比べれば統計的な誤差レベルであり、LLMは模倣に頼ることができない。そのため、モデルは構文を暗記するのではなく、言語の背後にある根本的な論理を理解し、推論する必要がある。

第二に、Brainf*ckが「アンチ・リテレート・プログラミング（非可読プログラミング）」である点だ。コメントや意味のある変数名、構造が一切排除されたこの言語では、既存のコードを参照することさえ学習の助けにならない。成功には、言語の基本ルールに基づいた高度な抽象化と、厳密なセマンティクスのメンタルモデルを自ら構築する能力が不可欠となる。

第三に、LLMの動作原理そのものを突く「繰り返しの問題」がある。Gemini 3などの最新モデルでも、Brainf*ckの生成を命じると特定の文字を無限に繰り返すループに陥ることが多い。これは、最小限の構造が繰り返される言語特性により、LLMの次トークン予測が自己完結的な予言として機能してしまう弱点を示している。

Webエンジニアにとって、この考察はLLMの真の限界を理解する上で重要だ。コピペ可能なコードが枯渇した環境で、モデルがいかに論理的な飛躍を成し遂げられるか。Brainf*ckでのコーディング能力は、LLMが単なる「確率的なオウム」を超え、真の推論能力を備えたAGIへと進化したかを確認するための、最も純粋な指標になり得ると筆者は結論づけている。