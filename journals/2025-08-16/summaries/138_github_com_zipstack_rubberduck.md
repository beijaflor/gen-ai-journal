## GitHub - Zipstack/rubberduck: LLM caching proxy server that emulates popular LLMs with the ability to simulate failures

https://github.com/Zipstack/rubberduck

Rubberduckは、LLMアプリケーションの開発とテストを効率化するため、主要なLLMプロバイダーをエミュレートし、キャッシュ、障害シミュレーション、レート制限などの高度な機能を提供するローカルプロキシサーバーを提供します。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:5/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 90/100 | **Overall**: 92/100

**Topics**: [[LLM開発, プロキシサーバー, テスト自動化, 障害シミュレーション, コスト最適化]]

Rubberduckは、LLM（大規模言語モデル）を活用するアプリケーション開発における「テストの複雑さ」と「実行コスト」という課題を解決する強力なローカルプロキシサーバーです。Webアプリケーションエンジニアは、OpenAI、Anthropic、Azure OpenAIといった主要なLLMプロバイダーの振る舞いを、実際のAPI呼び出しなしにローカルで忠実にエミュレートできます。

このツールの最大の強みは、その高度なテスト機能にあります。ネットワークのタイムアウト、APIエラー（429/500/400）、レート制限といった現実世界で起こりうる障害シナリオを詳細にシミュレートできるため、開発中のLLMアプリケーションが予期せぬ挙動にどう対応するかを事前に検証し、プロダクション環境での信頼性と堅牢性を飛躍的に高めることが可能です。

また、インテリジェントなキャッシュ機能は、同一リクエストに対するAPI呼び出しを削減し、開発時の応答速度を向上させるだけでなく、運用コストの削減にも直接的に貢献します。直感的なWebインターフェースを通じて、リクエストログのリアルタイム監視、プロキシの管理、トークン使用量やコストの追跡まで一元的に行えるため、開発ワークフローが大幅に効率化されます。

このツールは、継続的インテグレーション/デリバリー（CI/CD）パイプラインにLLMテストを組み込みたい企業や、AIエージェントの複雑な挙動を再現性高く検証したい開発者にとって不可欠なソリューションとなり、実際のLLMプロバイダーへの依存を減らし、よりアジャイルでコスト効率の良い開発・テストサイクルを実現します。