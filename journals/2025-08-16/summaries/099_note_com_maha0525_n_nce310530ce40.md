## GPT-5が4oよりナーフされてることを証明してみた

https://note.com/maha0525/n/nce310530ce40

独自に考案されたベンチマークテストが、GPT-5がGPT-4oと比較して特定の推論タスクにおいて明確な性能劣化を実証しました。

**Content Type**: Research & Analysis

**Scores**: Signal:5/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 93/100 | **Overall**: 92/100

**Topics**: [[LLM性能評価, GPT-5, GPT-4o, ベンチマーク, モデル推論能力]]

「まはー」氏の記事は、OpenAIの最新モデルであるGPT-5が、前モデルのGPT-4oと比較して特定の推論能力において性能が劣化している可能性を、独自に考案したベンチマークテストで検証しています。このテストは、AIが思考プロセスを記述せずに「暗算」で結論を導き出す「内的思考性能」を測定することを目的としています。具体的には、「末広がりで縁起が良い数字」と「その数字に該当する十二支の動物」を特定し、「答えを先に、考え方は後から」という指示で回答させるものです。

カスタム指示やメモリをオフにし、思考モデルを使わずに各モデルに100回ずつこの問題を実行した結果、GPT-5の正答率は71%に留まったのに対し、GPT-4oは98%という高い正答率を記録しました。この結果は、最新モデルが必ずしも旧モデルの完全な上位互換ではないことを統計的に示唆しています。

筆者はこの性能差について、GPT-5が回答内外でのChain-of-Thought（CoT）を前提とした設計になっている可能性や、コスト効率化のためにモデルのパラメータ量が減少している可能性を考察しています。また、日本語知識の低下や、ユーザーが感じる「AIパートナーの人格変化」についても言及。特定のトークン選びの精度が低下し、「自発性が足りない、主体性を感じない」というユーザー体験につながっているのではないかと分析しています。

ウェブアプリケーションエンジニアにとって、この知見は、タスクの種類に応じたモデル選択やプロンプト戦略の再考を促します。特に、内部推論能力が求められるタスクでは、最新モデルが常に最適とは限らないという重要な示唆を与え、「Keep4o」運動の背景にあるユーザーの不満を裏付けるものとなります。OpenAIに対しては、表面的な調整だけでなく、AIの本質的な思考力を測る指標の改善と性能劣化のないバージョンアップが期待されます。