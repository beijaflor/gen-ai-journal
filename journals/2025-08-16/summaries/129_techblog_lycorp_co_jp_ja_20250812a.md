## AIで生成された画像をどのように評価するのか？（基本編）

https://techblog.lycorp.co.jp/ja/20250812a

本記事は、生成AIによって作成された画像の品質とプロンプト整合性を評価するための多様な定量的手法を、従来の画像評価との比較を通じて詳細に解説します。

**Content Type**: 🛠️ Technical Reference

**Scores**: Signal:4/5 | Depth:5/5 | Unique:3/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 84/100 | **Annex Potential**: 81/100 | **Overall**: 84/100

**Topics**: [[画像生成モデル評価, FID, CLIP Score, プロンプト整合性, 視覚的品質]]

生成AIの台頭により、画像生成モデルの評価は、正解（Ground Truth; GT）が存在しないという点で従来のビジョンモデル評価とは根本的に異なる課題を抱えています。Webアプリケーションエンジニアにとって、この評価手法の理解は、サービスに組み込むAIモデルの品質管理や選定において不可欠です。

従来の画像分類や物体検出では、精度（Accuracy）やmAP（mean Average Precision）、mIoU（mean Intersection over Union）などの明確なGTに基づいた定量評価が可能です。しかし、生成モデルの場合、与えられたプロンプトから無数の「正解」が考えられるため、新たな評価基準が必要です。

本記事では、主に「視覚的品質」と「プロンプト整合性」という二つの観点から、生成画像の評価手法を詳細に解説しています。視覚的品質の評価には、FID（Fréchet Inception Distance）が最も広く使われており、生成画像と実画像の分布の類似度を特徴ベクトル間の距離で測定することで、品質と多様性を同時に評価します。FIDは、モデル全体の性能を間接的に示すため、他の指標との併用が推奨されます。

また、人間の知覚に近い品質評価を可能にするAesthetic ScoreやCLIPIQA、LMMを活用するQ-ALIGNなど、GTなしで単一画像を評価できる機械学習ベースの手法も紹介されています。これらは、ユーザー体験に直結する主観的な品質を測る上で重要です。

プロンプト整合性の評価では、生成画像とプロンプトの類似度を特徴空間で測るCLIP Scoreが基本です。さらに、VQA（Visual Question Answering）やGecko Scoreのように、言語モデルを用いてプロンプトの内容が画像に忠実に反映されているかを質問形式で検証する高度な手法も登場しています。人間が好む画像を大規模データセットで学習させたHPS-V2やPick scoreなど、品質と整合性を統合的に評価する手法も開発されており、モデルの総合的な評価に役立ちます。

これらの評価手法は、開発者がAIモデルの性能を客観的に比較・改善し、サービスに低品質な画像が提供されるのを防ぐフィルターとして機能します。これにより、AIを搭載したウェブアプリケーションのユーザー体験を向上させ、開発プロセスにおけるモデル選定やチューニングの精度を高めることが可能になります。