## GPT-5: Overdue, overhyped and underwhelming. And that’s not the worst of it.

https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming

ゲイリー・マーカスは、GPT-5の期待外れの登場が、大規模言語モデルの根深い限界を露呈させ、純粋なスケールアップ戦略ではAGIに到達しないことを断言する。

**Content Type**: 🎭 AI Hype

**Scores**: Signal:4/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 91/100 | **Annex Potential**: 93/100 | **Overall**: 88/100

**Topics**: [[LLM性能評価, AIの限界, 大規模言語モデル, AIの過剰な宣伝, AGIへの道のり]]

Gary Marcusは、OpenAIのGPT-5が、サム・アルトマンによる過剰な宣伝とは裏腹に期待外れのデビューを飾ったと指摘します。リリース後すぐに、ユーザーは従来のモデルと同様の誤り、幻覚、ベンチマークでの性能不足を報告し、OpenAIの技術的優位性や信頼性が大きく損なわれました。この記事は、この現象を大規模言語モデル（LLM）の根本的な限界、特に推論能力、一般化能力（分布シフトへの対応）、そして明示的な世界モデルの欠如に起因するものと分析しています。 Marcusは、アリゾナ州立大学の新たな研究が、LLMが学習データ範囲を超えた知識の一般化に失敗するという彼の長年の主張を裏付けるものだと強調します。これは、純粋なスケールアップ戦略だけでは汎用人工知能（AGI）には到達できず、明示的な世界モデルを持つニューロシンボリックAIのような異なるアプローチが不可欠であるという決定的な証拠です。

Webアプリケーションエンジニアにとって、この洞察は、AIツール選定やシステム設計において非常に重要です。GPT-5のような最新モデルであっても、基本的な推論や複雑な問題解決において予期せぬエラーや不正確な出力を生む可能性があることを認識すべきです。市場の過剰な宣伝に惑わされず、LLMの現実的な能力と限界を理解することは、信頼性の高いAI統合を計画し、開発リソースを効果的に配分するために不可欠です。特に、コード生成や複雑なロジックを必要とするタスクにおいて、LLMの出力に過度に依存することはリスクを伴います。本質的な問題が解決されていない限り、単なるモデルの規模拡大だけでは、知的な壁を乗り越えることはできないという筆者の警鐘は、現実的な開発アプローチを促します。