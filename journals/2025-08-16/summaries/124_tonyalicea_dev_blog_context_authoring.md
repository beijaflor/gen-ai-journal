## It's Not Context Engineering, It's Context Authoring

https://tonyalicea.dev/blog/context-authoring/

LLMとの対話における「プロンプトエンジニアリング」という概念を、「コンテキストオーサリング」として再定義し、より適切なメンタルモデルを提唱します。

**Content Type**: Opinion & Commentary

**Scores**: Signal:4/5 | Depth:3/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:5/5
**Main Journal**: 80/100 | **Annex Potential**: 81/100 | **Overall**: 80/100

**Topics**: [[LLM Interaction, Prompt Engineering, Mental Models, Communication Design, Generative AI]]

「プロンプトエンジニアリング」という言葉は、LLMとの効果的な対話において誤解を招く可能性がある、と著者は主張します。代わりに「コンテキストオーサリング」という呼称を提案し、その重要性を説いています。従来の「エンジニアリング」は、厳格なプロトコルに従って予測可能なシステムを構築するという意味合いが強く、LLMの確率的な性質とは乖離があります。LLMの出力は決定的ではなく、反復可能でもないため、この言葉は誤った期待値を設定してしまいます。

これに対し、「オーサリング」は、コンテンツを構造化し、解釈を導くコミュニケーションのプロセスを意味します。LLMは人間が生成した膨大なコミュニケーションデータで訓練されており、本質的にパターンマッチングを行います。したがって、LLMへの入力は、意図、制約、望ましい結果を尊重させるための「コミュニケーションの工夫」と捉えるべきです。これは、人間と協力して作業する際に、明確なドキュメントや指示を作成する行為と何ら変わりません。

例えば、LLMに特定の役割を与えたり、期待する出力の例を示したり、背景情報を補足したり、具体的な指示を与えたりすることは、すべて「オーサリング」の行為です。コード自体も、システムや人間への意図を伝えるコミュニケーションの一形態です。良質なコードが意図を正確に伝えるように、LLMへの入力も良質なコミュニケーションである必要があります。入力されるコミュニケーションの質が高いほど、LLMが出力するコミュニケーションは私たちの意図に沿ったものになる可能性が高まります。この「オーサリング」という視点を持つことで、開発者はLLMからより良い結果を引き出すことができる、と記事は結論付けています。