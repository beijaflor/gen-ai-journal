## AIの「思考法」に革命か。人間の脳を模倣した新モデル「HRM」、ChatGPTを凌駕する推論能力を証明

https://xenospectrum.com/new-model-mimicking-the-human-brain-demonstrates-reasoning-capabilities-surpassing-chatgpt/

Sapient Intelligenceが開発した人間の脳を模倣した階層的推論モデル（HRM）は、わずかなパラメータ数でChatGPTを凌駕する複雑な推論能力を示し、AI開発の新たな方向性を提示します。

**Content Type**: Research & Analysis

**Scores**: Signal:4/5 | Depth:4/5 | Unique:5/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 84/100 | **Annex Potential**: 86/100 | **Overall**: 84/100

**Topics**: [[階層的推論モデル, 大規模言語モデル, 推論能力, 少パラメータAI, 脳型アーキテクチャ]]

シンガポールのSapient Intelligenceが開発した「階層的推論モデル（HRM）」は、AI開発の新たな潮流を提示しています。わずか2,700万という少数のパラメータにもかかわらず、HRMはChatGPTなどの大規模言語モデル（LLM）が苦手とする複雑な推論タスクにおいて、既存モデルを凌駕する性能を発揮しました。

これまでのLLM開発は「スケーリング則」に基づき、パラメータ数や学習データを増やす「巨大化」に依存してきました。しかし、このアプローチは膨大な計算コストとエネルギー消費、そして「思考の連鎖（CoT）」のような脆弱な推論メカニズムという限界に直面しています。CoTは段階的思考を言語化する手法ですが、一つの誤りが全体を破綻させる脆さや、言語トークン生成による応答の遅延、膨大な学習データ要求が課題でした。

HRMは人間の脳の「階層性」と「マルチタイムスケール」に着想を得ており、熟考を担当する「高レベル（H）モジュール」と、高速な実行を担う「低レベル（L）モジュール」の二つが連携します。Hモジュールが全体戦略を立て、Lモジュールがサブタスクを高速処理。その結果をHモジュールが受けて戦略を更新する「階層的収束」により、多角的かつ粘り強い問題解決が可能です。これにより、思考を言語化しない「潜在的推論」が実現され、CoTの脆さを克服します。

その性能は衝撃的です。「AIのIQテスト」とも呼ばれるARC-AGIチャレンジでは、OpenAIのo3-mini-highやAnthropicのClaude 3.7 Sonnetを上回る40.3%を達成。さらに、既存LLMが0%だったSudoku-Extreme（55.0%）やMaze-Hard（74.5%）のような超難解パズルも攻略し、広範な探索や試行錯誤が必要な問題で質的なブレークスルーを示しました。これらがわずか1,000個という極めて少数の学習サンプルで達成された点は、AIの知性が「量」だけでなく「構造の賢さ」によってもたらされることを物語っています。

Webアプリケーションエンジニアにとって、このHRMの登場は大きな意味を持ちます。従来の巨大LLMのような天文学的なリソースを必要とせず、効率的かつ高速な推論が可能なモデルは、特にコストやリアルタイム性が重視される領域でのAI活用を加速させます。例えば、エッジAIとしてのデバイスへの組み込みや、限られたデータで動作するエンタープライズ向けの最適化システムなど、これまで導入が難しかったアプリケーションでのAI実装が現実味を帯びてきます。また、CoTのようなプロンプトエンジニアリングの複雑さやエラー耐性の低さに依存しない、より堅牢な推論能力は、AIを活用した機能開発における信頼性と開発効率を高める可能性を秘めています。これは、AIモデル選定において、パラメータ規模だけでなく、そのアーキテクチャと推論メカニズムの質を重視すべき時代が来たことを示唆しています。