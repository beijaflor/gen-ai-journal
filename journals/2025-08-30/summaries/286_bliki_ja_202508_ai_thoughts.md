## LLMとソフトウェア開発に関する考察

https://bliki-ja.github.io/202508-ai-thoughts

Martin Fowlerが、ソフトウェア開発におけるLLMの真の活用法はオートコンプリートに留まらないと主張し、AIバブルやハルシネーションへの現実的な対処法、エージェント型AIの深刻なセキュリティ課題について洞察を提供する。

**Content Type**: Opinion & Commentary

**Scores**: Signal:5/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 100/100 | **Annex Potential**: 100/100 | **Overall**: 84/100

**Topics**: [[LLM活用法, ソフトウェア開発生産性, AIバブル, ハルシネーション, AIエージェントセキュリティ]]

Martin Fowlerは、LLMがソフトウェア開発に与える影響について、現状の研究が「高機能なオートコンプリート」という限定的な使い方に焦点を当てすぎていると指摘します。真にLLMを使いこなすには、ソースコードの読み込みや編集を伴うエージェント的なアプローチが重要であり、この点が無視された研究は誤解を生む可能性があると警鐘を鳴らしています。ウェブアプリケーションエンジニアとしては、単なるコード補完に留まらない、より踏み込んだLLMの活用法を模索する必要があることを示唆しています。

プログラミングの未来については、「全くわからない」と率直に述べ、ジュニアエンジニアの不要論やシニアのキャリアパスに関する予測は無意味だと切り捨てています。この不確実な時代において、エンジニアは「とにかく試すこと」、他者の具体的な活用事例に学び、自ら実験して経験を共有することが何よりも重要だと強調します。これは、新しい技術トレンドに乗り遅れないための実践的な指針となります。

また、AI分野が経済的バブルであることは当然としながらも、ドットコムバブル後にAmazonが生き残ったように、バブルが弾けても本質的な価値を持つ企業や技術は残ると展望します。我々開発者は、目先の流行に惑わされず、長期的な視点で価値を見極めるべきでしょう。

LLMのハルシネーション（幻覚）については、「バグではなく特徴である」という見方を提示し、非決定論的な特性を持つLLMとの付き合い方を解説しています。同じ質問を複数回投げかけたり、答えを比較したりすることで、その差異から有益な情報を引き出す方法を提案。従来の決定論的なソフトウェア工学とは異なる、新たな検証アプローチが求められることを示しています。

最後に、LLMを用いたAIエージェントの深刻なセキュリティリスクに警鐘を鳴らしています。特に、プライベートデータへのアクセス、信頼されていないコンテンツへの露出、外部通信手段という「破滅の三要素」を併せ持つエージェントは極めて危険だと強調。攻撃者がウェブページに仕込んだ隠れた指示により、ブラウザで動作するエージェントが銀行口座から送金を行うといった、具体的な脅威シナリオを提示し、「エージェント型ブラウザ拡張はコンセプトに致命的な欠陥があり、安全に構築することはできない」とまで断言しています。これは、我々ウェブアプリケーションエンジニアがAIを活用したシステムを構築する上で、最優先で考慮すべきセキュリティ課題であり、安易なエージェントの導入に警鐘を鳴らす重要なメッセージです。