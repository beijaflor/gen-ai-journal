## 拡散言語モデルを使ってリアルタイムなアプリケーション生成システムを作った

https://www.ai-shift.co.jp/techblog/6064

拡散言語モデルの高速推論能力を活用し、リアルタイムでUIとロジックを生成するアプリケーション開発システムを構築した。

**Content Type**: Tools

**Scores**: Signal:4/5 | Depth:4/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:4/5
**Main Journal**: 80/100 | **Annex Potential**: 80/100 | **Overall**: 80/100

**Topics**: [[Diffusion Language Models, Real-time Application Generation, Code Generation, Developer Productivity, LLM Inference Speed]]

AI Shiftの戸田氏が、拡散言語モデルの高速推論能力を活かしたリアルタイムアプリケーション生成システムを開発し、その実装とデモを公開しました。このシステムは、ユーザーの要望に応じてHTMLベースのUIとロジックを即座に生成し、実行可能な形で提供します。従来の自己回帰型モデルでも同様のアプリケーション生成は可能ですが、拡散言語モデルの速度によりユーザーの待ち時間を劇的に短縮し、より優れた開発体験を提供できる点が重要です。

特に注目すべきは、コード生成に特化したInceptionLabsのMercury Coderを採用し、Next.js、TypeScript、Tailwind CSSでシステムを構築した点です。実装の工夫として、LLMに完全なHTMLを生成させるためのfew-shotプロンプト利用や、生成されたHTMLを即座に表示・実行するための`iframe srcDoc`と`sandbox`の使用が挙げられます。これにより、ビルドプロセスを省き、迅速なプロトタイピングと「その場で動く」体験を実現しています。

デモでは、メモ帳やペイントのようなアプリに加え、スネークゲームのような複雑なものも生成可能であることを示しました。推論速度の比較では、Mercury Coderが約4秒で生成を完了し、Gemini 2.5 Flash Liteの約6秒を上回る高速性を見せつけました。ドハティのしきい値にはまだ及ばないものの、この速度向上は体感的な使いやすさにつながると著者は指摘しています。

本記事は、拡散言語モデルが単なる研究対象ではなく、実際の開発ワークフローに組み込まれることで、どのように開発者の生産性向上に貢献し、リアルタイム性が求められるLLMアプリケーションの可能性を広げるかを示唆しています。groqやcerebrasのような推論特化型ハードウェアの進化と相まって、今後さらに高速でインタラクティブなAIコーディングアシスタントの登場が期待されます。