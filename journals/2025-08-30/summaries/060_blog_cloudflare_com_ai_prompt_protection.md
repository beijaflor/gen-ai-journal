## Beyond the ban: A better way to secure generative AI applications

https://blog.cloudflare.com/ai-prompt-protection/

Cloudflareは、生成AI利用時の機密データ漏洩リスクに対処するため、プロンプト検出、分類、きめ細かい制御を可能にする「AIプロンプト保護」機能を発表した。

**Content Type**: ⚙️ Tools

**Scores**: Signal:5/5 | Depth:4/5 | Unique:3/5 | Practical:5/5 | Anti-Hype:4/5
**Main Journal**: 85/100 | **Annex Potential**: 80/100 | **Overall**: 84/100

**Topics**: [[Generative AI Security, Data Loss Prevention, Prompt Engineering Security, Cloudflare One, LLM Orchestration]]

Cloudflareは、従業員による生成AIツールの利用に伴う機密データの漏洩リスクに対処するため、Data Loss Prevention (DLP) 製品の一部として「AIプロンプト保護」機能を発表しました。これは、単にAIツールを禁止するのではなく、文脈に応じたきめ細かい制御を可能にすることで、生産性を維持しつつセキュリティを強化することを目的としています。

本機能は、主に4つの要素で構成されます。まず「プロンプト検出」では、ChatGPTやGoogle GeminiなどのウェブベースAIツールのプロンプトと応答を、Cloudflareのネットワーク上で取得します。特許技術の「オペレーションマッピング」を活用することで、これまで難しかった未公開APIを通じたインタラクションも可視化します。次に「トピック分類」では、ユーザーのプロンプト内容（PII、ソースコード、顧客データなど）と意図（PII要求、悪意あるコード、ジェイルブレイクなど）を意味的に分析します。この分類には、Presidio、Promptguard2、Llama3-70Bといった複数のオープンソースLLMがCloudflare Workers AI上で並列実行され、Vectorize（bge-m3モデル）による埋め込みと組み合わせることで、高精度かつプライバシーを保護しつつ処理されます。これにより、ユーザーデータが第三者ベンダーに送信されることなく分類されます。

「ガードレール」は、このトピック分類に基づいて、誰がどのような種類の情報をAIに送信できるか、またどのような応答を受け取れるかについて、きめ細かいポリシーを設定することを可能にします。これにより、「ブロックまたは許可」という二者択一から脱却し、例えば人事チームはPIIを含むプロンプトを許可し、他の部門はブロックするといった柔軟な運用が可能になります。最後に、「ログ記録」機能は、すべてのプロンプトと応答を顧客提供の公開鍵で暗号化して記録し、会話IDを通じてインタラクション全体を再構築できる監査証跡を提供します。

ウェブアプリケーションエンジニアの視点からは、この機能は生成AIの導入におけるセキュリティ上の大きな懸念を解消し、開発者がAIを活用する自由を奪うことなく、企業全体のデータガバナンスを強化する点で重要です。特に、機密性の高いソースコードや顧客データを扱う際にもAIを安全に利用できる具体的な手段が提供されるため、開発ワークフローにおけるAIの適用範囲を広げることができます。また、オープンソースLLMとCloudflare Workers AIを組み合わせた技術実装は、パフォーマンスとプライバシーを両立させる先進的なアプローチであり、今後のAIツールのセキュリティ標準に影響を与える可能性を秘めています。