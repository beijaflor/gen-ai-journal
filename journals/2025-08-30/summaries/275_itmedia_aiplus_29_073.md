## Microsoft、OpenAIに頼らない初の自社製基盤モデルと高効率な音声AIを発表

https://www.itmedia.co.jp/aiplus/articles/2508/29/news073.html

Microsoftは、OpenAIに依存しない初の自社開発基盤モデル「MAI-1-preview」と高効率な音声AI「MAI-Voice-1」を発表し、Copilotを通じた独自のAI体験強化と戦略転換を明確に打ち出した。

**Content Type**: News & Announcements

**Scores**: Signal:5/5 | Depth:3/5 | Unique:4/5 | Practical:4/5 | Anti-Hype:3/5
**Main Journal**: 80/100 | **Annex Potential**: 76/100 | **Overall**: 76/100

**Topics**: [[Microsoft AI, 基盤モデル, 音声AI, Copilot, AI戦略]]

マイクロソフトは、OpenAIへの依存を減らし、自社AI部門Microsoft AI (MAI) が開発した初の基盤モデル「MAI-1-preview」と高効率な音声生成モデル「MAI-Voice-1」を発表した。これは、同社が独自のAI能力を深め、既存のCopilotエコシステムを強化する戦略的な転換点を示すものだ。

Webアプリケーションエンジニアにとって、この発表は複数の重要な意味を持つ。まず、「MAI-1-preview」が約1万5000基のNVIDIA H100 GPUでエンドツーエンドに学習された初の独立基盤モデルである点は、マイクロソフトがOpenAI以外の独自のAI技術スタックを構築している明確なシグナルだ。これにより、将来的にはより多様で、マイクロソフト製品に深く統合されたAI機能が提供される可能性が高まる。

次に、「MAI-Voice-1」は、単一のGPUで1分間のオーディオを1秒未満で生成できるという驚異的な高効率性を実現しており、その表現力豊かな音声品質は既に「Copilot Daily」や「Podcasts」に活用されている。これは、Webアプリケーションに音声UIや生成AIを活用したストーリーテリング機能を組み込む際のパフォーマンスとコスト効率に大きなメリットをもたらす。MAIが音声をAIコンパニオンの未来のインターフェースと位置付けていることから、音声ベースのインタラクション設計が、今後のWeb開発においてますます重要になることを示唆している。

Copilot内でこれらの新モデルが展開される予定であり、エンジニアは日常的な開発ワークフローでこれらの進化を直接体験することになるだろう。独自の基盤モデルと高効率なマルチモーダルAIの開発は、マイクロソフトのAI戦略が新たなフェーズに入ったことを示唆し、Webアプリケーション開発におけるAI活用の可能性をさらに広げる重要な動きだと言える。MAIのムスタファ・スレイマンCEOが開発者に向けて協力を呼びかけている点も注目に値する。